{"Page 9": {"response": "<h3>\n Simplified Explanation of Leximin and Leximax Algorithms for Distance Labels\n</h3>\n<p>\n In the context of a max-flow game, the\n <strong>\n  Leximin\n </strong>\n and\n <strong>\n  Leximax\n </strong>\n algorithms can be used to allocate profits or distance labels to the edges of the graph in a way that is consistent with certain fairness rules. Here's a detailed yet simplified explanation of how these algorithms work:\n</p>\n<h4>\n Algorithm 4: Leximin Dual-Consistent Core Imputation (for Distance Labels)\n</h4>\n<ol>\n <li>\n  <p>\n   <strong>\n    Input\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    You start with a max-flow game defined on a graph\n    G\n    (\n    V\n    ,\n    E\n    )\n    G(V, E)\n    G\n    (\n    V\n    ,\n    E\n    )\n    , where you have a source\n    s\n    s\n    s\n    , a sink\n    t\n    t\n    t\n    , and non-negative capacities\n    c\n    :\n    E\n    \u2192\n    N\n    +\n    c : E \\to \\mathbb{N}^+\n    c\n    :\n    E\n    \u2192\n    N\n    +\n    .\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Compute GPQ\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Calculate the Picard-Queyranne structure\n    G\n    P\n    Q\n    GPQ\n    GPQ\n    of the graph\n    G\n    G\n    G\n    . This involves creating a modified graph that captures essential edges.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Assign Initial Potentials\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Set the potential of the source vertex\n    s\n    s\n    s\n    to 1 and the potential of the sink vertex\n    t\n    t\n    t\n    to 0 in\n    G\n    P\n    Q\n    GPQ\n    GPQ\n    .\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    While There Are Free Vertices\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <p>\n     <strong>\n      Find a Free Path\n     </strong>\n     : Identify a free path\n     P\n     P\n     P\n     (a path through the graph involving only free vertices) that minimizes the ratio of:\n    </p>\n    \u03f5\n    b\n    \u2212\n    \u03f5\n    a\n    length\u00a0of\n    P\n    \\frac{\\epsilon_b - \\epsilon_a}{\\text{length of } P}\n    length\u00a0of\n    P\n    \u03f5\n    b\n    \u200b\n    \u2212\n    \u03f5\n    a\n    \u200b\n    \u200b\n    <p>\n     where\n     \u03f5\n     b\n     \\epsilon_b\n     \u03f5\n     b\n     \u200b\n     and\n     \u03f5\n     a\n     \\epsilon_a\n     \u03f5\n     a\n     \u200b\n     are the potentials at the endpoints of the path.\n    </p>\n   </li>\n   <li>\n    <p>\n     <strong>\n      Assign Potentials\n     </strong>\n     : Adjust the potentials along this path so that all edges on the path have equal profits.\n    </p>\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Update Vertices\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    After assigning potentials on the path, update the status of vertices (mark them as fixed or free based on whether their potentials have been assigned).\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Repeat\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Continue the process until all vertices have assigned potentials.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Calculate Profits\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    For each edge\n    (\n    i\n    ,\n    j\n    )\n    (i, j)\n    (\n    i\n    ,\n    j\n    )\n    , compute the profit using:\n    profit\n    i\n    j\n    =\n    c\n    i\n    j\n    \u00d7\n    (\n    \u03f5\n    j\n    \u2212\n    \u03f5\n    i\n    )\n    \\text{profit}_{ij} = c_{ij} \\times (\\epsilon_j - \\epsilon_i)\n    profit\n    ij\n    \u200b\n    =\n    c\n    ij\n    \u200b\n    \u00d7\n    (\n    \u03f5\n    j\n    \u200b\n    \u2212\n    \u03f5\n    i\n    \u200b\n    )\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Output\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    The result is the Leximin dual-consistent core imputation, which allocates profits based on the least profit edges being maximized.\n   </li>\n  </ul>\n </li>\n</ol>\n<h4>\n Algorithm 5: Leximax Dual-Consistent Core Imputation (for Distance Labels)\n</h4>\n<ol>\n <li>\n  <p>\n   <strong>\n    Input\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Similar to Algorithm 4, start with the same max-flow game graph\n    G\n    G\n    G\n    .\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Compute GPQ\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Calculate the Picard-Queyranne structure\n    G\n    P\n    Q\n    GPQ\n    GPQ\n    .\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Assign Initial Potentials\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Set the source vertex\n    s\n    s\n    s\n    to 1 and the sink vertex\n    t\n    t\n    t\n    to 0 in\n    G\n    P\n    Q\n    GPQ\n    GPQ\n    .\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    While There Are Free Vertices\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <p>\n     <strong>\n      Find a Free Path\n     </strong>\n     : Identify a free path\n     P\n     P\n     P\n     that maximizes the ratio of:\n    </p>\n    \u03f5\n    b\n    \u2212\n    \u03f5\n    a\n    length\u00a0of\n    P\n    \\frac{\\epsilon_b - \\epsilon_a}{\\text{length of } P}\n    length\u00a0of\n    P\n    \u03f5\n    b\n    \u200b\n    \u2212\n    \u03f5\n    a\n    \u200b\n    \u200b\n   </li>\n   <li>\n    <p>\n     <strong>\n      Assign Potentials\n     </strong>\n     : Adjust the potentials along this path to ensure all edges have equal profits.\n    </p>\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Update Vertices\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Update the status of vertices as fixed or free.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Repeat\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Continue until all vertices have assigned potentials.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Calculate Profits\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Compute profits for each edge using:\n    profit\n    i\n    j\n    =\n    c\n    i\n    j\n    \u00d7\n    (\n    \u03f5\n    j\n    \u2212\n    \u03f5\n    i\n    )\n    \\text{profit}_{ij} = c_{ij} \\times (\\epsilon_j - \\epsilon_i)\n    profit\n    ij\n    \u200b\n    =\n    c\n    ij\n    \u200b\n    \u00d7\n    (\n    \u03f5\n    j\n    \u200b\n    \u2212\n    \u03f5\n    i\n    \u200b\n    )\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Output\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    The result is the Leximax dual-consistent core imputation, which maximizes the average profits assigned to edges.\n   </li>\n  </ul>\n </li>\n</ol>\n<h3>\n Theorem 3.5\n</h3>\n<ul>\n <li>\n  <p>\n   <strong>\n    Statement\n   </strong>\n   : Algorithms 2 and 3 compute the Leximin and Leximax imputations over profits among all dual-consistent core imputations. Similarly, Algorithms 4 and 5 compute these imputations over distance labels.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Proof Summary\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <p>\n     <strong>\n      Algorithm Efficiency\n     </strong>\n     : The efficiency of Algorithm 2 (and similarly Algorithms 3, 4, and 5) is explained by how efficiently we can find paths and assign potentials. The process of finding the best path and verifying potentials can be done in polynomial time by transforming the problem into a simpler graph problem.\n    </p>\n   </li>\n   <li>\n    <p>\n     <strong>\n      Correctness\n     </strong>\n     : The correctness of these algorithms ensures that each imputation (profit distribution) is either Leximin or Leximax consistent. This means that the profits are assigned in a way that is consistent with the rules of the respective approach (Leximin or Leximax) and that the algorithms provide a valid and unique imputation.\n    </p>\n   </li>\n  </ul>\n </li>\n</ul>\n<p>\n In essence, these algorithms ensure fair profit distributions in max-flow games by carefully assigning and updating potentials in a way that respects the chosen fairness criterion, whether it\u2019s focusing on minimizing the least profit (Leximin) or maximizing the average profit (Leximax).\n</p>\n"}, "Page 5": {"response": "<h3>\n Understanding the Picard-Queyranne Graph and Leximin Core Imputations\n</h3>\n<p>\n To find a leximin dual-consistent core imputation in a max-flow game, we use a specialized graph called the\n <strong>\n  Picard-Queyranne graph\n </strong>\n . This graph helps simplify the problem, though working with it involves several key concepts and procedures. Let\u2019s break it down into simpler terms:\n</p>\n<h4>\n Background on Minimum Cuts\n</h4>\n<ul>\n <li>\n  <strong>\n   Minimum Cuts\n  </strong>\n  : In a graph, a minimum cut is a way to separate the source node from the sink node by cutting the edges with the smallest total capacity. Finding all integral minimum cuts (cuts with whole-number capacities) can be complex and may require exponential time due to the potentially large number of cuts.\n </li>\n</ul>\n<h4>\n Picard-Queyranne Graph (GPQ)\n</h4>\n<p>\n <strong>\n  Purpose\n </strong>\n :\n</p>\n<ul>\n <li>\n  The\n  <strong>\n   Picard-Queyranne graph\n  </strong>\n  (GPQ) is used to efficiently find leximin dual-consistent core imputations. This graph simplifies the problem by focusing on a reduced representation of the original graph.\n </li>\n</ul>\n<p>\n <strong>\n  Procedure\n </strong>\n :\n</p>\n<ol>\n <li>\n  <p>\n   <strong>\n    Find Maximum Flow\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Start by determining the maximum flow\n    f\n    f\n    f\n    from the source\n    s\n    s\n    s\n    to the sink\n    t\n    t\n    t\n    in the original graph\n    G\n    =\n    (\n    V\n    ,\n    E\n    )\n    G = (V, E)\n    G\n    =\n    (\n    V\n    ,\n    E\n    )\n    with given capacities.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Create Residual Graph (GR)\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Construct a\n    <strong>\n     residual graph\n    </strong>\n    G\n    R\n    G_R\n    G\n    R\n    \u200b\n    . This graph reflects the remaining capacities of edges after accounting for the current flow:\n    <ul>\n     <li>\n      <strong>\n       Forward Edge\n      </strong>\n      : For an edge\n      (\n      i\n      ,\n      j\n      )\n      (i, j)\n      (\n      i\n      ,\n      j\n      )\n      in the original graph with capacity\n      c\n      (\n      i\n      ,\n      j\n      )\n      c(i, j)\n      c\n      (\n      i\n      ,\n      j\n      )\n      and flow\n      f\n      (\n      i\n      ,\n      j\n      )\n      f(i, j)\n      f\n      (\n      i\n      ,\n      j\n      )\n      , the forward edge in\n      G\n      R\n      G_R\n      G\n      R\n      \u200b\n      has a residual capacity\n      c\n      R\n      (\n      i\n      ,\n      j\n      )\n      =\n      c\n      (\n      i\n      ,\n      j\n      )\n      \u2212\n      f\n      (\n      i\n      ,\n      j\n      )\n      c_R(i, j) = c(i, j) - f(i, j)\n      c\n      R\n      \u200b\n      (\n      i\n      ,\n      j\n      )\n      =\n      c\n      (\n      i\n      ,\n      j\n      )\n      \u2212\n      f\n      (\n      i\n      ,\n      j\n      )\n      .\n     </li>\n     <li>\n      <strong>\n       Backward Edge\n      </strong>\n      : A backward edge is introduced with a residual capacity\n      c\n      R\n      (\n      j\n      ,\n      i\n      )\n      =\n      f\n      (\n      i\n      ,\n      j\n      )\n      c_R(j, i) = f(i, j)\n      c\n      R\n      \u200b\n      (\n      j\n      ,\n      i\n      )\n      =\n      f\n      (\n      i\n      ,\n      j\n      )\n      , which represents the potential to reverse the flow.\n     </li>\n    </ul>\n   </li>\n   <li>\n    Remove edges with zero residual capacity from\n    G\n    R\n    G_R\n    G\n    R\n    \u200b\n    .\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Identify Strongly Connected Components (SCCs)\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     SCCs\n    </strong>\n    are groups of nodes in which each node can reach every other node in the same group via directed paths. Algorithms like Tarjan\u2019s or Kosaraju\u2019s can be used to find these SCCs in\n    G\n    R\n    G_R\n    G\n    R\n    \u200b\n    .\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Construct the Picard-Queyranne Graph (GPQ)\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Vertices\n    </strong>\n    : Each SCC in\n    G\n    R\n    G_R\n    G\n    R\n    \u200b\n    is condensed into a single vertex in\n    G\n    P\n    Q\n    GPQ\n    GPQ\n    . This results in a set of representative vertices\n    V\n    P\n    Q\n    V_{PQ}\n    V\n    PQ\n    \u200b\n    .\n   </li>\n   <li>\n    <strong>\n     Edges\n    </strong>\n    : Connect these vertices in\n    G\n    P\n    Q\n    GPQ\n    GPQ\n    based on the original edges between SCCs in\n    G\n    R\n    G_R\n    G\n    R\n    \u200b\n    , preserving edge directions and capacities.\n   </li>\n  </ul>\n </li>\n</ol>\n<p>\n <strong>\n  Functions in GPQ\n </strong>\n :\n</p>\n<ul>\n <li>\n  <strong>\n   Function\n   S\n   S\n   S\n  </strong>\n  : Maps a vertex from the original graph\n  G\n  G\n  G\n  to its corresponding SCC in\n  G\n  P\n  Q\n  GPQ\n  GPQ\n  .\n </li>\n <li>\n  <strong>\n   Function\n   T\n   T\n   T\n  </strong>\n  : Maps a vertex in\n  G\n  P\n  Q\n  GPQ\n  GPQ\n  back to the set of original vertices in\n  G\n  G\n  G\n  that it represents.\n </li>\n</ul>\n<p>\n <strong>\n  Important Points\n </strong>\n :\n</p>\n<ul>\n <li>\n  <strong>\n   No s-t Path in GPQ\n  </strong>\n  : Since there\u2019s no direct path from source to sink in\n  G\n  P\n  Q\n  GPQ\n  GPQ\n  , it reflects the structure of the residual graph\n  G\n  R\n  G_R\n  G\n  R\n  \u200b\n  .\n </li>\n <li>\n  <strong>\n   Edge Directions\n  </strong>\n  : The direction of edges in\n  G\n  P\n  Q\n  GPQ\n  GPQ\n  may be reversed compared to the original graph\n  G\n  G\n  G\n  .\n </li>\n</ul>\n<h4>\n Summary\n</h4>\n<ul>\n <li>\n  <strong>\n   Picard-Queyranne Graph\n  </strong>\n  helps to find leximin dual-consistent core imputations efficiently.\n </li>\n <li>\n  It simplifies the original max-flow problem by summarizing strongly connected components and their connections.\n </li>\n <li>\n  The process involves finding maximum flow, constructing a residual graph, identifying SCCs, and then building\n  G\n  P\n  Q\n  GPQ\n  GPQ\n  from these components.\n </li>\n</ul>\n<p>\n By following these steps, the problem of finding a leximin dual-consistent core imputation becomes more manageable, even when dealing with complex graphs.\n</p>\n"}, "Page 8": {"response": "<h3>\n Simplified Explanation of Leximin and Leximax Dual-Consistent Core Imputations\n</h3>\n<h4>\n What Are Leximin and Leximax Dual-Consistent Core Imputations?\n</h4>\n<p>\n In the context of a max-flow game,\n <strong>\n  leximin\n </strong>\n and\n <strong>\n  leximax\n </strong>\n core imputations are methods to fairly allocate profits to edges based on specific rules:\n</p>\n<ul>\n <li>\n  <p>\n   <strong>\n    Leximin\n   </strong>\n   : This approach aims to ensure the smallest profits are as large as possible. It prioritizes fairness by focusing on the least profitable edge and trying to make it better.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Leximax\n   </strong>\n   : This approach maximizes the average profits assigned to the edges, aiming to make the overall distribution as high as possible.\n  </p>\n </li>\n</ul>\n<h3>\n How the Algorithms Work\n</h3>\n<h4>\n Algorithm 2: Leximin Core Imputation\n</h4>\n<ol>\n <li>\n  <p>\n   <strong>\n    Input\n   </strong>\n   : The algorithm starts with a max-flow game represented by a graph\n   G\n   (\n   V\n   ,\n   E\n   )\n   G(V, E)\n   G\n   (\n   V\n   ,\n   E\n   )\n   with source\n   s\n   s\n   s\n   , sink\n   t\n   t\n   t\n   , and non-negative edge capacities\n   c\n   :\n   E\n   \u2192\n   N\n   +\n   c : E \\to \\mathbb{N}^+\n   c\n   :\n   E\n   \u2192\n   N\n   +\n   .\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Compute GPQ\n   </strong>\n   : Calculate the Picard-Queyranne structure\n   G\n   P\n   Q\n   GPQ\n   GPQ\n   of the graph. This step involves creating a new graph that captures essential edges and their properties.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Initial Potentials\n   </strong>\n   : Set the potential\n   \u03f5\n   \\epsilon\n   \u03f5\n   of the source vertex\n   s\n   s\n   s\n   to 1 and the potential of the sink vertex\n   t\n   t\n   t\n   to 0 in\n   G\n   P\n   Q\n   GPQ\n   GPQ\n   .\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Assign Potentials\n   </strong>\n   : For each free vertex (vertices not yet assigned a potential):\n  </p>\n  <ul>\n   <li>\n    <p>\n     <strong>\n      Find Free Path\n     </strong>\n     : Look for a path\n     P\n     P\n     P\n     among all free paths that minimizes the average cost, calculated as:\n    </p>\n    \u2211\n    e\n    \u2208\n    P\n    1\n    c\n    e\n    \u03f5\n    b\n    \u2212\n    \u03f5\n    a\n    \\frac{\\sum_{e \\in P} \\frac{1}{c_e}}{\\epsilon_b - \\epsilon_a}\n    \u03f5\n    b\n    \u200b\n    \u2212\n    \u03f5\n    a\n    \u200b\n    \u2211\n    e\n    \u2208\n    P\n    \u200b\n    c\n    e\n    \u200b\n    1\n    \u200b\n    \u200b\n    <p>\n     where\n     \u03f5\n     b\n     \\epsilon_b\n     \u03f5\n     b\n     \u200b\n     and\n     \u03f5\n     a\n     \\epsilon_a\n     \u03f5\n     a\n     \u200b\n     are potentials of the endpoints of the path.\n    </p>\n   </li>\n   <li>\n    <p>\n     <strong>\n      Assign Potentials\n     </strong>\n     : Adjust the potentials along this path so that all edges get equal profits.\n    </p>\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Update Vertices\n   </strong>\n   : After assigning potentials, update the lists of fixed (assigned) and free (unassigned) vertices.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Repeat\n   </strong>\n   : Continue the process until all vertices have assigned potentials.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Calculate Profits\n   </strong>\n   : For each edge\n   (\n   i\n   ,\n   j\n   )\n   (i, j)\n   (\n   i\n   ,\n   j\n   )\n   in the graph, compute the profit as:\n  </p>\n  profit\n  i\n  j\n  =\n  c\n  i\n  j\n  \u00d7\n  (\n  \u03f5\n  j\n  \u2212\n  \u03f5\n  i\n  )\n  \\text{profit}_{ij} = c_{ij} \\times (\\epsilon_j - \\epsilon_i)\n  profit\n  ij\n  \u200b\n  =\n  c\n  ij\n  \u200b\n  \u00d7\n  (\n  \u03f5\n  j\n  \u200b\n  \u2212\n  \u03f5\n  i\n  \u200b\n  )\n </li>\n <li>\n  <p>\n   <strong>\n    Output\n   </strong>\n   : The final result is the Leximin dual-consistent core imputation, which is the profit distribution that ensures fairness according to the Leximin rule.\n  </p>\n </li>\n</ol>\n<h4>\n Algorithm 3: Leximax Core Imputation\n</h4>\n<ol>\n <li>\n  <p>\n   <strong>\n    Input\n   </strong>\n   : Similar to Algorithm 2, start with the same max-flow game graph\n   G\n   G\n   G\n   .\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Compute GPQ\n   </strong>\n   : Calculate the Picard-Queyranne structure\n   G\n   P\n   Q\n   GPQ\n   GPQ\n   .\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Initial Potentials\n   </strong>\n   : Set potentials for the source\n   s\n   s\n   s\n   and sink\n   t\n   t\n   t\n   as before.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Assign Potentials\n   </strong>\n   : For each free vertex:\n  </p>\n  <ul>\n   <li>\n    <p>\n     <strong>\n      Find Free Path\n     </strong>\n     : Look for a path\n     P\n     P\n     P\n     that maximizes the average profit, calculated as:\n    </p>\n    \u2211\n    e\n    \u2208\n    P\n    1\n    c\n    e\n    \u03f5\n    b\n    \u2212\n    \u03f5\n    a\n    \\frac{\\sum_{e \\in P} \\frac{1}{c_e}}{\\epsilon_b - \\epsilon_a}\n    \u03f5\n    b\n    \u200b\n    \u2212\n    \u03f5\n    a\n    \u200b\n    \u2211\n    e\n    \u2208\n    P\n    \u200b\n    c\n    e\n    \u200b\n    1\n    \u200b\n    \u200b\n   </li>\n   <li>\n    <p>\n     <strong>\n      Assign Potentials\n     </strong>\n     : Adjust the potentials along this path so that all edges receive equal profits.\n    </p>\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Update Vertices\n   </strong>\n   : Update the status of vertices as fixed or free after assigning potentials.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Repeat\n   </strong>\n   : Continue the process until all vertices have assigned potentials.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Calculate Profits\n   </strong>\n   : Compute profits for each edge using:\n  </p>\n  profit\n  i\n  j\n  =\n  c\n  i\n  j\n  \u00d7\n  (\n  \u03f5\n  j\n  \u2212\n  \u03f5\n  i\n  )\n  \\text{profit}_{ij} = c_{ij} \\times (\\epsilon_j - \\epsilon_i)\n  profit\n  ij\n  \u200b\n  =\n  c\n  ij\n  \u200b\n  \u00d7\n  (\n  \u03f5\n  j\n  \u200b\n  \u2212\n  \u03f5\n  i\n  \u200b\n  )\n </li>\n <li>\n  <p>\n   <strong>\n    Output\n   </strong>\n   : The final result is the Leximax dual-consistent core imputation, which distributes profits to maximize the average value.\n  </p>\n </li>\n</ol>\n<h3>\n Summary\n</h3>\n<ul>\n <li>\n  <p>\n   <strong>\n    Leximin Approach\n   </strong>\n   : Ensures the smallest profits are as large as possible by finding paths that minimize costs and ensuring fairness across the least profitable edges.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Leximax Approach\n   </strong>\n   : Maximizes the average profit by finding paths that maximize the average value of the profits.\n  </p>\n </li>\n</ul>\n<p>\n Both algorithms use the Picard-Queyranne structure\n G\n P\n Q\n GPQ\n GPQ\n to determine edge profits based on vertex potentials, but they differ in how they prioritize and allocate these profits.\n</p>\n"}, "Page 6": {"response": "<h3>\n Simplified Explanation of Graph Properties and Dual-Consistent Potentials\n</h3>\n<p>\n Here\u2019s a breakdown of the concepts and results related to the Picard-Queyranne graph (GPQ) and dual-consistent potentials in a max-flow game:\n</p>\n<h4>\n Properties of Essential Edges and GPQ\n</h4>\n<p>\n <strong>\n  Key Concepts\n </strong>\n :\n</p>\n<ul>\n <li>\n  <strong>\n   Flow Conservation\n  </strong>\n  : This principle means that at every vertex (except the source and sink), the total flow coming into the vertex equals the total flow going out.\n </li>\n</ul>\n<p>\n <strong>\n  Essential Edges\n </strong>\n :\n</p>\n<ul>\n <li>\n  <strong>\n   Definition\n  </strong>\n  : An essential edge is one that is fully used in every possible maximum flow from the source to the sink.\n </li>\n <li>\n  <strong>\n   In GPQ\n  </strong>\n  :\n  <ul>\n   <li>\n    In the residual graph\n    G\n    R\n    G_R\n    G\n    R\n    \u200b\n    , only the backward edges for essential edges remain because the forward edges are fully utilized and removed.\n   </li>\n   <li>\n    As a result, in GPQ, essential edges from the original graph\n    G\n    G\n    G\n    appear with their directions reversed but with the same capacity.\n   </li>\n   <li>\n    Essential edges are crucial because all minimum cuts in\n    G\n    G\n    G\n    consist of these edges, and they are preserved in\n    G\n    P\n    Q\n    GPQ\n    GPQ\n    . Thus, minimum cuts in\n    G\n    G\n    G\n    and\n    G\n    P\n    Q\n    GPQ\n    GPQ\n    correspond directly to each other.\n   </li>\n  </ul>\n </li>\n</ul>\n<p>\n <strong>\n  Non-Essential Edges\n </strong>\n :\n</p>\n<ul>\n <li>\n  <strong>\n   Definition\n  </strong>\n  : Non-essential edges are those that are not fully used in every maximum flow.\n </li>\n <li>\n  <strong>\n   In GPQ\n  </strong>\n  :\n  <ul>\n   <li>\n    The vertices connected by non-essential edges are reachable from each other, meaning they belong to the same strongly connected component (SCC).\n   </li>\n   <li>\n    Consequently, non-essential edges are not preserved in GPQ, as they do not contribute to the minimum cuts.\n   </li>\n  </ul>\n </li>\n</ul>\n<p>\n <strong>\n  Uniqueness\n </strong>\n :\n</p>\n<ul>\n <li>\n  The Picard-Queyranne graph\n  G\n  P\n  Q\n  GPQ\n  GPQ\n  uniquely represents the essential edges and thus is unique for any given graph\n  G\n  G\n  G\n  .\n </li>\n</ul>\n<h4>\n Dual-Consistent Potentials and Fractional Min-Cuts\n</h4>\n<p>\n <strong>\n  Dual-Consistent Potentials\n </strong>\n :\n</p>\n<ul>\n <li>\n  <strong>\n   Definition\n  </strong>\n  : A potential function\n  \u03f5\n  \u02c9\n  \\bar{\\epsilon}\n  \u03f5\n  \u02c9\n  on the vertices of\n  G\n  P\n  Q\n  GPQ\n  GPQ\n  is dual-consistent if it meets the following criteria:\n  <ol>\n   <li>\n    <strong>\n     Source Potential\n    </strong>\n    : The potential for the source vertex\n    S\n    (\n    s\n    )\n    S(s)\n    S\n    (\n    s\n    )\n    is 1 (\n    \u03f5\n    \u02c9\n    (\n    S\n    (\n    s\n    )\n    )\n    =\n    1\n    \\bar{\\epsilon}(S(s)) = 1\n    \u03f5\n    \u02c9\n    (\n    S\n    (\n    s\n    ))\n    =\n    1\n    ).\n   </li>\n   <li>\n    <strong>\n     Sink Potential\n    </strong>\n    : The potential for the sink vertex\n    S\n    (\n    t\n    )\n    S(t)\n    S\n    (\n    t\n    )\n    is 0 (\n    \u03f5\n    \u02c9\n    (\n    S\n    (\n    t\n    )\n    )\n    =\n    0\n    \\bar{\\epsilon}(S(t)) = 0\n    \u03f5\n    \u02c9\n    (\n    S\n    (\n    t\n    ))\n    =\n    0\n    ).\n   </li>\n   <li>\n    <strong>\n     Non-Decreasing\n    </strong>\n    : The potential on any edge\n    (\n    i\n    ,\n    j\n    )\n    (i, j)\n    (\n    i\n    ,\n    j\n    )\n    is non-decreasing, meaning\n    \u03f5\n    \u02c9\n    (\n    i\n    )\n    \u2264\n    \u03f5\n    \u02c9\n    (\n    j\n    )\n    \\bar{\\epsilon}(i) \\leq \\bar{\\epsilon}(j)\n    \u03f5\n    \u02c9\n    (\n    i\n    )\n    \u2264\n    \u03f5\n    \u02c9\n    (\n    j\n    )\n    for all directed edges in\n    E\n    P\n    Q\n    EPQ\n    EPQ\n    .\n   </li>\n  </ol>\n </li>\n</ul>\n<p>\n <strong>\n  Fractional Min-Cuts\n </strong>\n :\n</p>\n<ul>\n <li>\n  <strong>\n   Definition\n  </strong>\n  : A fractional min-cut is a way to cut the graph such that the total weight of the cut is minimized, and the cut is defined by fractional capacities rather than integer values.\n </li>\n</ul>\n<p>\n <strong>\n  Constructing a Fractional Min-Cut\n </strong>\n :\n</p>\n<ol>\n <li>\n  <strong>\n   Order Vertices\n  </strong>\n  : List the vertices of\n  G\n  P\n  Q\n  GPQ\n  GPQ\n  in non-increasing order of their potentials, starting with\n  S\n  (\n  s\n  )\n  S(s)\n  S\n  (\n  s\n  )\n  and ending with\n  S\n  (\n  t\n  )\n  S(t)\n  S\n  (\n  t\n  )\n  .\n </li>\n <li>\n  <strong>\n   Create Initial Cut\n  </strong>\n  : Define the initial cut\n  S\n  1\n  S_1\n  S\n  1\n  \u200b\n  as all edges directed into the source vertex\n  S\n  (\n  s\n  )\n  S(s)\n  S\n  (\n  s\n  )\n  . This is a valid min-cut of\n  G\n  G\n  G\n  .\n </li>\n <li>\n  <strong>\n   Iterative Process\n  </strong>\n  :\n  <ul>\n   <li>\n    <strong>\n     Update Cuts\n    </strong>\n    : Iteratively update the cut by \"pulling\" vertices across the current cut. For each vertex\n    v\n    k\n    v_k\n    v\n    k\n    \u200b\n    in the list (except the first and last), remove edges going out of\n    v\n    k\n    v_k\n    v\n    k\n    \u200b\n    from the cut and add edges coming into\n    v\n    k\n    v_k\n    v\n    k\n    \u200b\n    .\n   </li>\n  </ul>\n </li>\n</ol>\n<p>\n This iterative process helps in constructing a fractional min-cut based on the dual-consistent potentials, ensuring the cut respects the potentials defined on\n G\n P\n Q\n GPQ\n GPQ\n .\n</p>\n<h3>\n Summary\n</h3>\n<ul>\n <li>\n  <strong>\n   Picard-Queyranne Graph (GPQ)\n  </strong>\n  simplifies the max-flow problem by focusing on essential edges, preserving only those edges in the reduced graph.\n </li>\n <li>\n  <strong>\n   Dual-Consistent Potentials\n  </strong>\n  are functions on the vertices of\n  G\n  P\n  Q\n  GPQ\n  GPQ\n  that help in defining fractional min-cuts.\n </li>\n <li>\n  <strong>\n   Fractional Min-Cuts\n  </strong>\n  are computed based on these potentials, ensuring that the cut represents the minimal capacity needed to separate the source and sink in the graph.\n </li>\n</ul>\n<p>\n By understanding these concepts and procedures, we can efficiently work with max-flow problems and find core imputations that are consistent with the dual LP formulation.\n</p>\n"}, "Page 1": {"response": "<h3>\n Overview of the Paper\n</h3>\n<p>\n The paper titled \"The Flow Game: Leximin and Leximax Core Imputations\" by Rohith R. Gangam, Naveen Garg, Parnian Shahkar, and Vijay V. Vazirani discusses methods for computing leximin and leximax core imputations for flow games. Published on March 12, 2024, this work is significant in algorithm design and game theory, particularly in the context of core imputations and flow games.\n</p>\n<h3>\n Introduction to Core Imputations\n</h3>\n<p>\n<strong>\n  Core Imputations\n </strong>\n :\nCore imputations are solutions to cooperative games where no subset of players can deviate and achieve a better outcome for themselves. In flow games, core imputations ensure that no coalition of players can improve their situation by working together outside the proposed imputation.\n</p>\n<h3>\n Leximin and Leximax Core Imputations\n</h3>\n<p>\n<strong>\n  Leximin Core Imputations\n </strong>\n :\n</p>\n<ul>\n<li>\n  Leximin (short for lexicographic minimax) imputations focus on maximizing the minimum value in a lexicographic order.\n </li>\n<li>\n  The leximin approach seeks to provide the most equitable distribution where the smallest component of the solution is as large as possible.\n </li>\n</ul>\n<p>\n<strong>\n  Leximax Core Imputations\n </strong>\n :\n</p>\n<ul>\n<li>\n  Leximax (short for lexicographic maximax) imputations aim to maximize the maximum value in a lexicographic order.\n </li>\n<li>\n  This approach focuses on maximizing the largest component of the imputation in a lexicographic sense, often resulting in less equitable but potentially more favorable solutions for the top performers.\n </li>\n</ul>\n<h3>\n Flow Games and Their Importance\n</h3>\n<p>\n<strong>\n  Flow Games\n </strong>\n :\n</p>\n<ul>\n<li>\n  Flow games are a type of cooperative game where players control flows through a network. The objective is to allocate resources (or flow) through various paths in the network while adhering to certain constraints such as capacities and distances.\n </li>\n<li>\n  Kalai and Zemel (1982) introduced flow games, and these games are crucial in studying the allocation of resources and the stability of cooperative outcomes.\n </li>\n</ul>\n<h3>\n Contributions of the Paper\n</h3>\n<p>\n<strong>\n  Mechanisms for Leximin and Leximax Imputations\n </strong>\n :\n</p>\n<ul>\n<li>\n  The authors propose strongly polynomial-time mechanisms for computing both leximin and leximax core imputations for flow games. This is a significant advancement because it addresses the problem in polynomial time, which is crucial for practical applications.\n </li>\n</ul>\n<p>\n<strong>\n  Dual LP Approach\n </strong>\n :\n</p>\n<ul>\n<li>\n  The solutions are derived from the dual of a linear programming (LP) formulation. The dual LP captures the essence of the core imputations by considering constraints and objectives related to the flow game.\n </li>\n<li>\n  By solving the dual LP, the authors provide efficient algorithms for finding core imputations that are either leximin or leximax, depending on the criteria used.\n </li>\n</ul>\n<h3>\n Specific Versions Addressed\n</h3>\n<ol>\n<li>\n<p>\n<strong>\n    Distance Labels of Edges\n   </strong>\n   :\n  </p>\n<ul>\n<li>\n    This version of the problem considers the leximin and leximax imputations with respect to the distance labels of the edges in the flow network.\n   </li>\n<li>\n    The distance labels can influence the fairness and efficiency of the flow distribution, impacting how resources are allocated across the network.\n   </li>\n</ul>\n</li>\n<li>\n<p>\n<strong>\n    Product of Capacities and Distance Labels\n   </strong>\n   :\n  </p>\n<ul>\n<li>\n    In this version, the imputations are evaluated with respect to the product of the capacities of edges and their distance labels.\n   </li>\n<li>\n    This approach takes into account both the capacity of the edges and the distance, providing a nuanced way to compute core imputations.\n   </li>\n</ul>\n</li>\n</ol>\n<h3>\n Implications and Future Directions\n</h3>\n<p>\n<strong>\n  Algorithm Design Insights\n </strong>\n :\n</p>\n<ul>\n<li>\n  The paper highlights a broader trend in algorithm design where techniques discovered for specific problems (like matching) are adapted to other problems (like flow games). This cross-application of techniques often leads to new insights and efficient algorithms.\n </li>\n</ul>\n<p>\n<strong>\n  Future Research\n </strong>\n :\n</p>\n<ul>\n<li>\n  The results could have implications for other cooperative games and resource allocation problems. Future research may explore extending these methods to more complex scenarios or other types of cooperative games.\n </li>\n</ul>\n<p>\n In summary, the paper by Gangam et al. makes significant strides in computing leximin and leximax core imputations for flow games using efficient algorithms. This work builds on previous methods and offers new approaches that could be applied to various problems in cooperative game theory and combinatorial optimization.\n</p>\n"}, "Page 2": {"response": "<h3>\n Preliminaries\n</h3>\n<p>\n In this section, we'll break down the foundational concepts necessary to understand cooperative games and max-flow games.\n</p>\n<h4>\n Cooperative Games\n</h4>\n<p>\n <strong>\n  Cooperative Game Definition\n </strong>\n :\n</p>\n<ul>\n <li>\n  A cooperative game involves a set of players, denoted by\n  N\n  N\n  N\n  , with\n  n\n  n\n  n\n  representing the number of players.\n </li>\n <li>\n  There is a function\n  c\n  c\n  c\n  that assigns a value to each possible subset of players. This value,\n  c\n  (\n  S\n  )\n  c(S)\n  c\n  (\n  S\n  )\n  , represents how much that subset can achieve on its own.\n </li>\n <li>\n  The entire set of players,\n  N\n  N\n  N\n  , is referred to as the\n  <strong>\n   grand coalition\n  </strong>\n  .\n </li>\n</ul>\n<p>\n <strong>\n  Imputation Definition\n </strong>\n :\n</p>\n<ul>\n <li>\n  An\n  <strong>\n   imputation\n  </strong>\n  is a way to distribute the total value of the game among the players.\n </li>\n <li>\n  This is done using a function\n  p\n  p\n  p\n  where\n  p\n  (\n  i\n  )\n  p(i)\n  p\n  (\n  i\n  )\n  is the share given to player\n  i\n  i\n  i\n  .\n </li>\n <li>\n  The sum of all shares must equal the total value of the grand coalition, i.e.,\n  \u2211\n  i\n  \u2208\n  N\n  p\n  (\n  i\n  )\n  =\n  c\n  (\n  N\n  )\n  \\sum_{i \\in N} p(i) = c(N)\n  \u2211\n  i\n  \u2208\n  N\n  \u200b\n  p\n  (\n  i\n  )\n  =\n  c\n  (\n  N\n  )\n  .\n </li>\n</ul>\n<p>\n <strong>\n  Core of the Game\n </strong>\n :\n</p>\n<ul>\n <li>\n  An imputation is considered to be in the\n  <strong>\n   core\n  </strong>\n  of the game if it meets the following condition: For every possible subset\n  S\n  S\n  S\n  of players, the total share given to the players in\n  S\n  S\n  S\n  must be at least as much as the value\n  c\n  (\n  S\n  )\n  c(S)\n  c\n  (\n  S\n  )\n  that they could generate on their own. Formally, this is written as\n  \u2211\n  i\n  \u2208\n  S\n  p\n  (\n  i\n  )\n  \u2265\n  c\n  (\n  S\n  )\n  \\sum_{i \\in S} p(i) \\geq c(S)\n  \u2211\n  i\n  \u2208\n  S\n  \u200b\n  p\n  (\n  i\n  )\n  \u2265\n  c\n  (\n  S\n  )\n  .\n </li>\n</ul>\n<h3>\n Max-Flow Game\n</h3>\n<p>\n <strong>\n  Graph Basics\n </strong>\n :\n</p>\n<ul>\n <li>\n  Consider a directed graph\n  G\n  =\n  (\n  V\n  ,\n  E\n  )\n  G = (V, E)\n  G\n  =\n  (\n  V\n  ,\n  E\n  )\n  where\n  V\n  V\n  V\n  represents the vertices and\n  E\n  E\n  E\n  represents the edges.\n </li>\n <li>\n  The graph has two special nodes: a\n  <strong>\n   source\n  </strong>\n  s\n  s\n  s\n  and a\n  <strong>\n   sink\n  </strong>\n  t\n  t\n  t\n  .\n </li>\n <li>\n  Each edge\n  e\n  e\n  e\n  has a positive capacity\n  c\n  (\n  e\n  )\n  c(e)\n  c\n  (\n  e\n  )\n  indicating the maximum flow it can handle.\n </li>\n</ul>\n<p>\n <strong>\n  Feasible Flow\n </strong>\n :\n</p>\n<ul>\n <li>\n  A\n  <strong>\n   feasible flow\n  </strong>\n  f\n  f\n  f\n  is one where:\n  <ul>\n   <li>\n    The flow through any edge does not exceed its capacity.\n   </li>\n   <li>\n    At each vertex (except for\n    s\n    s\n    s\n    and\n    t\n    t\n    t\n    ), the amount of flow coming in equals the amount of flow going out.\n   </li>\n  </ul>\n </li>\n</ul>\n<p>\n <strong>\n  Max-Flow Problem\n </strong>\n :\n</p>\n<ul>\n <li>\n  The\n  <strong>\n   max-flow problem\n  </strong>\n  seeks to maximize the total flow from the source\n  s\n  s\n  s\n  to the sink\n  t\n  t\n  t\n  , while respecting the capacity constraints of the edges.\n </li>\n</ul>\n<p>\n <strong>\n  Max-Flow Game Definition\n </strong>\n :\n</p>\n<ul>\n <li>\n  In a max-flow game, the graph\n  G\n  =\n  (\n  V\n  ,\n  E\n  )\n  G = (V, E)\n  G\n  =\n  (\n  V\n  ,\n  E\n  )\n  is used to define a cooperative game where edges are considered as players.\n </li>\n <li>\n  The total flow from\n  s\n  s\n  s\n  to\n  t\n  t\n  t\n  represents the profit that needs to be distributed among the edge-players.\n </li>\n <li>\n  The value of the grand coalition (all edges) is the maximum flow that can be achieved in the graph.\n </li>\n</ul>\n<p>\n <strong>\n  Subset Values\n </strong>\n :\n</p>\n<ul>\n <li>\n  For any subset of edges\n  S\n  \u2286\n  E\n  S \\subseteq E\n  S\n  \u2286\n  E\n  , the graph\n  G\n  (\n  S\n  )\n  G(S)\n  G\n  (\n  S\n  )\n  contains only the edges in\n  S\n  S\n  S\n  , with capacities restricted to\n  S\n  S\n  S\n  . The maximum flow in this subgraph\n  G\n  (\n  S\n  )\n  G(S)\n  G\n  (\n  S\n  )\n  is the value of the subset\n  S\n  S\n  S\n  .\n </li>\n</ul>\n<p>\n <strong>\n  s-t Cut\n </strong>\n :\n</p>\n<ul>\n <li>\n  To analyze flows, divide the vertex set\n  V\n  V\n  V\n  into two disjoint subsets,\n  X\n  X\n  X\n  and\n  X\n  \u203e\n  \\overline{X}\n  X\n  , where\n  s\n  s\n  s\n  is in\n  X\n  X\n  X\n  and\n  t\n  t\n  t\n  is in\n  X\n  \u203e\n  \\overline{X}\n  X\n  .\n </li>\n <li>\n  The edges going from\n  X\n  X\n  X\n  to\n  X\n  \u203e\n  \\overline{X}\n  X\n  form an\n  <strong>\n   s-t cut\n  </strong>\n  . The capacity of this cut is the sum of the capacities of these edges.\n </li>\n <li>\n  The capacity of an s-t cut provides an upper bound on the maximum flow.\n </li>\n</ul>\n<p>\n <strong>\n  Max-Flow Min-Cut Theorem\n </strong>\n :\n</p>\n<ul>\n <li>\n  This theorem states that the maximum flow in a network is equal to the capacity of the minimum s-t cut. It guarantees that if you find the maximum flow, you will also identify the minimum capacity cut that limits the flow.\n </li>\n</ul>\n<p>\n In summary, these concepts provide the groundwork for understanding how to distribute resources (flow) in a network efficiently and fairly, both in cooperative game scenarios and in network flow problems.\n</p>\n"}, "Page 3": {"response": "<h3>\n Framing the Maximum Flow Problem with Linear Programming\n</h3>\n<p>\n To solve the maximum flow problem using linear programming, we approach it by adding a new edge to the graph and setting up a system of equations that captures the constraints and objectives of the problem. Here's a step-by-step explanation:\n</p>\n<h4>\n Adding the Edge with Unlimited Capacity\n</h4>\n<ol>\n <li>\n  <p>\n   <strong>\n    Graph Modification\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    We add an edge with\n    <strong>\n     unlimited capacity\n    </strong>\n    from the sink node\n    t\n    t\n    t\n    back to the source node\n    s\n    s\n    s\n    . This addition transforms the problem into what\u2019s called a\n    <strong>\n     circulation problem\n    </strong>\n    .\n   </li>\n   <li>\n    This new edge ensures that the flow conservation principles are maintained at both\n    s\n    s\n    s\n    and\n    t\n    t\n    t\n    .\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Objective\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    The goal now is to\n    <strong>\n     maximize the flow\n    </strong>\n    f\n    t\n    s\n    f_{ts}\n    f\n    t\n    s\n    \u200b\n    through this newly added edge, which indirectly maximizes the flow in the original graph from\n    s\n    s\n    s\n    to\n    t\n    t\n    t\n    .\n   </li>\n  </ul>\n </li>\n</ol>\n<h4>\n Linear Programming Formulation\n</h4>\n<ol start=\"3\">\n <li>\n  <p>\n   <strong>\n    Primal Linear Program\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <p>\n     We define a variable\n     f\n     i\n     j\n     f_{ij}\n     f\n     ij\n     \u200b\n     to represent the flow through each edge\n     (\n     i\n     ,\n     j\n     )\n     \u2208\n     E\n     (i, j) \\in E\n     (\n     i\n     ,\n     j\n     )\n     \u2208\n     E\n     . The linear programming formulation for the maximum flow problem is:\n    </p>\n    maximize\n    f\n    t\n    s\n    \\text{maximize} \\quad f_{ts}\n    maximize\n    f\n    t\n    s\n    \u200b\n    subject\u00a0to:\n    \\text{subject to:}\n    subject\u00a0to:\n    \u2211\n    (\n    j\n    ,\n    i\n    )\n    \u2208\n    E\n    f\n    j\n    i\n    \u2212\n    \u2211\n    (\n    i\n    ,\n    j\n    )\n    \u2208\n    E\n    f\n    i\n    j\n    \u2264\n    0\n    \u2200\n    i\n    \u2208\n    V\n    \\sum_{(j,i) \\in E} f_{ji} - \\sum_{(i,j) \\in E} f_{ij} \\leq 0 \\quad \\forall i \\in V\n    (\n    j\n    ,\n    i\n    )\n    \u2208\n    E\n    \u2211\n    \u200b\n    f\n    ji\n    \u200b\n    \u2212\n    (\n    i\n    ,\n    j\n    )\n    \u2208\n    E\n    \u2211\n    \u200b\n    f\n    ij\n    \u200b\n    \u2264\n    0\n    \u2200\n    i\n    \u2208\n    V\n    f\n    i\n    j\n    \u2264\n    c\n    i\n    j\n    \u2200\n    (\n    i\n    ,\n    j\n    )\n    \u2208\n    E\n    f_{ij} \\leq c_{ij} \\quad \\forall (i, j) \\in E\n    f\n    ij\n    \u200b\n    \u2264\n    c\n    ij\n    \u200b\n    \u2200\n    (\n    i\n    ,\n    j\n    )\n    \u2208\n    E\n    f\n    i\n    j\n    \u2265\n    0\n    \u2200\n    (\n    i\n    ,\n    j\n    )\n    \u2208\n    E\n    f_{ij} \\geq 0 \\quad \\forall (i, j) \\in E\n    f\n    ij\n    \u200b\n    \u2265\n    0\n    \u2200\n    (\n    i\n    ,\n    j\n    )\n    \u2208\n    E\n   </li>\n   <li>\n    <p>\n     <strong>\n      Explanation\n     </strong>\n     :\n    </p>\n    <ul>\n     <li>\n      The first set of constraints ensures that the incoming flow at each node does not exceed the outgoing flow. This maintains flow conservation at each node.\n     </li>\n     <li>\n      The second set ensures that the flow through each edge does not exceed its capacity.\n     </li>\n     <li>\n      The third set ensures that flows are non-negative.\n     </li>\n    </ul>\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Equality Constraint\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Although the setup doesn\u2019t strictly enforce equal incoming and outgoing flows, it does ensure flow conservation as per standard linear programming principles.\n   </li>\n  </ul>\n </li>\n</ol>\n<h4>\n Dual Linear Program\n</h4>\n<ol start=\"5\">\n <li>\n  <p>\n   <strong>\n    Dual Variables\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Introduce dual variables:\n    <ul>\n     <li>\n      \u03f5\n      i\n      \\epsilon_i\n      \u03f5\n      i\n      \u200b\n      for node potentials.\n     </li>\n     <li>\n      \u03c1\n      i\n      j\n      \\rho_{ij}\n      \u03c1\n      ij\n      \u200b\n      for the capacity constraints on edges.\n     </li>\n    </ul>\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Dual Linear Program Formulation\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <p>\n     The dual problem is formulated as:\n    </p>\n    minimize\n    \u2211\n    (\n    i\n    ,\n    j\n    )\n    \u2208\n    E\n    c\n    i\n    j\n    \u03c1\n    i\n    j\n    \\text{minimize} \\quad \\sum_{(i,j) \\in E} c_{ij} \\rho_{ij}\n    minimize\n    (\n    i\n    ,\n    j\n    )\n    \u2208\n    E\n    \u2211\n    \u200b\n    c\n    ij\n    \u200b\n    \u03c1\n    ij\n    \u200b\n    subject\u00a0to:\n    \\text{subject to:}\n    subject\u00a0to:\n    \u03c1\n    i\n    j\n    \u2212\n    \u03f5\n    i\n    +\n    \u03f5\n    j\n    \u2265\n    0\n    \u2200\n    (\n    i\n    ,\n    j\n    )\n    \u2208\n    E\n    \\rho_{ij} - \\epsilon_i + \\epsilon_j \\geq 0 \\quad \\forall (i, j) \\in E\n    \u03c1\n    ij\n    \u200b\n    \u2212\n    \u03f5\n    i\n    \u200b\n    +\n    \u03f5\n    j\n    \u200b\n    \u2265\n    0\n    \u2200\n    (\n    i\n    ,\n    j\n    )\n    \u2208\n    E\n    \u03f5\n    s\n    \u2212\n    \u03f5\n    t\n    \u2265\n    1\n    \\epsilon_s - \\epsilon_t \\geq 1\n    \u03f5\n    s\n    \u200b\n    \u2212\n    \u03f5\n    t\n    \u200b\n    \u2265\n    1\n    \u03c1\n    i\n    j\n    \u2265\n    0\n    \u2200\n    (\n    i\n    ,\n    j\n    )\n    \u2208\n    E\n    \\rho_{ij} \\geq 0 \\quad \\forall (i, j) \\in E\n    \u03c1\n    ij\n    \u200b\n    \u2265\n    0\n    \u2200\n    (\n    i\n    ,\n    j\n    )\n    \u2208\n    E\n    \u03f5\n    i\n    \u2265\n    0\n    \u2200\n    i\n    \u2208\n    V\n    \\epsilon_i \\geq 0 \\quad \\forall i \\in V\n    \u03f5\n    i\n    \u200b\n    \u2265\n    0\n    \u2200\n    i\n    \u2208\n    V\n   </li>\n   <li>\n    <p>\n     <strong>\n      Explanation\n     </strong>\n     :\n    </p>\n    <ul>\n     <li>\n      The dual variables\n      \u03c1\n      i\n      j\n      \\rho_{ij}\n      \u03c1\n      ij\n      \u200b\n      and\n      \u03f5\n      i\n      \\epsilon_i\n      \u03f5\n      i\n      \u200b\n      correspond to the edge distances and node potentials.\n     </li>\n     <li>\n      The dual objective minimizes the total weighted capacity of the edges.\n     </li>\n     <li>\n      The constraints ensure that the differences in node potentials are correctly captured, reflecting the capacity constraints of the edges.\n     </li>\n    </ul>\n   </li>\n  </ul>\n </li>\n</ol>\n<h4>\n Optimal Solution and LP-Duality Theorem\n</h4>\n<ol start=\"7\">\n <li>\n  <p>\n   <strong>\n    Integral Solution\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    If the dual linear program has an integral optimal solution (where\n    \u03c1\n    i\n    j\n    \\rho_{ij}\n    \u03c1\n    ij\n    \u200b\n    and\n    \u03f5\n    i\n    \\epsilon_i\n    \u03f5\n    i\n    \u200b\n    are either 0 or 1), it simplifies understanding the solution. For instance,\n    \u03f5\n    s\n    \\epsilon_s\n    \u03f5\n    s\n    \u200b\n    will be 1,\n    \u03f5\n    t\n    \\epsilon_t\n    \u03f5\n    t\n    \u200b\n    will be 0, and other node potentials will be 0 or 1.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Fractional s-t Cut\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <p>\n     In an optimal dual solution, the distance labels (dual variables\n     \u03c1\n     i\n     j\n     \\rho_{ij}\n     \u03c1\n     ij\n     \u200b\n     ) represent a fractional s-t cut. The capacity of this cut is given by:\n    </p>\n    \u2211\n    (\n    i\n    ,\n    j\n    )\n    \u2208\n    E\n    c\n    i\n    j\n    \u03c1\n    i\n    j\n    \\sum_{(i,j) \\in E} c_{ij} \\rho_{ij}\n    (\n    i\n    ,\n    j\n    )\n    \u2208\n    E\n    \u2211\n    \u200b\n    c\n    ij\n    \u200b\n    \u03c1\n    ij\n    \u200b\n   </li>\n   <li>\n    <p>\n     <strong>\n      LP-Duality Theorem\n     </strong>\n     :\n    </p>\n    <ul>\n     <li>\n      This capacity of the fractional s-t cut equals the maximum flow value in the original graph.\n     </li>\n    </ul>\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Total Value\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <p>\n     According to the LP-Duality Theorem, the total value of the game (or the maximum flow) is equal to the objective value of the dual linear program:\n    </p>\n    worth\n    (\n    E\n    )\n    =\n    \u2211\n    (\n    i\n    ,\n    j\n    )\n    \u2208\n    E\n    c\n    i\n    j\n    \u03c1\n    i\n    j\n    \\text{worth}(E) = \\sum_{(i,j) \\in E} c_{ij} \\rho_{ij}\n    worth\n    (\n    E\n    )\n    =\n    (\n    i\n    ,\n    j\n    )\n    \u2208\n    E\n    \u2211\n    \u200b\n    c\n    ij\n    \u200b\n    \u03c1\n    ij\n    \u200b\n   </li>\n  </ul>\n </li>\n</ol>\n<p>\n In summary, by framing the maximum flow problem as a linear programming problem with added constraints and dual variables, we can effectively solve it and understand the relationship between the flow through the network and the capacities of the edges.\n</p>\n"}, "Page 4": {"response": "<h3>\n Understanding Core Imputations and Dual Consistency\n</h3>\n<p>\n Let's break down the concepts of core imputations, dual consistency, and how these are used in the context of the maximum flow problem.\n</p>\n<h4>\n Profit of an Edge\n</h4>\n<p>\n <strong>\n  Profit Definition\n </strong>\n :\n</p>\n<ul>\n <li>\n  The\n  <strong>\n   profit\n  </strong>\n  p\n  (\n  i\n  ,\n  j\n  )\n  p(i, j)\n  p\n  (\n  i\n  ,\n  j\n  )\n  of an edge\n  (\n  i\n  ,\n  j\n  )\n  (i, j)\n  (\n  i\n  ,\n  j\n  )\n  is calculated as:\n  p\n  (\n  i\n  ,\n  j\n  )\n  :\n  =\n  c\n  i\n  j\n  \u22c5\n  \u03c1\n  i\n  j\n  p(i, j) := c_{ij} \\cdot \\rho_{ij}\n  p\n  (\n  i\n  ,\n  j\n  )\n  :=\n  c\n  ij\n  \u200b\n  \u22c5\n  \u03c1\n  ij\n  \u200b\n  where\n  c\n  i\n  j\n  c_{ij}\n  c\n  ij\n  \u200b\n  is the capacity of the edge and\n  \u03c1\n  i\n  j\n  \\rho_{ij}\n  \u03c1\n  ij\n  \u200b\n  is the dual variable associated with that edge in the linear programming (LP) formulation.\n </li>\n</ul>\n<h4>\n Core Imputations and Dual Consistency\n</h4>\n<p>\n <strong>\n  Core Imputation\n </strong>\n :\n</p>\n<ul>\n <li>\n  A core imputation is a way of distributing the total value of the game among the players such that no subset of players would be better off by leaving and working together on their own. It ensures stability in the distribution of resources.\n </li>\n</ul>\n<p>\n <strong>\n  Dual-Consistent Core Imputation\n </strong>\n :\n</p>\n<ul>\n <li>\n  According to [Vaz23], the dual LP formulation helps to characterize the core of the max-flow game. An imputation is\n  <strong>\n   dual-consistent\n  </strong>\n  if it can be derived from an optimal solution to the dual LP where the profit of each edge\n  (\n  i\n  ,\n  j\n  )\n  (i, j)\n  (\n  i\n  ,\n  j\n  )\n  matches the formula\n  p\n  (\n  i\n  ,\n  j\n  )\n  =\n  c\n  i\n  j\n  \u22c5\n  \u03c1\n  i\n  j\n  p(i, j) = c_{ij} \\cdot \\rho_{ij}\n  p\n  (\n  i\n  ,\n  j\n  )\n  =\n  c\n  ij\n  \u200b\n  \u22c5\n  \u03c1\n  ij\n  \u200b\n  .\n </li>\n</ul>\n<p>\n <strong>\n  Challenges\n </strong>\n :\n</p>\n<ul>\n <li>\n  Not all core imputations are dual-consistent. Finding whether an imputation is in the core can be complex and is known to be NP-hard, meaning it is computationally difficult to determine.\n </li>\n</ul>\n<h4>\n Example of Non-Dual-Consistent Core Imputation\n</h4>\n<p>\n <strong>\n  Example Graph\n </strong>\n :\n</p>\n<ul>\n <li>\n  <p>\n   Consider a graph\n   G\n   =\n   (\n   V\n   ,\n   E\n   )\n   G = (V, E)\n   G\n   =\n   (\n   V\n   ,\n   E\n   )\n   with four nodes\n   s\n   s\n   s\n   ,\n   a\n   a\n   a\n   ,\n   b\n   b\n   b\n   , and\n   t\n   t\n   t\n   . The edges and their capacities are:\n  </p>\n  <ul>\n   <li>\n    s\n    \u2192\n    a\n    s \\to a\n    s\n    \u2192\n    a\n    with capacity 5\n   </li>\n   <li>\n    s\n    \u2192\n    b\n    s \\to b\n    s\n    \u2192\n    b\n    with capacity 5\n   </li>\n   <li>\n    a\n    \u2192\n    t\n    a \\to t\n    a\n    \u2192\n    t\n    with capacity 5\n   </li>\n   <li>\n    b\n    \u2192\n    t\n    b \\to t\n    b\n    \u2192\n    t\n    with capacity 10\n   </li>\n  </ul>\n  <p>\n   The maximum flow from\n   s\n   s\n   s\n   to\n   t\n   t\n   t\n   is 10. An imputation might distribute this flow evenly among the edges.\n  </p>\n </li>\n</ul>\n<p>\n <strong>\n  Profit Calculation\n </strong>\n :\n</p>\n<ul>\n <li>\n  If each edge receives a profit of 2.5 units (i.e.,\n  p\n  (\n  i\n  ,\n  j\n  )\n  =\n  2.5\n  p(i, j) = 2.5\n  p\n  (\n  i\n  ,\n  j\n  )\n  =\n  2.5\n  ), then the distance labels in the dual LP are:\n  <ul>\n   <li>\n    \u03c1\n    s\n    b\n    =\n    1\n    2\n    \\rho_{sb} = \\frac{1}{2}\n    \u03c1\n    s\n    b\n    \u200b\n    =\n    2\n    1\n    \u200b\n   </li>\n   <li>\n    \u03c1\n    b\n    t\n    =\n    1\n    4\n    \\rho_{bt} = \\frac{1}{4}\n    \u03c1\n    b\n    t\n    \u200b\n    =\n    4\n    1\n    \u200b\n   </li>\n   <li>\n    \u03c1\n    s\n    a\n    =\n    1\n    2\n    \\rho_{sa} = \\frac{1}{2}\n    \u03c1\n    s\n    a\n    \u200b\n    =\n    2\n    1\n    \u200b\n   </li>\n   <li>\n    \u03c1\n    a\n    b\n    =\n    1\n    2\n    \\rho_{ab} = \\frac{1}{2}\n    \u03c1\n    ab\n    \u200b\n    =\n    2\n    1\n    \u200b\n   </li>\n  </ul>\n </li>\n</ul>\n<p>\n <strong>\n  Issue with Dual LP\n </strong>\n :\n</p>\n<ul>\n <li>\n  The optimal solution for the dual LP would require specific values for\n  \u03f5\n  i\n  \\epsilon_i\n  \u03f5\n  i\n  \u200b\n  (node potentials) and\n  \u03c1\n  i\n  j\n  \\rho_{ij}\n  \u03c1\n  ij\n  \u200b\n  (edge distances). For this example, no value of\n  \u03f5\n  b\n  \\epsilon_b\n  \u03f5\n  b\n  \u200b\n  satisfies the constraints given by the edge distances\n  \u03c1\n  s\n  b\n  \\rho_{sb}\n  \u03c1\n  s\n  b\n  \u200b\n  and\n  \u03c1\n  b\n  t\n  \\rho_{bt}\n  \u03c1\n  b\n  t\n  \u200b\n  . Thus, this particular core imputation cannot be achieved from any optimal solution of the dual LP.\n </li>\n</ul>\n<h4>\n Leximin and Leximax Dual-Consistent Core Imputations\n</h4>\n<p>\n <strong>\n  Leximin Core Imputation\n </strong>\n :\n</p>\n<ul>\n <li>\n  <strong>\n   Leximin\n  </strong>\n  approach focuses on fairness by sorting the allocations to edges in increasing order.\n </li>\n <li>\n  An imputation is called\n  <strong>\n   leximin dual-consistent\n  </strong>\n  if it results in the lexicographically greatest sequence of allocations when sorted in increasing order. This means that among all dual-consistent core imputations, it provides the most equitable distribution when you consider the smallest values first.\n </li>\n</ul>\n<p>\n <strong>\n  Leximax Core Imputation\n </strong>\n :\n</p>\n<ul>\n <li>\n  <strong>\n   Leximax\n  </strong>\n  approach sorts allocations in decreasing order.\n </li>\n <li>\n  An imputation is termed\n  <strong>\n   leximax dual-consistent\n  </strong>\n  if it results in the lexicographically smallest sequence of allocations when sorted in decreasing order. This means it maximizes the largest allocations first among all dual-consistent core imputations.\n </li>\n</ul>\n<h3>\n Summary\n</h3>\n<ul>\n <li>\n  <strong>\n   Profit\n  </strong>\n  of an edge is determined by the product of its capacity and the dual variable in the LP.\n </li>\n <li>\n  <strong>\n   Dual-consistent core imputations\n  </strong>\n  are those that match the profits derived from optimal dual LP solutions.\n </li>\n <li>\n  Some core imputations might not be achievable through the dual LP, as illustrated by the example.\n </li>\n <li>\n  <strong>\n   Leximin\n  </strong>\n  and\n  <strong>\n   leximax\n  </strong>\n  are methods to find the most equitable or most favorable core imputations, respectively, among those consistent with the dual LP.\n </li>\n</ul>\n<p>\n Understanding these concepts helps in efficiently allocating resources in network flow problems and ensuring fair outcomes in cooperative games.\n</p>\n"}, "Page 7": {"response": "<h3>\n Simplified Explanation of Dual-Consistent Potentials and Core Imputations\n</h3>\n<h4>\n Understanding Min-Cuts and Fractional Cuts\n</h4>\n<ol>\n <li>\n  <p>\n   <strong>\n    Flow Conservation and Min-Cuts\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Flow Conservation\n    </strong>\n    : For every vertex except the source and sink in a flow network, the total capacity of incoming edges equals the total capacity of outgoing edges.\n   </li>\n   <li>\n    <strong>\n     Min-Cuts\n    </strong>\n    : A min-cut is a way of dividing the graph into two parts such that the total capacity of edges crossing the division is minimized. In this case, each cut\n    S\n    k\n    S_k\n    S\n    k\n    \u200b\n    from the algorithm corresponds to a min-cut of the original graph\n    G\n    G\n    G\n    .\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Creating a Fractional Cut\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Fractional Cut Definition\n    </strong>\n    : A fractional cut\n    C\n    P\n    Q\n    (\n    \u03f5\n    \u02c9\n    )\n    C_{PQ}(\\bar{\\epsilon})\n    C\n    PQ\n    \u200b\n    (\n    \u03f5\n    \u02c9\n    )\n    combines various min-cuts based on the potentials assigned to the vertices. The weight of this cut is computed as:\n    C\n    P\n    Q\n    (\n    \u03f5\n    \u02c9\n    )\n    =\n    (\n    \u03f5\n    \u02c9\n    (\n    v\n    1\n    )\n    \u2212\n    \u03f5\n    \u02c9\n    (\n    v\n    2\n    )\n    )\n    \u00d7\n    S\n    1\n    +\n    (\n    \u03f5\n    \u02c9\n    (\n    v\n    2\n    )\n    \u2212\n    \u03f5\n    \u02c9\n    (\n    v\n    3\n    )\n    )\n    \u00d7\n    S\n    2\n    +\n    \u22ef\n    +\n    (\n    \u03f5\n    \u02c9\n    (\n    v\n    k\n    \u2212\n    1\n    )\n    \u2212\n    \u03f5\n    \u02c9\n    (\n    v\n    k\n    )\n    )\n    \u00d7\n    S\n    k\n    \u2212\n    1\n    C_{PQ}(\\bar{\\epsilon}) = (\\bar{\\epsilon}(v_1) - \\bar{\\epsilon}(v_2)) \\times S_1 + (\\bar{\\epsilon}(v_2) - \\bar{\\epsilon}(v_3)) \\times S_2 + \\cdots + (\\bar{\\epsilon}(v_{k-1}) - \\bar{\\epsilon}(v_k)) \\times S_{k-1}\n    C\n    PQ\n    \u200b\n    (\n    \u03f5\n    \u02c9\n    )\n    =\n    (\n    \u03f5\n    \u02c9\n    (\n    v\n    1\n    \u200b\n    )\n    \u2212\n    \u03f5\n    \u02c9\n    (\n    v\n    2\n    \u200b\n    ))\n    \u00d7\n    S\n    1\n    \u200b\n    +\n    (\n    \u03f5\n    \u02c9\n    (\n    v\n    2\n    \u200b\n    )\n    \u2212\n    \u03f5\n    \u02c9\n    (\n    v\n    3\n    \u200b\n    ))\n    \u00d7\n    S\n    2\n    \u200b\n    +\n    \u22ef\n    +\n    (\n    \u03f5\n    \u02c9\n    (\n    v\n    k\n    \u2212\n    1\n    \u200b\n    )\n    \u2212\n    \u03f5\n    \u02c9\n    (\n    v\n    k\n    \u200b\n    ))\n    \u00d7\n    S\n    k\n    \u2212\n    1\n    \u200b\n   </li>\n   <li>\n    <strong>\n     Sum of Weights\n    </strong>\n    : The total weight of the fractional cut is always\n    \u03f5\n    \u02c9\n    (\n    S\n    (\n    s\n    )\n    )\n    \u2212\n    \u03f5\n    \u02c9\n    (\n    S\n    (\n    t\n    )\n    )\n    \\bar{\\epsilon}(S(s)) - \\bar{\\epsilon}(S(t))\n    \u03f5\n    \u02c9\n    (\n    S\n    (\n    s\n    ))\n    \u2212\n    \u03f5\n    \u02c9\n    (\n    S\n    (\n    t\n    ))\n    , which equals 1 in this case. This confirms that\n    C\n    P\n    Q\n    (\n    \u03f5\n    \u02c9\n    )\n    C_{PQ}(\\bar{\\epsilon})\n    C\n    PQ\n    \u200b\n    (\n    \u03f5\n    \u02c9\n    )\n    is a valid fractional min-cut of the graph.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Uniqueness of the Fractional Min-Cut\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Uniqueness\n    </strong>\n    : The fractional cut is unique because it is determined by the potentials assigned to the vertices. When there are ties in potentials, they do not affect the cut, as identical potentials do not change the structure of the cut.\n   </li>\n  </ul>\n </li>\n</ol>\n<h4>\n Dual-Consistent Potentials and Core Imputations\n</h4>\n<ol>\n <li>\n  <p>\n   <strong>\n    Defining Dual-Consistent Potentials\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Dual-Consistent Potential Function\n    </strong>\n    : A potential function\n    \u03f5\n    \u02c9\n    \\bar{\\epsilon}\n    \u03f5\n    \u02c9\n    on vertices is dual-consistent if:\n    <ol>\n     <li>\n      <strong>\n       Source\n      </strong>\n      : The potential for the source vertex\n      S\n      (\n      s\n      )\n      S(s)\n      S\n      (\n      s\n      )\n      is 1.\n     </li>\n     <li>\n      <strong>\n       Sink\n      </strong>\n      : The potential for the sink vertex\n      S\n      (\n      t\n      )\n      S(t)\n      S\n      (\n      t\n      )\n      is 0.\n     </li>\n     <li>\n      <strong>\n       Non-Decreasing\n      </strong>\n      : For any directed edge\n      (\n      i\n      ,\n      j\n      )\n      (i, j)\n      (\n      i\n      ,\n      j\n      )\n      in\n      E\n      P\n      Q\n      EPQ\n      EPQ\n      , the potential of\n      i\n      i\n      i\n      should be less than or equal to the potential of\n      j\n      j\n      j\n      (\n      \u03f5\n      \u02c9\n      (\n      i\n      )\n      \u2264\n      \u03f5\n      \u02c9\n      (\n      j\n      )\n      \\bar{\\epsilon}(i) \\leq \\bar{\\epsilon}(j)\n      \u03f5\n      \u02c9\n      (\n      i\n      )\n      \u2264\n      \u03f5\n      \u02c9\n      (\n      j\n      )\n      ).\n     </li>\n    </ol>\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Imputation Defined by Potentials\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Profit Calculation\n    </strong>\n    : The profit\n    p\n    i\n    j\n    p_{ij}\n    p\n    ij\n    \u200b\n    for an edge\n    (\n    i\n    ,\n    j\n    )\n    (i, j)\n    (\n    i\n    ,\n    j\n    )\n    is determined by the potentials of the vertices as follows:\n    p\n    i\n    j\n    =\n    c\n    i\n    j\n    \u00d7\n    \u03c1\n    i\n    j\n    p_{ij} = c_{ij} \\times \\rho_{ij}\n    p\n    ij\n    \u200b\n    =\n    c\n    ij\n    \u200b\n    \u00d7\n    \u03c1\n    ij\n    \u200b\n    where\n    \u03c1\n    i\n    j\n    =\n    \u03f5\n    \u02c9\n    (\n    S\n    (\n    i\n    )\n    )\n    \u2212\n    \u03f5\n    \u02c9\n    (\n    S\n    (\n    j\n    )\n    )\n    \\rho_{ij} = \\bar{\\epsilon}(S(i)) - \\bar{\\epsilon}(S(j))\n    \u03c1\n    ij\n    \u200b\n    =\n    \u03f5\n    \u02c9\n    (\n    S\n    (\n    i\n    ))\n    \u2212\n    \u03f5\n    \u02c9\n    (\n    S\n    (\n    j\n    ))\n    .\n   </li>\n   <li>\n    <strong>\n     Total Profit\n    </strong>\n    : This profit corresponds to the value of the fractional min-cut, which is also the maximum flow and the worth of the graph\n    G\n    G\n    G\n    .\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Core of the Max-Flow Game\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Core Imputation\n    </strong>\n    : An imputation (distribution of profits) defined by a dual-consistent potential is in the core of the max-flow game. This means it is a fair distribution that satisfies all constraints of the game.\n   </li>\n   <li>\n    <strong>\n     Feasibility\n    </strong>\n    : The imputation derived from the dual-consistent potentials is feasible and optimal, as it distributes the total worth (max-flow) of the graph.\n   </li>\n  </ul>\n </li>\n</ol>\n<h4>\n Finding Leximin and Leximax Dual-Consistent Core Imputations\n</h4>\n<ol>\n <li>\n  <p>\n   <strong>\n    Leximin Core Imputation\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Algorithm Overview\n    </strong>\n    : The algorithm for finding the leximin core imputation involves:\n    <ol>\n     <li>\n      <strong>\n       Constructing GPQ\n      </strong>\n      : Build the Picard-Queyranne graph, which preserves only essential edges.\n     </li>\n     <li>\n      <strong>\n       Assigning Potentials\n      </strong>\n      : Assign potentials greedily, starting with 1 for the source and 0 for the sink.\n     </li>\n     <li>\n      <strong>\n       Free and Fixed Vertices\n      </strong>\n      : Classify vertices as fixed (potentials assigned) and free (potentials not assigned).\n     </li>\n     <li>\n      <strong>\n       Finding Paths\n      </strong>\n      : Identify the free path with the highest potential difference and adjust potentials accordingly.\n     </li>\n    </ol>\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Leximax Core Imputation\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Leximax Core Imputation\n    </strong>\n    : Similarly, the leximax core imputation can be found by sorting and assigning potentials in a way that maximizes the smallest value in the list of profits.\n   </li>\n  </ul>\n </li>\n</ol>\n<p>\n By following these methods, we can effectively compute fair and optimal distributions of profits in the max-flow game, ensuring that the solution aligns with both dual-consistent potentials and game constraints.\n</p>\n"}, "Page 10": {"response": "<h3>\n Simplified Explanation of Leximin Imputation and Related References\n</h3>\n<h4>\n Understanding the Leximin Imputation\n</h4>\n<p>\n <strong>\n  Concept\n </strong>\n : The Leximin imputation is a method used to distribute profits in a max-flow game, aiming to be as fair as possible. Here's a simpler breakdown of how it works and why it's important:\n</p>\n<ol>\n <li>\n  <p>\n   <strong>\n    Finding the Best Path\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Free Paths\n    </strong>\n    : In the context of the algorithm, a \"free path\" is a path through the graph that can be adjusted to improve fairness in the profit distribution.\n   </li>\n   <li>\n    <strong>\n     Assigning Profits\n    </strong>\n    : When assigning profits to the edges along this path, the goal is to make the profits as uniform as possible. This means giving equal profits to all edges on the path if possible.\n   </li>\n   <li>\n    <strong>\n     Minimizing Differences\n    </strong>\n    : The algorithm chooses paths where the difference in potential between the start and end points, adjusted by the length of the path, is minimized. This helps in finding the most equitable way to distribute profits.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Why Uniform Profits Matter\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Fair Allocation\n    </strong>\n    : If one edge on the path gets a higher profit, then some other edge on the same path must get a lower profit. If you don\u2019t adjust all edges to have the same profit, the distribution is considered \"lexicographically worse\" or less fair.\n   </li>\n   <li>\n    <strong>\n     Optimal Allocation\n    </strong>\n    : By ensuring that all edges on the path have the same profit, the imputation is optimal in the Leximin sense. This means it's as fair as possible based on the least profit edges.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Proof by Induction\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    The algorithm's correctness in ensuring a leximin allocation can be proven using mathematical induction. This means showing that if the algorithm works for a smaller case, it will work for larger cases as well, thus proving that the result is indeed the leximin imputation.\n   </li>\n  </ul>\n </li>\n</ol>\n<h4>\n References for Further Reading\n</h4>\n<ol>\n <li>\n  <p>\n   <strong>\n    Fang et al. (2002)\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Title\n    </strong>\n    :\n    <em>\n     On Computational Complexity of Membership Test in Flow Games and Linear Production Games\n    </em>\n   </li>\n   <li>\n    <strong>\n     Journal\n    </strong>\n    : International Journal of Game Theory\n   </li>\n   <li>\n    <strong>\n     Summary\n    </strong>\n    : This paper discusses the complexity of determining membership in flow games and linear production games, focusing on how difficult it is to test whether a given allocation belongs to the core of these games.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Kalai and Zemel (1982)\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Title\n    </strong>\n    :\n    <em>\n     Totally Balanced Games and Games of Flow\n    </em>\n   </li>\n   <li>\n    <strong>\n     Journal\n    </strong>\n    : Mathematics of Operations Research\n   </li>\n   <li>\n    <strong>\n     Summary\n    </strong>\n    : This work explores the concept of totally balanced games, which are a broader class of games including flow games. It discusses the properties of these games and their applications.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Picard and Queyranne (1980)\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Title\n    </strong>\n    :\n    <em>\n     On the Structure of All Minimum Cuts in a Network and Applications\n    </em>\n   </li>\n   <li>\n    <strong>\n     Publisher\n    </strong>\n    : Springer Berlin Heidelberg\n   </li>\n   <li>\n    <strong>\n     Summary\n    </strong>\n    : This paper introduces the Picard-Queyranne structure for analyzing minimum cuts in networks. It provides foundational knowledge for understanding how minimum cuts are structured and used in network flow problems.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Vazirani (2023)\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Title\n    </strong>\n    :\n    <em>\n     LP-Duality Theory and the Cores of Games\n    </em>\n   </li>\n   <li>\n    <strong>\n     Preprint\n    </strong>\n    : arXiv:2302.07627\n   </li>\n   <li>\n    <strong>\n     Summary\n    </strong>\n    : This paper delves into linear programming duality theory and its connection to the cores of various games, including flow games. It provides insights into the theoretical underpinnings of core imputations.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Vazirani (2024)\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Title\n    </strong>\n    :\n    <em>\n     The Assignment Game: New Mechanisms for Equitable Core Imputations\n    </em>\n   </li>\n   <li>\n    <strong>\n     Preprint\n    </strong>\n    : arXiv:2402.11437\n   </li>\n   <li>\n    <strong>\n     Summary\n    </strong>\n    : This paper introduces new mechanisms for ensuring equitable core imputations in the assignment game, expanding the theory and practical approaches to game fairness.\n   </li>\n  </ul>\n </li>\n</ol>\n<p>\n In essence, these references provide a broad overview of theoretical and practical aspects related to flow games, core imputations, and methods for achieving fairness in profit distribution.\n</p>\n"}, "arXiv:2403.06037v1  [cs.GT]  9 Mar 2024\nThe Flow Game: Leximin and Leximax Core Imputations\nRohith R. Gangam1, Naveen Garg2, Parnian Shahkar1, and Vijay V. Vazirani1\n1University of California, Irvine\n2Indian Institute of Technology Delhi\nMarch 12, 2024\nAbstract\nRecently [Vaz24] gave mechanisms for \ufb01nding leximin and leximax core imputations for the\nassignment game and remarked, \u201cWithin the area of algorithm design, the \u201cright\u201d technique\nfor solving several types of algorithmic questions was \ufb01rst discovered in the context of matching\nand later these insights were applied to other problems. We expect a similar phenomenon here.\u201d\nOne of the games explicitly mentioned in this context was the \ufb02ow game of Kalai and Zemel\n[KZ82].\nIn this paper, we give strongly polynomial time mechanisms for computing the leximin and\nleximax core imputations for the \ufb02ow game, among the set of core imputations that are captured\nas optimal solutions to the dual LP. We address two versions:\n1. The imputations are leximin and leximax with respect to the distance labels of edges.\n2. The imputations are leximin and leximax with respect to the product of capacities of edges\nand their distance labels.\n1\nIntroduction\nMotivated by a need to \ufb01nd equitable core imputations for the assignment game, recently [Vaz24]\ngave mechanisms for \ufb01nding leximin and leximax core imputations.\nThese mechanisms run in\nstrongly polynomial time and were obtained via a suitable adaptation of the classical primal-\ndual paradigm from combinatorial optimization. [Vaz24] further remarked, \u201cWithin the area of\nalgorithm design, the \u201cright\u201d technique for solving several types of algorithmic questions was \ufb01rst\ndiscovered in the context of matching and later these insights were applied to other problems. We\nexpect a similar phenomenon here.\u201d One of the games explicitly mentioned in this context was the\n\ufb02ow game of Kalai and Zemel [KZ82].\nIn this paper, we give strongly polynomial time mechanisms for computing the leximin and\nleximax core imputations for the \ufb02ow game, among the set of core imputations that are captured\nas optimal solutions to the dual LP. We address two versions:\n1. The imputations are leximin and leximax with respect to the distance labels of edges.\n2. The imputations are leximin and leximax with respect to the product of capacities of edges\nand their distance labels.\n1\n": {"response": "\n<p>\n Linear programming (LP) is a mathematical technique used for optimizing a linear objective function, subject to a set of linear constraints. It's widely used in various fields such as economics, engineering, logistics, and operations research to find the best possible outcome from a set of linear relationships. Here\u2019s a breakdown of its key components and concepts:\n</p>\n<h3>\n Key Components of Linear Programming\n</h3>\n<ol>\n <li>\n  <p>\n   <strong>\n    Objective Function\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Definition\n    </strong>\n    : This is the function you want to maximize or minimize. It is a linear combination of decision variables.\n   </li>\n   <li>\n    <strong>\n     Example\n    </strong>\n    : In a business context, this could be maximizing profit or minimizing costs.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Decision Variables\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Definition\n    </strong>\n    : These are the variables that decision-makers will choose values for in order to achieve the best outcome.\n   </li>\n   <li>\n    <strong>\n     Example\n    </strong>\n    : In a production problem, decision variables might represent the number of units of different products to produce.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Constraints\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Definition\n    </strong>\n    : These are the linear inequalities or equations that represent the limitations or requirements of the problem.\n   </li>\n   <li>\n    <strong>\n     Example\n    </strong>\n    : Constraints could include resource limits, budget restrictions, or production capacities.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Feasible Region\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Definition\n    </strong>\n    : This is the set of all possible values for the decision variables that satisfy all constraints. It is typically represented as a polyhedron in multi-dimensional space.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Optimal Solution\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Definition\n    </strong>\n    : This is the solution within the feasible region that provides the best value for the objective function (either maximum or minimum).\n   </li>\n  </ul>\n </li>\n</ol>\n<h3>\n Basic Structure of a Linear Programming Problem\n</h3>\n<p>\n An LP problem is usually formulated in the following way:\n</p>\n<ul>\n <li>\n  <strong>\n   Maximize\n  </strong>\n  or\n  <strong>\n   Minimize\n  </strong>\n  :\n  c\n  1\n  x\n  1\n  +\n  c\n  2\n  x\n  2\n  +\n  \u22ef\n  +\n  c\n  n\n  x\n  n\n  c_1x_1 + c_2x_2 + \\cdots + c_nx_n\n  c\n  1\n  \u200b\n  x\n  1\n  \u200b\n  +\n  c\n  2\n  \u200b\n  x\n  2\n  \u200b\n  +\n  \u22ef\n  +\n  c\n  n\n  \u200b\n  x\n  n\n  \u200b\n </li>\n <li>\n  <strong>\n   Subject to\n  </strong>\n  :\n  <ul>\n   <li>\n    a\n    11\n    x\n    1\n    +\n    a\n    12\n    x\n    2\n    +\n    \u22ef\n    +\n    a\n    1\n    n\n    x\n    n\n    \u2264\n    b\n    1\n    a_{11}x_1 + a_{12}x_2 + \\cdots + a_{1n}x_n \\leq b_1\n    a\n    11\n    \u200b\n    x\n    1\n    \u200b\n    +\n    a\n    12\n    \u200b\n    x\n    2\n    \u200b\n    +\n    \u22ef\n    +\n    a\n    1\n    n\n    \u200b\n    x\n    n\n    \u200b\n    \u2264\n    b\n    1\n    \u200b\n   </li>\n   <li>\n    a\n    21\n    x\n    1\n    +\n    a\n    22\n    x\n    2\n    +\n    \u22ef\n    +\n    a\n    2\n    n\n    x\n    n\n    \u2264\n    b\n    2\n    a_{21}x_1 + a_{22}x_2 + \\cdots + a_{2n}x_n \\leq b_2\n    a\n    21\n    \u200b\n    x\n    1\n    \u200b\n    +\n    a\n    22\n    \u200b\n    x\n    2\n    \u200b\n    +\n    \u22ef\n    +\n    a\n    2\n    n\n    \u200b\n    x\n    n\n    \u200b\n    \u2264\n    b\n    2\n    \u200b\n   </li>\n   <li>\n    \u22ef\n    \\cdots\n    \u22ef\n   </li>\n   <li>\n    a\n    m\n    1\n    x\n    1\n    +\n    a\n    m\n    2\n    x\n    2\n    +\n    \u22ef\n    +\n    a\n    m\n    n\n    x\n    n\n    \u2264\n    b\n    m\n    a_{m1}x_1 + a_{m2}x_2 + \\cdots + a_{mn}x_n \\leq b_m\n    a\n    m\n    1\n    \u200b\n    x\n    1\n    \u200b\n    +\n    a\n    m\n    2\n    \u200b\n    x\n    2\n    \u200b\n    +\n    \u22ef\n    +\n    a\n    mn\n    \u200b\n    x\n    n\n    \u200b\n    \u2264\n    b\n    m\n    \u200b\n   </li>\n   <li>\n    x\n    i\n    \u2265\n    0\n    x_i \\geq 0\n    x\n    i\n    \u200b\n    \u2265\n    0\n    for all\n    i\n    i\n    i\n   </li>\n  </ul>\n </li>\n</ul>\n<h3>\n Applications of Linear Programming\n</h3>\n<ul>\n <li>\n  <strong>\n   Optimization in Business\n  </strong>\n  : Determining the best mix of products to maximize profit or minimize cost.\n </li>\n <li>\n  <strong>\n   Supply Chain Management\n  </strong>\n  : Optimizing the distribution of goods to minimize shipping costs while meeting demand.\n </li>\n <li>\n  <strong>\n   Financial Portfolio Management\n  </strong>\n  : Allocating investments to maximize return or minimize risk subject to budget constraints.\n </li>\n <li>\n  <strong>\n   Resource Allocation\n  </strong>\n  : Allocating resources such as labor and materials to different projects to achieve the best outcome.\n </li>\n</ul>\n<h3>\n Solution Methods\n</h3>\n<p>\n Several methods exist for solving linear programming problems:\n</p>\n<ol>\n <li>\n  <strong>\n   Simplex Method\n  </strong>\n  : An iterative algorithm that moves from one vertex of the feasible region to another, aiming to find the optimal vertex.\n </li>\n <li>\n  <strong>\n   Interior-Point Methods\n  </strong>\n  : Algorithms that traverse the interior of the feasible region to find the optimal solution, often used for large-scale problems.\n </li>\n <li>\n  <strong>\n   Graphical Method\n  </strong>\n  : A visual approach used for problems with two variables, where feasible regions and constraints are plotted on a graph.\n </li>\n</ol>\n<h3>\n Conclusion\n</h3>\n<p>\n Linear programming is a powerful tool for decision-making and optimization, providing clear solutions to problems involving linear relationships and constraints. Its applications span across various domains, making it a fundamental technique in operational research and economics.\n</p>\n"}}