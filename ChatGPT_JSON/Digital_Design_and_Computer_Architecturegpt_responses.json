{"Page 2": {"response": "<h3>\n About the Authors\n</h3>\n<p>\n <strong>\n  David Money Harris\n </strong>\n</p>\n<ul>\n <li>\n  Position: Associate Professor of Engineering at Harvey Mudd College.\n </li>\n <li>\n  Education: Ph.D. in Electrical Engineering from Stanford University; M.Eng. in Electrical Engineering and Computer Science from MIT.\n </li>\n <li>\n  Experience: Worked at Intel as a logic and circuit designer for Itanium and Pentium II processors. He has consulted for companies like Sun Microsystems, Hewlett-Packard, and Evans &amp; Sutherland.\n </li>\n <li>\n  Interests: Teaching, chip design, and outdoor activities like hiking, mountaineering, and rock climbing. Enjoys hiking with his son, Abraham, who was born during this book project.\n </li>\n <li>\n  Contributions: Holds about a dozen patents and has authored three textbooks on chip design and two guidebooks for Southern California mountains.\n </li>\n</ul>\n<p>\n <strong>\n  Sarah L. Harris\n </strong>\n</p>\n<ul>\n <li>\n  Position: Assistant Professor of Engineering at Harvey Mudd College.\n </li>\n <li>\n  Education: Ph.D. and M.S. in Electrical Engineering from Stanford University; B.S. in Electrical and Computer Engineering from Brigham Young University.\n </li>\n <li>\n  Experience: Worked with Hewlett-Packard, the San Diego Supercomputer Center, Nvidia, and Microsoft Research in Beijing.\n </li>\n <li>\n  Interests: Passionate about teaching, technology development, travel, wind surfing, rock climbing, and playing guitar. Recent projects include researching sketching interfaces for digital circuit design and serving as a science correspondent for NPR.\n </li>\n <li>\n  Languages: Speaks four languages and aims to learn more.\n </li>\n</ul>\n"}, "Page 3": {"response": "<h3>\n Preface\n</h3>\n<p>\n <strong>\n  Purpose of the Book\n </strong>\n :\n <br/>\n This book aims to fill a gap in existing literature on digital design and computer architecture. While there are many good resources available, this book uniquely combines digital logic design with computer architecture, guiding students from the basics of binary (1\u2019s and 0\u2019s) to designing a MIPS microprocessor.\n</p>\n<p>\n <strong>\n  Background\n </strong>\n :\n <br/>\n The authors have extensively used Patterson and Hennessy\u2019s\n <em>\n  Computer Organization and Design\n </em>\n (COD) at Harvey Mudd College. They appreciate COD's coverage of the MIPS architecture, which is both commercially successful and simple enough for introductory classes. The first half of their course focuses on digital design, a topic not fully covered in COD, responding to a broader need for combined resources in this area.\n</p>\n<p>\n <strong>\n  Educational Philosophy\n </strong>\n :\n <br/>\n The authors believe that constructing a microprocessor is an essential experience for engineering and computer science students. While the workings of a processor may seem complex, they become clear with thorough explanation. Digital design is an exciting field, and understanding assembly language reveals how processors operate. Microarchitecture serves as the connecting element.\n</p>\n<p>\n <strong>\n  Course Structure\n </strong>\n :\n <br/>\n This book is designed for a fast-paced, single-semester introduction to digital design and computer architecture, or for a longer two-quarter or two-semester course that allows for deeper understanding and lab work. The only prerequisite is a basic familiarity with a high-level programming language like C, C++, or Java. The material is typically taught to sophomores or juniors, but motivated freshmen with programming experience can also benefit.\n</p>\n"}, "Page 4": {"response": "<h3>\n Features\n</h3>\n<p>\n This book includes several special features:\n</p>\n<p>\n <strong>\n  Side-by-Side Coverage of Verilog and VHDL\n </strong>\n :\n</p>\n<ul>\n <li>\n  <strong>\n   Importance of HDLs\n  </strong>\n  : Hardware description languages (HDLs) are crucial in modern digital design. The two main languages are Verilog and VHDL, with designers evenly divided between them.\n </li>\n <li>\n  <strong>\n   Introduction\n  </strong>\n  : Chapter 4 introduces HDLs after covering combinational and sequential logic design. HDLs are then used in Chapters 5 and 7 for designing larger components and processors.\n </li>\n <li>\n  <strong>\n   Unique Presentation\n  </strong>\n  : The book presents Verilog and VHDL side by side, allowing readers to easily compare the two. Chapter 4 covers general principles and provides specific syntax examples in adjacent columns. This format makes it easier for instructors to choose either HDL and helps readers transition between them.\n </li>\n</ul>\n<p>\n <strong>\n  Classic MIPS Architecture and Microarchitecture\n </strong>\n :\n</p>\n<ul>\n <li>\n  <strong>\n   Focus on MIPS\n  </strong>\n  : Chapters 6 and 7 delve into the MIPS architecture, based on Patterson and Hennessy's work. MIPS is chosen for its real-world application and its straightforward learning curve, as it's used in millions of products and has widespread educational resources.\n </li>\n</ul>\n<p>\n <strong>\n  Real-World Perspectives\n </strong>\n :\n</p>\n<ul>\n <li>\n  <strong>\n   Intel IA-32 Processors\n  </strong>\n  : Chapters 6, 7, and 8 connect theoretical concepts to real-world applications by illustrating the architecture, microarchitecture, and memory hierarchy of Intel IA-32 processors, commonly found in most PCs.\n </li>\n</ul>\n<p>\n <strong>\n  Accessible Overview of Advanced Microarchitecture\n </strong>\n :\n</p>\n<ul>\n <li>\n  <strong>\n   Modern Features\n  </strong>\n  : Chapter 7 provides an overview of advanced microarchitectural features such as branch prediction, superscalar operations, out-of-order execution, multithreading, and multicore processors. This content is designed to be understandable for first-course students and shows how these concepts apply to modern processors.\n </li>\n</ul>\n<p>\n <strong>\n  End-of-Chapter Exercises and Interview Questions\n </strong>\n :\n</p>\n<ul>\n <li>\n  <strong>\n   Practical Learning\n  </strong>\n  : Each chapter concludes with exercises that reinforce the material. Following these exercises, there are interview questions based on inquiries from industry professionals, helping students prepare for job applications in the field.\n </li>\n</ul>\n"}, "Page 5": {"response": "<p>\n This section highlights the types of problems job applicants may face in interviews. Solutions to exercises are available online through the book's companion and instructor websites.\n</p>\n<h3>\n Online Supplements\n</h3>\n<p>\n Supplementary materials can be accessed at textbooks.elsevier.com/9780123704979. The companion site for all readers includes:\n</p>\n<ul>\n <li>\n  Solutions for odd-numbered exercises\n </li>\n <li>\n  Links to professional computer-aided design (CAD) tools from Xilinx\u00ae and Synplicity\u00ae\n </li>\n <li>\n  Access to PCSPIM, a MIPS simulator for Windows\n </li>\n <li>\n  HDL code for the MIPS processor\n </li>\n <li>\n  Helpful hints for using Xilinx Project Navigator\n </li>\n <li>\n  Lecture slides in PowerPoint format\n </li>\n <li>\n  Sample course and lab materials\n </li>\n <li>\n  A list of errors (errata)\n </li>\n</ul>\n<p>\n The instructor site, which requires registration at the same link, includes:\n</p>\n<ul>\n <li>\n  Solutions for even-numbered exercises\n </li>\n <li>\n  Access to professional CAD tools from Xilinx\u00ae and Synplicity\u00ae (instructors from qualified universities can use free Synplicity tools in their classrooms)\n </li>\n <li>\n  Figures from the text in JPG and PowerPoint formats\n </li>\n</ul>\n<p>\n Further information on using Xilinx, Synplicity, and PCSPIM tools in courses, as well as details on sample lab materials, will be provided in the next section.\n</p>\n<h3>\n Using Software Tools in a Course\n</h3>\n<p>\n <strong>\n  Xilinx ISE WebPACK\n </strong>\n :\n</p>\n<ul>\n <li>\n  This is a free version of Xilinx\u2019s professional FPGA design tools. It allows students to create digital designs using schematics or Verilog/VHDL. After inputting their designs, students can proceed with the design process.\n </li>\n</ul>\n"}, "Page 6": {"response": "<p>\n Students can simulate their circuits using\n <strong>\n  ModelSim MXE III Starter\n </strong>\n , which comes with the\n <strong>\n  Xilinx WebPACK\n </strong>\n . This package also includes\n <strong>\n  XST\n </strong>\n , a logic synthesis tool that supports both Verilog and VHDL.\n</p>\n<p>\n <strong>\n  Key Differences:\n </strong>\n</p>\n<ul>\n <li>\n  <strong>\n   WebPACK\n  </strong>\n  supports a limited range of common Xilinx FPGAs, while\n  <strong>\n   Foundation\n  </strong>\n  offers broader support.\n </li>\n <li>\n  <strong>\n   ModelSim MXE III Starter\n  </strong>\n  has reduced performance for simulations over 10,000 lines of HDL compared to commercial versions.\n </li>\n</ul>\n<h3>\n Synplify Pro\n</h3>\n<p>\n <strong>\n  Synplify Pro\u00ae\n </strong>\n is an advanced logic synthesis tool for FPGA and CPLD designs. It includes\n <strong>\n  HDL Analyst\n </strong>\n , a graphical tool that visualizes HDL source code, which is very helpful for learning and debugging. Synplicity donates Synplify Pro to qualified universities, providing as many licenses as needed for lab use. Instructors can find details on how to request licenses on the instructor web page. More information about Synplicity and its products can be found at\n <a rel=\"noopener\" style=\"--streaming-animation-state: var(--batch-play-state-1); --animation-rate: var(--batch-play-rate-1);\" target=\"_new\">\n  www\n  .synplicity\n  .com\n  /university\n </a>\n .\n</p>\n<h3>\n PCSPIM\n</h3>\n<p>\n <strong>\n  PCSPIM\n </strong>\n , or simply\n <strong>\n  SPIM\n </strong>\n , is a Windows-based simulator for running MIPS assembly code. Students can input their assembly code into a text file and execute it using PCSPIM, which shows the instructions, memory, and register values. Links to the user manual and example files are available on the companion site.\n</p>\n<h3>\n Labs\n</h3>\n<p>\n The companion site offers access to various labs that cover topics from digital design to computer architecture. These labs help students learn how to use Xilinx tools for entering, simulating, synthesizing, and implementing designs. They also cover assembly language programming with the PCSPIM simulator.\n</p>\n<p>\n After synthesis, students can implement their designs using either the\n <strong>\n  Digilent Spartan 3 Starter Board\n </strong>\n or the\n <strong>\n  XUP-Virtex 2 Pro Board\n </strong>\n . Both boards, which contain programmable FPGAs, are available from\n <a rel=\"noopener\" style=\"--streaming-animation-state: var(--batch-play-state-1); --animation-rate: var(--batch-play-rate-1);\" target=\"_new\">\n  www\n  .digilentinc\n  .com\n </a>\n . The labs provide instructions for implementing designs on the Digilent Spartan 3 Board.\n</p>\n"}, "Page 7": {"response": "<h3>\n Preface Summary\n</h3>\n<p>\n The\n <strong>\n  Xilinx WebPACK\n </strong>\n does not support the larger FPGA on the V2Pro board. Qualified universities can request a donation of the full\n <strong>\n  Foundation tools\n </strong>\n from the Xilinx University Program.\n</p>\n<p>\n To complete the labs, students must download and install\n <strong>\n  Xilinx WebPACK\n </strong>\n ,\n <strong>\n  PCSPIM\n </strong>\n , and possibly\n <strong>\n  Synplify Pro\n </strong>\n . Instructors can also install these tools on lab computers. The labs provide guidance on implementing projects on the\n <strong>\n  Digilent Spartan 3 Starter Board\n </strong>\n . While implementation can be skipped, it is highly beneficial. The labs are compatible with the\n <strong>\n  XST synthesis tool\n </strong>\n , but using Synplify Pro is recommended for its detailed schematics, which give valuable feedback to students.\n</p>\n<p>\n The labs have been tested on\n <strong>\n  Windows\n </strong>\n , but tools are also available for\n <strong>\n  Linux\n </strong>\n .\n</p>\n<h3>\n Bugs\n</h3>\n<p>\n Like any complex program, this book may contain errors despite careful review. An errata list will be maintained on the book\u2019s website. Readers are encouraged to report bugs to\n <a rel=\"noopener\" style=\"--streaming-animation-state: var(--batch-play-state-1); --animation-rate: var(--batch-play-rate-1);\">\n  ddcabugs\n  @onehotlogic\n  .com\n </a>\n . The first person to report a significant bug with a fix used in future editions will receive a $1 reward (include your mailing address).\n</p>\n<h3>\n Acknowledgments\n</h3>\n<p>\n The authors express gratitude to\n <strong>\n  David Patterson\n </strong>\n and\n <strong>\n  John Hennessy\n </strong>\n for their foundational work on MIPS microarchitectures in their textbook,\n <strong>\n  Computer Organization and Design\n </strong>\n . Their support and permission to build on their work have been invaluable.\n</p>\n<p>\n Thanks are also given to\n <strong>\n  Duane Bibby\n </strong>\n for his illustrations, and to the team at\n <strong>\n  Morgan Kaufmann\n </strong>\n for their enthusiasm and support in producing the book.\n <strong>\n  Jeff Somers\n </strong>\n at\n <strong>\n  Graphic World Publishing Services\n </strong>\n has guided the book through its production.\n</p>\n<p>\n Numerous reviewers have helped improve the book, including individuals from various academic and industry backgrounds.\n</p>\n"}, "Page 8": {"response": "<h3>\n Acknowledgments Summary\n</h3>\n<p>\n The authors extend their gratitude to several reviewers for their contributions, including individuals from various universities and organizations such as\n <strong>\n  ShotSpotter, Inc.\n </strong>\n and\n <strong>\n  Claremont McKenna College\n </strong>\n . Special thanks to\n <strong>\n  Simon Moore\n </strong>\n for hosting David during his sabbatical at\n <strong>\n  Cambridge University\n </strong>\n , where significant parts of the book were written.\n</p>\n<p>\n They also appreciate the students at\n <strong>\n  Harvey Mudd College\n </strong>\n who provided valuable feedback on the textbook drafts, particularly\n <strong>\n  Casey Schilling\n </strong>\n ,\n <strong>\n  Alice Clifton\n </strong>\n ,\n <strong>\n  Chris Acon\n </strong>\n , and\n <strong>\n  Stephen Brawner\n </strong>\n .\n</p>\n<p>\n David specifically thanks his wife,\n <strong>\n  Jennifer\n </strong>\n , for her patience and support, especially as they welcomed their son\n <strong>\n  Abraham\n </strong>\n at the start of this project.\n</p>\n"}, "Page 9": {"response": "<h3>\n Chapter Overview\n</h3>\n<h4>\n 1.1 The Game Plan\n</h4>\n<p>\n Microprocessors have dramatically changed our world in the last 30 years. Today's laptops are far more powerful than older mainframes that took up entire rooms. Modern luxury cars have around 50 microprocessors. These advances have enabled technologies like cell phones and the Internet, improved medicine, and changed warfare. The global semiconductor industry saw sales rise from\n <strong>\n  $21 billion in 1985\n </strong>\n to\n <strong>\n  $227 billion in 2005\n </strong>\n , with microprocessors being a significant part of this growth.\n</p>\n<p>\n Microprocessors are not just important for technology, economy, and society; they are also fascinating inventions. By the end of this book, you will know how to design and build your own microprocessor. The skills you'll acquire will also help you in designing various digital systems.\n</p>\n<p>\n This book assumes you have a basic understanding of electricity, some programming experience, and a desire to learn about computer internals. The focus is on digital systems that use binary (1\u2019s and 0\u2019s). We'll start with digital logic gates that take binary inputs and produce binary outputs. From there, we\u2019ll learn how to combine these gates into complex components like adders and memory units. We will then delve into assembly language programming, the microprocessor's native language. Finally, you'll use these gates to construct a functioning microprocessor capable of running assembly programs.\n</p>\n<p>\n The beauty of digital systems lies in their simplicity: they only use 1\u2019s and 0\u2019s. This means they don't require complex math or advanced physics knowledge. Instead, the challenge is to combine these basic elements into intricate systems, such as microprocessors, which can be quite complex.\n</p>\n"}, "Page 10": {"response": "<h3>\n 1.2 The Art of Managing Complexity\n</h3>\n<p>\n Engineers and computer scientists have a unique ability to manage complexity, which sets them apart from non-experts. Modern digital systems consist of millions or even billions of transistors, making it impossible to understand them by solving equations for every single transistor. Instead, you\u2019ll need to learn to manage this complexity to effectively build a microprocessor without getting lost in overwhelming details.\n</p>\n<h4>\n 1.2.1 Abstraction\n</h4>\n<p>\n Abstraction is a key technique for handling complexity. It involves hiding unnecessary details and focusing on what matters. Different levels of abstraction allow you to view a system in various ways. For example, politicians often think of regions as cities, counties, states, and countries. When running for president, they care more about state-wide voting trends than the specifics of each county.\n</p>\n<p>\n In the context of electronic computer systems, there are several levels of abstraction (see Figure 1.1):\n</p>\n<ol>\n <li>\n  <strong>\n   Physics\n  </strong>\n  : At the lowest level, you deal with the motion of electrons, described by quantum mechanics.\n </li>\n <li>\n  <strong>\n   Devices\n  </strong>\n  : This level includes electronic components like transistors, which can be modeled by their voltage and current relationships at specific terminals.\n </li>\n <li>\n  <strong>\n   Analog Circuits\n  </strong>\n  : Here, devices are combined to create components like amplifiers that handle a continuous range of voltages.\n </li>\n <li>\n  <strong>\n   Digital Circuits\n  </strong>\n  : In this layer, circuits use discrete voltage levels to represent binary values (0s and 1s), forming the basis for logic gates.\n </li>\n <li>\n  <strong>\n   Logic Design\n  </strong>\n  : This involves creating complex structures like adders and memory from digital circuits.\n </li>\n <li>\n  <strong>\n   Microarchitecture\n  </strong>\n  : This links the logic and architectural levels, defining how components work together.\n </li>\n <li>\n  <strong>\n   Architecture\n  </strong>\n  : This level describes a computer from the programmer\u2019s perspective, such as the Intel IA-32 architecture used in most personal computers, which is defined by a set of instructions and registers.\n </li>\n</ol>\n<p>\n Understanding these levels of abstraction helps simplify the complexity inherent in building digital systems.\n</p>\n"}, "Page 11": {"response": "<p>\n Microarchitecture combines various logic elements to carry out the instructions defined by a computer's architecture, which includes instructions and registers for temporary variable storage. Different microarchitectures can implement the same architecture with varying trade-offs in cost, performance, and power consumption. For example, the Intel Core 2 Duo, Intel 80486, and AMD Athlon all use the IA-32 architecture but differ in their microarchitectural designs.\n</p>\n<p>\n The operating system manages low-level tasks, like accessing hard drives and memory, while application software uses these operating system features to solve user problems. Thanks to abstraction, users can perform tasks like browsing the Web without needing to understand the intricate details of electron behavior or memory organization.\n</p>\n<p>\n This book emphasizes understanding the various abstraction levels, from digital circuits to computer architecture. It's important to know the levels above and below your current focus. For instance, a computer scientist needs to understand the architecture to optimize code effectively, while a device engineer should be familiar with circuit design to make informed transistor design decisions. By the end of this book, you'll be able to select the appropriate level of abstraction for your problems and assess how your design choices affect other levels.\n</p>\n<h3>\n 1.2.2 Discipline\n</h3>\n<p>\n Discipline involves intentionally limiting your design options to work more effectively at a higher abstraction level. A well-known example of this is the use of interchangeable parts in manufacturing. Before the 19th century, rifles were made individually by skilled craftsmen, who hand-fitted each component. The introduction of interchangeable parts standardized components, allowing for faster assembly and repairs without needing specialized skills. This shift meant that craftsmen no longer had to worry about the specific details of individual parts.\n</p>\n<p>\n In this book, the concept of digital discipline is crucial. Digital circuits, which use discrete voltages, are simpler to design than analog circuits, which use continuous voltages. Although digital circuits can achieve less than their analog counterparts, their simplicity and ease of use make them effective for many applications.\n</p>\n"}, "Page 12": {"response": "<p>\n By focusing on digital circuits, we can easily combine components to create advanced systems that often outperform those made from analog parts. This shift is evident in technologies like digital televisions, compact discs (CDs), and cell phones, which have largely replaced their analog versions.\n</p>\n<h3>\n 1.2.3 The Three \"-Y's\"\n</h3>\n<p>\n In addition to abstraction and discipline, designers use three key principles to manage complexity: hierarchy, modularity, and regularity. These principles are applicable in both software and hardware development.\n</p>\n<ul>\n <li>\n  <p>\n   <strong>\n    Hierarchy\n   </strong>\n   means breaking a system down into smaller modules and further subdividing those modules until they are manageable and understandable.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Modularity\n   </strong>\n   states that each module should have clear functions and interfaces, allowing them to connect easily without unexpected issues.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Regularity\n   </strong>\n   aims for consistency among modules. By reusing common modules, designers can minimize the variety of distinct modules needed.\n  </p>\n </li>\n</ul>\n<p>\n To illustrate these concepts, let's return to the example of rifle manufacturing. A flintlock rifle, a complex object of the early 19th century, can be divided into key components: the lock, stock, and barrel.\n</p>\n<ul>\n <li>\n  The\n  <strong>\n   barrel\n  </strong>\n  is the metal tube that fires the bullet.\n </li>\n <li>\n  The\n  <strong>\n   lock\n  </strong>\n  is the mechanism that triggers the shot.\n </li>\n <li>\n  The\n  <strong>\n   stock\n  </strong>\n  is the wooden part that holds everything together and provides a grip.\n </li>\n</ul>\n<p>\n Each of these components can be described in more detail using hierarchy. For instance, the lock includes the trigger, hammer, flint, frizzen, and pan.\n</p>\n<p>\n <strong>\n  Modularity\n </strong>\n ensures that each part has a specific role. For example, the stock's function is to support the barrel and lock, and it connects to these parts through defined dimensions and mounting points. Different stocks can fit the same barrel, as long as they match in size and mounting style.\n</p>\n<p>\n <strong>\n  Regularity\n </strong>\n emphasizes the benefits of interchangeable parts. If a barrel gets damaged, it can be easily replaced with a standard part, which can be mass-produced rather than individually crafted.\n</p>\n<p>\n These principles of hierarchy, modularity, and regularity will be revisited throughout the book.\n</p>\n<p>\n Captain Meriwether Lewis, from the Lewis and Clark Expedition, highlighted the importance of interchangeable parts for rifles in 1806. He noted that having extra parts on hand, like locks and screws, was crucial for maintaining their guns in good working order during the expedition.\n</p>\n"}, "Page 13": {"response": "<h3>\n 1.3 The Digital Abstraction\n</h3>\n<p>\n Most physical variables, like voltage, frequency, or position, are continuous, meaning they can take on any value within a range. In contrast, digital systems use discrete values, which means they represent information with a limited number of distinct values.\n</p>\n<p>\n One of the earliest digital systems was Charles Babbage's Analytical Engine, which he worked on from 1834 to 1871. This mechanical computer was designed to use ten discrete values, represented by gears that had ten positions labeled from 0 to 9, similar to a car\u2019s mechanical odometer.\n</p>\n<p>\n Babbage\u2019s contributions are significant in the history of computing. He was born in 1791, studied at Cambridge University, and married Georgiana Whitmore in 1814. Aside from the Analytical Engine, he also invented the cowcatcher (a device on trains) and proposed a universal postage rate. He had interests ranging from lock-picking to a dislike for street musicians.\n</p>\n"}, "Page 14": {"response": "<p>\n Babbage's Analytical Engine was designed to process one digit per row, using 25 rows of gears for a total precision of 25 digits. Unlike this machine, most electronic computers use a binary system, which represents information with just two values: a high voltage for \u20181\u2019 and a low voltage for \u20180.\u2019 This binary representation is easier to work with than ten distinct voltages.\n</p>\n<p>\n The amount of information\n D\n D\n D\n in a discrete variable with\n N\n N\n N\n states is calculated in bits using the formula:\n</p>\n<p>\n D\n =\n log\n \u2061\n 2\n N\n bits\n D = \\log_2 N \\, \\text{bits}\n D\n =\n lo\n g\n 2\n \u200b\n N\n bits\n</p>\n<p>\n For example, a binary variable conveys\n log\n \u2061\n 2\n 2\n =\n 1\n \\log_2 2 = 1\n lo\n g\n 2\n \u200b\n 2\n =\n 1\n bit of information. Each of Babbage\u2019s gears provided\n log\n \u2061\n 2\n 10\n \u2248\n 3.322\n \\log_2 10 \\approx 3.322\n lo\n g\n 2\n \u200b\n 10\n \u2248\n 3.322\n bits of information because it could be in one of about 10 different positions. Continuous signals can theoretically have infinite information since they can take on countless values, but in practice, noise limits this to about 10 to 16 bits for most signals. If measurements need to be taken quickly, the information can drop to around 8 bits.\n</p>\n<p>\n This book will focus on digital circuits using binary variables\u20141\u2019s and 0\u2019s. George Boole developed Boolean logic, where each variable can be TRUE or FALSE. In electronic computers, a positive voltage represents \u20181\u2019 and zero volts represent \u20180\u2019. In this text, we will use \u20181,\u2019 TRUE, and HIGH as synonyms, and \u20180,\u2019 FALSE, and LOW interchangeably.\n</p>\n<p>\n The advantage of the digital abstraction is that designers can concentrate on 1\u2019s and 0\u2019s without worrying about how these values are physically represented\u2014whether through voltages, gears, or hydraulic systems.\n</p>\n"}, "Page 15": {"response": "<p>\n Understanding computer systems requires some knowledge of both hardware and software. A programmer can create software without knowing all the details of the hardware, but knowing how the hardware works can help them optimize the software for better performance.\n</p>\n<p>\n A single bit (the smallest unit of data) doesn\u2019t hold much information on its own. In this section, we will explore how groups of bits can represent numbers and later how they can represent letters and programs.\n</p>\n<h3>\n 1.4 NUMBER SYSTEMS\n</h3>\n<p>\n You\u2019re familiar with decimal numbers, but in digital systems, binary and hexadecimal numbers are often more practical. This section will introduce the different number systems used throughout the book.\n</p>\n<h4>\n 1.4.1 Decimal Numbers\n</h4>\n<p>\n In school, you learned to count using the decimal system, which has ten digits: 0, 1, 2, ..., 9. These digits can be combined to create larger numbers. Each column in a decimal number is worth ten times more than the column to its right. From right to left, the column values are 1, 10, 100, 1000, etc. Decimal numbers are called base 10. To avoid confusion when using different bases, we write the base as a subscript after the number. For example, the decimal number 9742 can be expressed as:\n</p>\n<p>\n 974\n 2\n 10\n =\n 9\n \u00d7\n 1\n 0\n 3\n +\n 7\n \u00d7\n 1\n 0\n 2\n +\n 4\n \u00d7\n 1\n 0\n 1\n +\n 2\n \u00d7\n 1\n 0\n 0\n 9742_{10} = 9 \\times 10^3 + 7 \\times 10^2 + 4 \\times 10^1 + 2 \\times 10^0\n 974\n 2\n 10\n \u200b\n =\n 9\n \u00d7\n 1\n 0\n 3\n +\n 7\n \u00d7\n 1\n 0\n 2\n +\n 4\n \u00d7\n 1\n 0\n 1\n +\n 2\n \u00d7\n 1\n 0\n 0\n</p>\n<p>\n In this example, 9 is in the thousands column, 7 in the hundreds column, 4 in the tens column, and 2 in the ones column. An N-digit decimal number can represent one of\n 1\n 0\n N\n 10^N\n 1\n 0\n N\n possibilities. For instance, a three-digit decimal number can represent numbers from 0 to 999, giving it 1000 possible values.\n</p>\n<h4>\n 1.4.2 Binary Numbers\n</h4>\n<p>\n In binary, bits can hold one of two values: 0 or 1. These bits are combined to form binary numbers. Each column in a binary number is worth twice as much as the column to its right.\n</p>\n"}, "Page 16": {"response": "<p>\n In binary, each bit can be either 0 or 1, and binary numbers are based on powers of 2. The weights of the columns in binary, from right to left, are 1, 2, 4, 8, 16, 32, 64, 128, and so on. If you often work with binary, it\u2019s helpful to remember these powers of two up to\n 2\n 16\n 2^{16}\n 2\n 16\n .\n</p>\n<p>\n An N-bit binary number can represent\n 2\n N\n 2^N\n 2\n N\n different values, ranging from 0 to\n 2\n N\n \u2212\n 1\n 2^N - 1\n 2\n N\n \u2212\n 1\n . For example, a 4-bit binary number can represent 16 different values (0 to 15).\n</p>\n<p>\n <strong>\n  Example: Binary to Decimal Conversion\n </strong>\n <br/>\n To convert the binary number 10110 to decimal, follow this process:\n</p>\n<ol>\n <li>\n  <p>\n   Break down the binary number by its column weights:\n  </p>\n  <ul>\n   <li>\n    1\n    \u00d7\n    2\n    4\n    1 \\times 2^4\n    1\n    \u00d7\n    2\n    4\n    (16)\n   </li>\n   <li>\n    0\n    \u00d7\n    2\n    3\n    0 \\times 2^3\n    0\n    \u00d7\n    2\n    3\n    (0)\n   </li>\n   <li>\n    1\n    \u00d7\n    2\n    2\n    1 \\times 2^2\n    1\n    \u00d7\n    2\n    2\n    (4)\n   </li>\n   <li>\n    1\n    \u00d7\n    2\n    1\n    1 \\times 2^1\n    1\n    \u00d7\n    2\n    1\n    (2)\n   </li>\n   <li>\n    0\n    \u00d7\n    2\n    0\n    0 \\times 2^0\n    0\n    \u00d7\n    2\n    0\n    (0)\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   Add the values together:\n   <br/>\n   16\n   +\n   0\n   +\n   4\n   +\n   2\n   +\n   0\n   =\n   22\n   16 + 0 + 4 + 2 + 0 = 22\n   16\n   +\n   0\n   +\n   4\n   +\n   2\n   +\n   0\n   =\n   22\n  </p>\n </li>\n</ol>\n<p>\n So, 10110 in binary equals 22 in decimal.\n</p>\n<p>\n <strong>\n  Table 1.1\n </strong>\n provides a quick reference of 1 to 4-bit binary numbers alongside their decimal equivalents:\n</p>\n<ul>\n <li>\n  <p>\n   <strong>\n    1-Bit:\n   </strong>\n  </p>\n  <ul>\n   <li>\n    0 \u2192 0\n   </li>\n   <li>\n    1 \u2192 1\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    2-Bit:\n   </strong>\n  </p>\n  <ul>\n   <li>\n    00 \u2192 0\n   </li>\n   <li>\n    01 \u2192 1\n   </li>\n   <li>\n    10 \u2192 2\n   </li>\n   <li>\n    11 \u2192 3\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    3-Bit:\n   </strong>\n  </p>\n  <ul>\n   <li>\n    000 \u2192 0\n   </li>\n   <li>\n    001 \u2192 1\n   </li>\n   <li>\n    010 \u2192 2\n   </li>\n   <li>\n    011 \u2192 3\n   </li>\n   <li>\n    100 \u2192 4\n   </li>\n   <li>\n    101 \u2192 5\n   </li>\n   <li>\n    110 \u2192 6\n   </li>\n   <li>\n    111 \u2192 7\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    4-Bit:\n   </strong>\n  </p>\n  <ul>\n   <li>\n    0000 \u2192 0\n   </li>\n   <li>\n    0001 \u2192 1\n   </li>\n   <li>\n    0010 \u2192 2\n   </li>\n   <li>\n    0011 \u2192 3\n   </li>\n   <li>\n    0100 \u2192 4\n   </li>\n   <li>\n    0101 \u2192 5\n   </li>\n   <li>\n    0110 \u2192 6\n   </li>\n   <li>\n    0111 \u2192 7\n   </li>\n   <li>\n    1000 \u2192 8\n   </li>\n   <li>\n    1001 \u2192 9\n   </li>\n   <li>\n    1010 \u2192 10\n   </li>\n   <li>\n    1011 \u2192 11\n   </li>\n   <li>\n    1100 \u2192 12\n   </li>\n   <li>\n    1101 \u2192 13\n   </li>\n   <li>\n    1110 \u2192 14\n   </li>\n   <li>\n    1111 \u2192 15\n   </li>\n  </ul>\n </li>\n</ul>\n"}, "Page 17": {"response": "<h3>\n Example 1.2: Decimal to Binary Conversion\n</h3>\n<p>\n To convert the decimal number 84 to binary, you can determine if each column in the binary result has a 1 or a 0. You can start from either the left or right.\n</p>\n<p>\n <strong>\n  Left-to-Right Method:\n </strong>\n</p>\n<ol>\n <li>\n  Start with the largest power of 2 less than 84, which is 64. Since\n  84\n  \u2212\n  64\n  =\n  20\n  84 - 64 = 20\n  84\n  \u2212\n  64\n  =\n  20\n  , put a 1 in the 64's column.\n </li>\n <li>\n  The next power of 2 is 32, but 20 is less than 32, so put a 0 in the 32's column.\n </li>\n <li>\n  The next power is 16. Since\n  20\n  \u2212\n  16\n  =\n  4\n  20 - 16 = 4\n  20\n  \u2212\n  16\n  =\n  4\n  , put a 1 in the 16's column.\n </li>\n <li>\n  The next power is 8, but 4 is less than 8, so put a 0 in the 8's column.\n </li>\n <li>\n  Since\n  4\n  \u2212\n  4\n  =\n  0\n  4 - 4 = 0\n  4\n  \u2212\n  4\n  =\n  0\n  , put a 1 in the 4's column.\n </li>\n <li>\n  The 2's and 1's columns will both be 0 since we have 0 left.\n </li>\n</ol>\n<p>\n Putting it all together,\n 8\n 4\n 10\n =\n 101010\n 0\n 2\n 84_{10} = 1010100_2\n 8\n 4\n 10\n \u200b\n =\n 101010\n 0\n 2\n \u200b\n .\n</p>\n<p>\n <strong>\n  Right-to-Left Method:\n </strong>\n</p>\n<ol>\n <li>\n  Divide the number by 2 repeatedly and record the remainder:\n  <ul>\n   <li>\n    84\n    /\n    2\n    =\n    42\n    84 / 2 = 42\n    84/2\n    =\n    42\n    \u2192 remainder 0 (1's column)\n   </li>\n   <li>\n    42\n    /\n    2\n    =\n    21\n    42 / 2 = 21\n    42/2\n    =\n    21\n    \u2192 remainder 0 (2's column)\n   </li>\n   <li>\n    21\n    /\n    2\n    =\n    10\n    21 / 2 = 10\n    21/2\n    =\n    10\n    \u2192 remainder 1 (4's column)\n   </li>\n   <li>\n    10\n    /\n    2\n    =\n    5\n    10 / 2 = 5\n    10/2\n    =\n    5\n    \u2192 remainder 0 (8's column)\n   </li>\n   <li>\n    5\n    /\n    2\n    =\n    2\n    5 / 2 = 2\n    5/2\n    =\n    2\n    \u2192 remainder 1 (16's column)\n   </li>\n   <li>\n    2\n    /\n    2\n    =\n    1\n    2 / 2 = 1\n    2/2\n    =\n    1\n    \u2192 remainder 0 (32's column)\n   </li>\n   <li>\n    1\n    /\n    2\n    =\n    0\n    1 / 2 = 0\n    1/2\n    =\n    0\n    \u2192 remainder 1 (64's column)\n   </li>\n  </ul>\n </li>\n</ol>\n<p>\n Thus, again,\n 8\n 4\n 10\n =\n 101010\n 0\n 2\n 84_{10} = 1010100_2\n 8\n 4\n 10\n \u200b\n =\n 101010\n 0\n 2\n \u200b\n .\n</p>\n<h3>\n 1.4.3 Hexadecimal Numbers\n</h3>\n<p>\n Using long binary numbers can be tedious and error-prone. Instead, hexadecimal (base 16) is often used, which simplifies things because a group of four bits can represent one of 16 values. Hexadecimal uses digits 0-9 and letters A-F, as shown in Table 1.2. In base 16, the weights of the columns are 1, 16, 256, 4096, and so on.\n</p>\n<h3>\n Example 1.3: Hexadecimal to Binary and Decimal Conversion\n</h3>\n<p>\n To convert the hexadecimal number 2ED\u2081\u2086 to binary and decimal:\n</p>\n<p>\n <strong>\n  Hexadecimal to Binary:\n </strong>\n Each hex digit corresponds directly to four binary digits:\n</p>\n<ul>\n <li>\n  2\u2081\u2086 = 0010\u2082\n </li>\n <li>\n  E\u2081\u2086 = 1110\u2082\n </li>\n <li>\n  D\u2081\u2086 = 1101\u2082\n </li>\n</ul>\n<p>\n So, 2ED\u2081\u2086 = 001011101101\u2082.\n</p>\n<p>\n <strong>\n  Hexadecimal to Decimal:\n </strong>\n To convert 2ED\u2081\u2086 to decimal, calculate as follows:\n</p>\n<ul>\n <li>\n  2\n  \u00d7\n  1\n  6\n  2\n  +\n  E\n  \u00d7\n  1\n  6\n  1\n  +\n  D\n  \u00d7\n  1\n  6\n  0\n  2 \\times 16^2 + E \\times 16^1 + D \\times 16^0\n  2\n  \u00d7\n  1\n  6\n  2\n  +\n  E\n  \u00d7\n  1\n  6\n  1\n  +\n  D\n  \u00d7\n  1\n  6\n  0\n </li>\n <li>\n  =\n  2\n  \u00d7\n  256\n  +\n  14\n  \u00d7\n  16\n  +\n  13\n  \u00d7\n  1\n  = 2 \\times 256 + 14 \\times 16 + 13 \\times 1\n  =\n  2\n  \u00d7\n  256\n  +\n  14\n  \u00d7\n  16\n  +\n  13\n  \u00d7\n  1\n </li>\n <li>\n  =\n  512\n  +\n  224\n  +\n  13\n  =\n  74\n  9\n  10\n  = 512 + 224 + 13 = 749_{10}\n  =\n  512\n  +\n  224\n  +\n  13\n  =\n  74\n  9\n  10\n  \u200b\n  .\n </li>\n</ul>\n<p>\n Thus, 2ED\u2081\u2086 = 001011101101\u2082 and 749\u2081\u2080.\n</p>\n"}, "Page 18": {"response": "<h3>\n Example 1.4: Binary to Hexadecimal Conversion\n</h3>\n<p>\n To convert the binary number 11110100\u2082 to hexadecimal:\n</p>\n<ol>\n <li>\n  <strong>\n   Start from the Right:\n  </strong>\n  Read the binary number in groups of four bits from the right.\n </li>\n <li>\n  The four least significant bits (rightmost) are 0100, which equals 4 in decimal.\n </li>\n <li>\n  The next four bits (to the left) are 111, which equals 7 in decimal.\n </li>\n <li>\n  The final result combines these two values, with the first group representing the higher place value.\n </li>\n</ol>\n<p>\n Thus, the binary number 11110100\u2082 converts to hexadecimal as 7A\u2081\u2086.\n</p>\n<h3>\n Table 1.2: Hexadecimal Number System\n</h3>\n<p>\n Here\u2019s how the hexadecimal digits correspond to their decimal and binary equivalents:\n</p>\n<table>\n <thead>\n  <tr>\n   <th>\n    Hexadecimal Digit\n   </th>\n   <th>\n    Decimal Equivalent\n   </th>\n   <th>\n    Binary Equivalent\n   </th>\n  </tr>\n </thead>\n <tbody>\n  <tr>\n   <td>\n    0\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    0000\n   </td>\n  </tr>\n  <tr>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    0001\n   </td>\n  </tr>\n  <tr>\n   <td>\n    2\n   </td>\n   <td>\n    2\n   </td>\n   <td>\n    0010\n   </td>\n  </tr>\n  <tr>\n   <td>\n    3\n   </td>\n   <td>\n    3\n   </td>\n   <td>\n    0011\n   </td>\n  </tr>\n  <tr>\n   <td>\n    4\n   </td>\n   <td>\n    4\n   </td>\n   <td>\n    0100\n   </td>\n  </tr>\n  <tr>\n   <td>\n    5\n   </td>\n   <td>\n    5\n   </td>\n   <td>\n    0101\n   </td>\n  </tr>\n  <tr>\n   <td>\n    6\n   </td>\n   <td>\n    6\n   </td>\n   <td>\n    0110\n   </td>\n  </tr>\n  <tr>\n   <td>\n    7\n   </td>\n   <td>\n    7\n   </td>\n   <td>\n    0111\n   </td>\n  </tr>\n  <tr>\n   <td>\n    8\n   </td>\n   <td>\n    8\n   </td>\n   <td>\n    1000\n   </td>\n  </tr>\n  <tr>\n   <td>\n    9\n   </td>\n   <td>\n    9\n   </td>\n   <td>\n    1001\n   </td>\n  </tr>\n  <tr>\n   <td>\n    A\n   </td>\n   <td>\n    10\n   </td>\n   <td>\n    1010\n   </td>\n  </tr>\n  <tr>\n   <td>\n    B\n   </td>\n   <td>\n    11\n   </td>\n   <td>\n    1011\n   </td>\n  </tr>\n  <tr>\n   <td>\n    C\n   </td>\n   <td>\n    12\n   </td>\n   <td>\n    1100\n   </td>\n  </tr>\n  <tr>\n   <td>\n    D\n   </td>\n   <td>\n    13\n   </td>\n   <td>\n    1101\n   </td>\n  </tr>\n  <tr>\n   <td>\n    E\n   </td>\n   <td>\n    14\n   </td>\n   <td>\n    1110\n   </td>\n  </tr>\n  <tr>\n   <td>\n    F\n   </td>\n   <td>\n    15\n   </td>\n   <td>\n    1111\n   </td>\n  </tr>\n </tbody>\n</table>\n<h3>\n Conversion Example: Hexadecimal to Decimal\n</h3>\n<p>\n For further clarity, the earlier example of 2ED\u2081\u2086 converts to decimal as follows:\n</p>\n<ul>\n <li>\n  2\n  \u00d7\n  1\n  6\n  2\n  +\n  E\n  \u00d7\n  1\n  6\n  1\n  +\n  D\n  \u00d7\n  1\n  6\n  0\n  2 \\times 16^2 + E \\times 16^1 + D \\times 16^0\n  2\n  \u00d7\n  1\n  6\n  2\n  +\n  E\n  \u00d7\n  1\n  6\n  1\n  +\n  D\n  \u00d7\n  1\n  6\n  0\n </li>\n <li>\n  This calculates to\n  2\n  \u00d7\n  256\n  +\n  14\n  \u00d7\n  16\n  +\n  13\n  \u00d7\n  1\n  =\n  74\n  9\n  10\n  2 \\times 256 + 14 \\times 16 + 13 \\times 1 = 749_{10}\n  2\n  \u00d7\n  256\n  +\n  14\n  \u00d7\n  16\n  +\n  13\n  \u00d7\n  1\n  =\n  74\n  9\n  10\n  \u200b\n  .\n </li>\n</ul>\n<p>\n This demonstrates how hexadecimal numbers relate to both binary and decimal systems.\n</p>\n"}, "Page 19": {"response": "<h3>\n Example 1.5: Decimal to Hexadecimal and Binary Conversion\n</h3>\n<p>\n To convert the decimal number 333\u2081\u2080 into hexadecimal and binary:\n</p>\n<ol>\n <li>\n  <p>\n   <strong>\n    Conversion from Left to Right:\n   </strong>\n  </p>\n  <ul>\n   <li>\n    Start with the largest power of 16 less than 333, which is 256.\n   </li>\n   <li>\n    256 fits into 333 once, so put a 1 in the 256's column. Subtracting gives\n    333\n    \u2212\n    256\n    =\n    77\n    333 - 256 = 77\n    333\n    \u2212\n    256\n    =\n    77\n    .\n   </li>\n   <li>\n    Next, see how many times 16 fits into 77, which is 4 times, so put a 4 in the 16's column. Subtracting gives\n    77\n    \u2212\n    64\n    =\n    13\n    77 - 64 = 13\n    77\n    \u2212\n    64\n    =\n    13\n    .\n   </li>\n   <li>\n    Finally, 13 in decimal is represented by D in hexadecimal. So, in summary,\n    33\n    3\n    10\n    =\n    14\n    D\n    16\n    333\u2081\u2080 = 14D\u2081\u2086\n    33\n    3\n    10\n    \u200b\n    =\n    14\n    D\n    16\n    \u200b\n    .\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Conversion to Binary:\n   </strong>\n  </p>\n  <ul>\n   <li>\n    From the hexadecimal 14D\u2081\u2086, convert each digit to binary:\n    <ul>\n     <li>\n      1 = 0001\n     </li>\n     <li>\n      4 = 0100\n     </li>\n     <li>\n      D = 1101\n     </li>\n    </ul>\n   </li>\n   <li>\n    Therefore,\n    14\n    D\n    16\n    =\n    10100110\n    1\n    2\n    14D\u2081\u2086 = 101001101\u2082\n    14\n    D\n    16\n    \u200b\n    =\n    10100110\n    1\n    2\n    \u200b\n    .\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Conversion from Right to Left:\n   </strong>\n  </p>\n  <ul>\n   <li>\n    Divide 333 by 16 repeatedly, keeping track of the remainders:\n    <ul>\n     <li>\n      333\n      \u00f7\n      16\n      =\n      20\n      333 \u00f7 16 = 20\n      333\n      \u00f7\n      16\n      =\n      20\n      remainder 13 (D).\n     </li>\n     <li>\n      20\n      \u00f7\n      16\n      =\n      1\n      20 \u00f7 16 = 1\n      20\n      \u00f7\n      16\n      =\n      1\n      remainder 4.\n     </li>\n     <li>\n      1\n      \u00f7\n      16\n      =\n      0\n      1 \u00f7 16 = 0\n      1\n      \u00f7\n      16\n      =\n      0\n      remainder 1.\n     </li>\n    </ul>\n   </li>\n   <li>\n    This gives the same result:\n    14\n    D\n    16\n    14D\u2081\u2086\n    14\n    D\n    16\n    \u200b\n    .\n   </li>\n  </ul>\n </li>\n</ol>\n<h3>\n Bytes, Nibbles, and Data Sizes\n</h3>\n<ul>\n <li>\n  <p>\n   <strong>\n    Byte:\n   </strong>\n   A group of 8 bits, representing 256 possible values (2\u2078). Memory sizes are usually measured in bytes.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Nibble:\n   </strong>\n   A group of 4 bits (half a byte), representing 16 possible values (2\u2074). One hexadecimal digit corresponds to one nibble, and two hexadecimal digits make a full byte. Although \"nibble\" is a playful term, it's not commonly used today.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Word:\n   </strong>\n   Microprocessors process data in chunks called words, which vary in size depending on the architecture. In 2006, most computers operated with 32-bit words, while 64-bit processors were becoming common. Simpler devices, like toasters, might use 8- or 16-bit words.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Significance of Bits:\n   </strong>\n  </p>\n  <ul>\n   <li>\n    The\n    <strong>\n     least significant bit (LSB)\n    </strong>\n    is the rightmost bit, and the\n    <strong>\n     most significant bit (MSB)\n    </strong>\n    is the leftmost.\n   </li>\n   <li>\n    In a word, bytes are identified similarly, from least significant byte (LSB) to most significant byte (MSB).\n   </li>\n  </ul>\n </li>\n</ul>\n<h3>\n Microprocessors\n</h3>\n<p>\n Microprocessors are processors built on a single chip. Before the 1970s, processors were too complex to fit on one chip, so they were made from multiple chips on circuit boards. Intel introduced the first 4-bit microprocessor, the 4004, in 1971. Now, even advanced supercomputers are constructed using microprocessors. The terms \"microprocessor\" and \"processor\" are used interchangeably in this book.\n</p>\n"}, "Page 20": {"response": "<p>\n By a happy coincidence,\n 2\n 10\n =\n 1024\n \u2248\n 1\n 0\n 3\n 2^{10} = 1024 \\approx 10^3\n 2\n 10\n =\n 1024\n \u2248\n 1\n 0\n 3\n . So, the term \"kilo,\" which means \"thousand\" in Greek, refers to\n 2\n 10\n 2^{10}\n 2\n 10\n . For example, 1 kilobyte (KB) is 1024 bytes. Similarly, \"mega\" (million) refers to\n 2\n 20\n 2^{20}\n 2\n 20\n or about\n 1\n 0\n 6\n 10^6\n 1\n 0\n 6\n , and \"giga\" (billion) refers to\n 2\n 30\n 2^{30}\n 2\n 30\n or about\n 1\n 0\n 9\n 10^9\n 1\n 0\n 9\n . If you remember that\n 2\n 10\n \u2248\n 1\n ,\n 000\n 2^{10} \\approx 1,000\n 2\n 10\n \u2248\n 1\n ,\n 000\n ,\n 2\n 20\n \u2248\n 1\n ,\n 000\n ,\n 000\n 2^{20} \\approx 1,000,000\n 2\n 20\n \u2248\n 1\n ,\n 000\n ,\n 000\n , and\n 2\n 30\n \u2248\n 1\n ,\n 000\n ,\n 000\n ,\n 000\n 2^{30} \\approx 1,000,000,000\n 2\n 30\n \u2248\n 1\n ,\n 000\n ,\n 000\n ,\n 000\n , along with powers of two up to\n 2\n 9\n 2^9\n 2\n 9\n , estimating powers of two becomes simple.\n</p>\n<h3>\n Example 1.6: Estimating Powers of Two\n</h3>\n<p>\n To estimate\n 2\n 24\n 2^{24}\n 2\n 24\n without a calculator:\n</p>\n<ul>\n <li>\n  Break it down into\n  2\n  20\n  2^{20}\n  2\n  20\n  and\n  2\n  4\n  2^4\n  2\n  4\n  .\n </li>\n <li>\n  2\n  20\n  2^{20}\n  2\n  20\n  is about 1 million.\n </li>\n <li>\n  2\n  4\n  2^4\n  2\n  4\n  is 16.\n </li>\n <li>\n  Therefore,\n  2\n  24\n  2^{24}\n  2\n  24\n  is approximately\n  16\n  16\n  16\n  million. The exact value is\n  16\n  ,\n  777\n  ,\n  216\n  16,777,216\n  16\n  ,\n  777\n  ,\n  216\n  , but for general use, 16 million is sufficient.\n </li>\n</ul>\n<p>\n In terms of data measurement:\n</p>\n<ul>\n <li>\n  1024 bytes make up 1 kilobyte (KB).\n </li>\n <li>\n  1024 bits are called 1 kilobit (Kb or Kbit).\n </li>\n <li>\n  Memory is typically measured in bytes, while communication speeds are measured in bits per second. For instance, a typical dial-up modem has a maximum speed of 56 Kbits/sec.\n </li>\n</ul>\n<h3>\n 1.4.5: Binary Addition\n</h3>\n<p>\n Binary addition is similar to decimal addition but generally easier. If the total exceeds what can fit in a single digit, you carry over to the next column.\n</p>\n<p>\n For example:\n</p>\n<ul>\n <li>\n  In decimal addition,\n  7\n  +\n  9\n  =\n  16\n  7 + 9 = 16\n  7\n  +\n  9\n  =\n  16\n  . You record the rightmost digit (6) and carry the left digit (1) to the next column.\n </li>\n <li>\n  In binary, if the sum exceeds 1, you carry over as well.\n </li>\n</ul>\n<p>\n In the binary example:\n</p>\n<ul>\n <li>\n  Adding two binary numbers where the sum exceeds 1 requires carrying over, just like in decimal. The process is visualized in a comparison of decimal and binary addition in Figure 1.8.\n </li>\n</ul>\n"}, "Page 21": {"response": "<p>\n When adding binary numbers, if the sum exceeds what can fit in a single digit, we handle it by recording the rightmost digit (0) and carrying the left digit (1) to the next column. For example, when adding 1 + 1 in binary (which equals 2 in decimal), we write down 0 and carry over 1 to the next column. This carried bit is known as the carry bit.\n</p>\n<h3>\n Example 1.7: Binary Addition\n</h3>\n<p>\n To add\n 011\n 1\n 2\n +\n 010\n 1\n 2\n 0111_2 + 0101_2\n 011\n 1\n 2\n \u200b\n +\n 010\n 1\n 2\n \u200b\n :\n</p>\n<ul>\n <li>\n  The sum is\n  110\n  0\n  2\n  1100_2\n  110\n  0\n  2\n  \u200b\n  , as shown in Figure 1.9. The carry bits are marked in blue.\n </li>\n <li>\n  To verify, we can convert to decimal:\n  011\n  1\n  2\n  =\n  7\n  10\n  0111_2 = 7_{10}\n  011\n  1\n  2\n  \u200b\n  =\n  7\n  10\n  \u200b\n  and\n  010\n  1\n  2\n  =\n  5\n  10\n  0101_2 = 5_{10}\n  010\n  1\n  2\n  \u200b\n  =\n  5\n  10\n  \u200b\n  . The total is\n  1\n  2\n  10\n  12_{10}\n  1\n  2\n  10\n  \u200b\n  , which converts back to\n  110\n  0\n  2\n  1100_2\n  110\n  0\n  2\n  \u200b\n  .\n </li>\n</ul>\n<p>\n Digital systems typically use a fixed number of bits for operations. If the result of an addition exceeds the maximum value representable by those bits, it\u2019s called overflow. For example, a 4-bit number can represent values from 0 to 15. If a sum goes beyond 15, the fifth bit is lost, leading to an incorrect result. Overflow can be identified by checking if there's a carry out of the most significant bit.\n</p>\n<h3>\n Example 1.8: Addition with Overflow\n</h3>\n<p>\n When adding\n 110\n 1\n 2\n +\n 010\n 1\n 2\n 1101_2 + 0101_2\n 110\n 1\n 2\n \u200b\n +\n 010\n 1\n 2\n \u200b\n :\n</p>\n<ul>\n <li>\n  The result is\n  1001\n  0\n  2\n  10010_2\n  1001\n  0\n  2\n  \u200b\n  , which overflows for a 4-bit number.\n </li>\n <li>\n  If we try to store it as four bits, we lose the most significant bit, resulting in\n  001\n  0\n  2\n  0010_2\n  001\n  0\n  2\n  \u200b\n  , which is incorrect. If we used five bits,\n  1001\n  0\n  2\n  10010_2\n  1001\n  0\n  2\n  \u200b\n  would have been correct.\n </li>\n</ul>\n<h3>\n 1.4.6: Signed Binary Numbers\n</h3>\n<p>\n So far, we've only discussed unsigned binary numbers, which represent non-negative values. To handle both positive and negative numbers, we need a different system. The two main methods for representing signed binary numbers are sign/magnitude and two's complement.\n</p>\n<h4>\n Sign/Magnitude Numbers\n</h4>\n<p>\n Sign/magnitude representation is straightforward; the most significant bit indicates the sign (0 for positive, 1 for negative), while the remaining bits represent the magnitude. This method aligns with how we typically express negative numbers using a minus sign followed by the number itself.\n</p>\n"}, "Page 22": {"response": "<h3>\n Sign/Magnitude Numbers\n</h3>\n<p>\n In the sign/magnitude system, the most significant bit (MSB) acts as the sign bit, while the remaining bits represent the magnitude (absolute value). A sign bit of 0 means the number is positive, and a sign bit of 1 means it is negative.\n</p>\n<h4>\n Example 1.9: Sign/Magnitude Representation\n</h4>\n<ul>\n <li>\n  The number 5 has a magnitude of 5, represented as\n  010\n  1\n  2\n  0101_2\n  010\n  1\n  2\n  \u200b\n  .\n </li>\n <li>\n  The number -5 also has a magnitude of 5 but is negative, represented as\n  110\n  1\n  2\n  1101_2\n  110\n  1\n  2\n  \u200b\n  .\n </li>\n</ul>\n<p>\n A problem with sign/magnitude numbers is that regular binary addition doesn't work properly for them. For instance, adding -5 and 5 using standard binary addition gives\n 100\n 1\n 2\n 1001_2\n 100\n 1\n 2\n \u200b\n , which doesn't make sense.\n</p>\n<p>\n The range for an N-bit sign/magnitude number is from\n [\n \u2212\n 2\n (\n N\n \u2212\n 1\n )\n +\n 1\n ,\n 2\n (\n N\n \u2212\n 1\n )\n \u2212\n 1\n ]\n [-2^{(N-1)} + 1, 2^{(N-1)} - 1]\n [\n \u2212\n 2\n (\n N\n \u2212\n 1\n )\n +\n 1\n ,\n 2\n (\n N\n \u2212\n 1\n )\n \u2212\n 1\n ]\n . In this system, both +0 and -0 exist, which can lead to confusion since they represent the same value.\n</p>\n<h3>\n Two\u2019s Complement Numbers\n</h3>\n<p>\n Two's complement representation is similar to unsigned binary numbers, but the MSB has a negative weight. This method solves the issues with sign/magnitude numbers: zero has only one representation, and normal addition can be used.\n</p>\n<ul>\n <li>\n  Zero is represented as all zeros:\n  00...00\n  0\n  2\n  00...000_2\n  00...00\n  0\n  2\n  \u200b\n  .\n </li>\n <li>\n  The largest positive number has a 0 in the MSB and 1's elsewhere:\n  01...11\n  1\n  2\n  01...111_2\n  01...11\n  1\n  2\n  \u200b\n  (which equals\n  2\n  (\n  N\n  \u2212\n  1\n  )\n  \u2212\n  1\n  2^{(N-1)} - 1\n  2\n  (\n  N\n  \u2212\n  1\n  )\n  \u2212\n  1\n  ).\n </li>\n <li>\n  The most negative number has a 1 in the MSB and 0's elsewhere:\n  10...00\n  0\n  2\n  10...000_2\n  10...00\n  0\n  2\n  \u200b\n  (which equals\n  \u2212\n  2\n  (\n  N\n  \u2212\n  1\n  )\n  -2^{(N-1)}\n  \u2212\n  2\n  (\n  N\n  \u2212\n  1\n  )\n  ).\n </li>\n <li>\n  The number -1 is represented as all ones:\n  11...11\n  1\n  2\n  11...111_2\n  11...11\n  1\n  2\n  \u200b\n  .\n </li>\n</ul>\n<p>\n In two's complement, the MSB serves as a sign bit, where 0 indicates a positive number and 1 indicates a negative number. The way we interpret the remaining bits differs from sign/magnitude.\n</p>\n<p>\n To find the two's complement (which allows for the representation of negative numbers), you invert all the bits of the number and then add 1 to the least significant bit (LSB).\n</p>\n<h4>\n Example 1.10: Two\u2019s Complement of -2\n</h4>\n<p>\n To represent -2 as a 4-bit two's complement number:\n</p>\n<ol>\n <li>\n  Start with the binary representation of 2, which is\n  001\n  0\n  2\n  0010_2\n  001\n  0\n  2\n  \u200b\n  .\n </li>\n <li>\n  Invert the bits to get\n  110\n  1\n  2\n  1101_2\n  110\n  1\n  2\n  \u200b\n  .\n </li>\n <li>\n  Add 1 to this result:\n  110\n  1\n  2\n  +\n  000\n  1\n  2\n  =\n  111\n  0\n  2\n  1101_2 + 0001_2 = 1110_2\n  110\n  1\n  2\n  \u200b\n  +\n  000\n  1\n  2\n  \u200b\n  =\n  111\n  0\n  2\n  \u200b\n  .\nSo, -2 in 4-bit two's complement is\n  111\n  0\n  2\n  1110_2\n  111\n  0\n  2\n  \u200b\n  .\n </li>\n</ol>\n<h3>\n Notable Example: Ariane 5 Rocket Failure\n</h3>\n<p>\n In 1996, the Ariane 5 rocket failed shortly after launch due to a 16-bit overflow in its control computer, which had been tested on the Ariane 4. The Ariane 5's faster engine produced larger values, leading to the overflow and ultimately causing the rocket to veer off course and explode.\n</p>\n"}, "Page 23": {"response": "<h3>\n Converting Negative Two\u2019s Complement Numbers\n</h3>\n<p>\n To find the two's complement of -2, start with its binary representation, which is\n 001\n 0\n 2\n 0010_2\n 001\n 0\n 2\n \u200b\n . To convert it to +2, invert the bits to get\n 110\n 1\n 2\n 1101_2\n 110\n 1\n 2\n \u200b\n , then add 1:\n</p>\n110\n1\n2\n+\n000\n1\n2\n=\n111\n0\n2\n1101_2 + 0001_2 = 1110_2\n110\n1\n2\n\u200b\n+\n000\n1\n2\n\u200b\n=\n111\n0\n2\n\u200b\n<p>\n So, -2 is represented as\n 111\n 0\n 2\n 1110_2\n 111\n 0\n 2\n \u200b\n .\n</p>\n<h3>\n Finding the Value of a Negative Two\u2019s Complement Number\n</h3>\n<h4>\n Example 1.11: Value of\n 100\n 1\n 2\n 1001_2\n 100\n 1\n 2\n \u200b\n</h4>\n<p>\n The binary number\n 100\n 1\n 2\n 1001_2\n 100\n 1\n 2\n \u200b\n has a leading 1, indicating it's negative. To find its magnitude, invert the bits:\n</p>\n100\n1\n2\n\u2192\n011\n0\n2\n1001_2 \\rightarrow 0110_2\n100\n1\n2\n\u200b\n\u2192\n011\n0\n2\n\u200b\n<p>\n Then add 1:\n</p>\n011\n0\n2\n+\n000\n1\n2\n=\n011\n1\n2\n0110_2 + 0001_2 = 0111_2\n011\n0\n2\n\u200b\n+\n000\n1\n2\n\u200b\n=\n011\n1\n2\n\u200b\n<p>\n This gives us\n 011\n 1\n 2\n 0111_2\n 011\n 1\n 2\n \u200b\n , which equals 7 in decimal. Therefore,\n 100\n 1\n 2\n 1001_2\n 100\n 1\n 2\n \u200b\n represents -7.\n</p>\n<h3>\n Addition of Two\u2019s Complement Numbers\n</h3>\n<p>\n Two's complement addition works correctly for both positive and negative numbers. When adding N-bit numbers, any carry out of the Nth bit is discarded.\n</p>\n<h4>\n Example 1.12: Adding Two\u2019s Complement Numbers\n</h4>\n<ul>\n <li>\n  (a) To compute\n  \u2212\n  2\n  +\n  6\n  -2 + 6\n  \u2212\n  2\n  +\n  6\n  :\n </li>\n</ul>\n<p>\n -2 \\text{ is } 1110_2, \\quad 6 \\text{ is } 0110_2\n]\n <br/>\n Adding these gives:\n</p>\n111\n0\n2\n+\n011\n0\n2\n=\n111\n1\n2\n1110_2 + 0110_2 = 1111_2\n111\n0\n2\n\u200b\n+\n011\n0\n2\n\u200b\n=\n111\n1\n2\n\u200b\n<p>\n This result represents -2 + 6 = 4.\n</p>\n<ul>\n <li>\n  (b) To compute\n  \u2212\n  7\n  +\n  7\n  -7 + 7\n  \u2212\n  7\n  +\n  7\n  :\n </li>\n</ul>\n<p>\n -7 \\text{ is } 1001_2, \\quad 7 \\text{ is } 0111_2\n]\n <br/>\n Adding these gives:\n</p>\n100\n1\n2\n+\n011\n1\n2\n=\n1000\n0\n2\n1001_2 + 0111_2 = 10000_2\n100\n1\n2\n\u200b\n+\n011\n1\n2\n\u200b\n=\n1000\n0\n2\n\u200b\n<p>\n The fifth bit is discarded, resulting in\n 000\n 0\n 2\n 0000_2\n 000\n 0\n 2\n \u200b\n , which is 0.\n</p>\n<h3>\n Subtraction Using Two\u2019s Complement\n</h3>\n<p>\n To subtract numbers, take the two's complement of the number being subtracted and then add.\n</p>\n<h4>\n Example 1.13: Subtracting Two\u2019s Complement Numbers\n</h4>\n<ul>\n <li>\n  (a) For\n  5\n  \u2212\n  3\n  5 - 3\n  5\n  \u2212\n  3\n  :\n  <ul>\n   <li>\n    First, represent 3 in binary:\n    3\n    is\n    001\n    1\n    2\n    3 \\text{ is } 0011_2\n    3\n    is\n    001\n    1\n    2\n    \u200b\n    .\n   </li>\n   <li>\n    Find its two's complement:\n   </li>\n  </ul>\n </li>\n</ul>\n<p>\n 0011_2 \\rightarrow 1100_2 + 1 = 1101_2\n]\n</p>\n<ul>\n <li>\n  Now add:\n </li>\n</ul>\n010\n1\n2\n+\n110\n1\n2\n=\n001\n0\n2\n0101_2 + 1101_2 = 0010_2\n010\n1\n2\n\u200b\n+\n110\n1\n2\n\u200b\n=\n001\n0\n2\n\u200b\n<p>\n This results in\n 2\n 2\n 2\n , which is correct.\n</p>\n<ul>\n <li>\n  (b) For\n  3\n  \u2212\n  5\n  3 - 5\n  3\n  \u2212\n  5\n  :\n  <ul>\n   <li>\n    First, represent 5 in binary:\n    5\n    is\n    010\n    1\n    2\n    5 \\text{ is } 0101_2\n    5\n    is\n    010\n    1\n    2\n    \u200b\n    .\n   </li>\n   <li>\n    Find its two's complement:\n   </li>\n  </ul>\n </li>\n</ul>\n<p>\n 0101_2 \\rightarrow 1010_2 + 1 = 1011_2\n]\n</p>\n<ul>\n <li>\n  Now add:\n </li>\n</ul>\n001\n1\n2\n+\n101\n1\n2\n=\n111\n0\n2\n0011_2 + 1011_2 = 1110_2\n001\n1\n2\n\u200b\n+\n101\n1\n2\n\u200b\n=\n111\n0\n2\n\u200b\n<p>\n This gives\n \u2212\n 2\n -2\n \u2212\n 2\n .\n</p>\n<h3>\n Representing Zero in Two\u2019s Complement\n</h3>\n<p>\n The two\u2019s complement of 0 is found by inverting all bits (resulting in\n 1111...\n 1\n 2\n 1111...1_2\n 1111...\n 1\n 2\n \u200b\n ) and adding 1, which produces all 0's. Zero is always represented as all 0's in this system, and unlike sign/magnitude, there\u2019s no separate representation for -0. Zero is treated as positive because its sign bit is 0.\n</p>\n"}, "Page 24": {"response": "<h3>\n Two\u2019s Complement Number System\n</h3>\n<p>\n N-bit two\u2019s complement numbers can represent\n 2\n N\n 2^N\n 2\n N\n different values, but these values are divided between positive and negative numbers. For instance:\n</p>\n<ul>\n <li>\n  A 4-bit unsigned number can represent values from 0 to 15 (16 values).\n </li>\n <li>\n  A 4-bit two\u2019s complement number represents values from -8 to 7 (also 16 values).\n </li>\n</ul>\n<p>\n In general, the range for an N-bit two's complement number is from\n \u2212\n 2\n (\n N\n \u2212\n 1\n )\n -2^{(N-1)}\n \u2212\n 2\n (\n N\n \u2212\n 1\n )\n to\n 2\n (\n N\n \u2212\n 1\n )\n \u2212\n 1\n 2^{(N-1)} - 1\n 2\n (\n N\n \u2212\n 1\n )\n \u2212\n 1\n . This means there\u2019s one more negative number than positive because there's no separate representation for zero. The most negative number is\n 10...00\n 0\n 2\n 10...000_2\n 10...00\n 0\n 2\n \u200b\n , which is considered unique because it has no positive equivalent. Its two's complement is calculated by inverting the bits and adding 1, resulting in the same value.\n</p>\n<h3>\n Overflow in Two\u2019s Complement\n</h3>\n<p>\n When adding two N-bit numbers:\n</p>\n<ul>\n <li>\n  If both numbers are positive and their sum exceeds\n  2\n  (\n  N\n  \u2212\n  1\n  )\n  \u2212\n  1\n  2^{(N-1)} - 1\n  2\n  (\n  N\n  \u2212\n  1\n  )\n  \u2212\n  1\n  , or if both are negative and their sum is less than\n  \u2212\n  2\n  (\n  N\n  \u2212\n  1\n  )\n  -2^{(N-1)}\n  \u2212\n  2\n  (\n  N\n  \u2212\n  1\n  )\n  , overflow occurs.\n </li>\n <li>\n  Adding a positive and a negative number does not cause overflow.\n </li>\n <li>\n  Unlike unsigned numbers, a carry from the most significant bit does not indicate overflow. Instead, overflow happens when both numbers have the same sign bit, but the result has the opposite sign bit.\n </li>\n</ul>\n<h4>\n Example 1.14: Adding with Overflow\n</h4>\n<ul>\n <li>\n  To compute\n  4\n  +\n  5\n  4 + 5\n  4\n  +\n  5\n  using 4-bit two\u2019s complement:\n  <ul>\n   <li>\n    4\n    4\n    4\n    is\n    010\n    0\n    2\n    0100_2\n    010\n    0\n    2\n    \u200b\n    and\n    5\n    5\n    5\n    is\n    010\n    1\n    2\n    0101_2\n    010\n    1\n    2\n    \u200b\n    .\n   </li>\n   <li>\n    Adding these gives:\n   </li>\n  </ul>\n </li>\n</ul>\n<p>\n 0100_2 + 0101_2 = 1001_2\n]\n</p>\n<ul>\n <li>\n  This result represents -7, which is incorrect since the expected sum (9) is out of range for 4-bit representation. Using 5 or more bits would have given the correct result\n  0100\n  1\n  2\n  =\n  9\n  01001_2 = 9\n  0100\n  1\n  2\n  \u200b\n  =\n  9\n  .\n </li>\n</ul>\n<h3>\n Sign Extension\n</h3>\n<p>\n When increasing the number of bits in a two's complement number, the sign bit (the most significant bit) is copied into the new positions. This process is called sign extension. For example:\n</p>\n<ul>\n <li>\n  The number\n  3\n  3\n  3\n  (binary\n  0011\n  0011\n  0011\n  ) becomes\n  0000011\n  0000011\n  0000011\n  in 7 bits.\n </li>\n <li>\n  The number\n  \u2212\n  3\n  -3\n  \u2212\n  3\n  (binary\n  1101\n  1101\n  1101\n  ) becomes\n  1111101\n  1111101\n  1111101\n  in 7 bits.\n </li>\n</ul>\n<h3>\n Comparison of Number Systems\n</h3>\n<p>\n The three main binary number systems are:\n</p>\n<ol>\n <li>\n  <strong>\n   Unsigned\n  </strong>\n  : Represents only positive values.\n </li>\n <li>\n  <strong>\n   Two\u2019s Complement\n  </strong>\n  : Represents both positive and negative values; addition works for all types.\n </li>\n <li>\n  <strong>\n   Sign/Magnitude\n  </strong>\n  : Represents positive and negative values but can be problematic due to having two representations for zero.\n </li>\n</ol>\n<p>\n Two's complement is generally preferred because it simplifies arithmetic operations and effectively represents both positive and negative integers.\n</p>\n"}, "Page 25": {"response": "<h3>\n Subtraction in Two's Complement\n</h3>\n<p>\n To subtract one number from another in binary, you can negate the second number by finding its two\u2019s complement and then add it to the first number. For signed binary numbers, we generally use the two\u2019s complement system.\n</p>\n<h3>\n Number Ranges for Different Systems\n</h3>\n<ol>\n <li>\n  <p>\n   <strong>\n    Unsigned Numbers\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Range: [0, 15]\n   </li>\n   <li>\n    Represented in standard binary form.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Two\u2019s Complement Numbers\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Range: [-8, 7]\n   </li>\n   <li>\n    Non-negative numbers (0 to 7) have the same binary encoding as unsigned numbers.\n   </li>\n   <li>\n    Negative numbers (-8 to -1) are encoded such that higher unsigned values represent numbers closer to 0. For instance, the number\n    1000\n    1000\n    1000\n    represents -8 and has no positive equivalent.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Sign/Magnitude Numbers\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Range: [-7, 7]\n   </li>\n   <li>\n    The most significant bit acts as the sign bit.\n   </li>\n   <li>\n    Positive numbers (1 to 7) are represented the same way as unsigned numbers.\n   </li>\n   <li>\n    Negative numbers are similar but have the sign bit set to 1. Zero can be represented by both\n    0000\n    0000\n    0000\n    and\n    1000\n    1000\n    1000\n    . Thus, N-bit sign/magnitude numbers only represent\n    2\n    N\n    \u2212\n    1\n    2^N - 1\n    2\n    N\n    \u2212\n    1\n    unique integers because of this dual representation for zero.\n   </li>\n  </ul>\n </li>\n</ol>\n<h3>\n Logic Gates\n</h3>\n<p>\n Logic gates are fundamental components in digital systems. They are simple circuits that take one or more binary inputs and produce a binary output. Each logic gate has a specific symbol that represents its function and shows how many inputs it has and the resulting output.\n</p>\n"}, "Page 26": {"response": "<h3>\n Logic Gates Overview\n</h3>\n<p>\n Logic gates are essential components in digital design, typically represented with inputs on the left (or top) and outputs on the right (or bottom). Inputs are often labeled with letters from the beginning of the alphabet, while the output is labeled as Y. The relationship between inputs and outputs can be explained using a truth table or a Boolean equation. A truth table shows all possible input combinations on the left, with the corresponding output on the right. A Boolean equation is a mathematical expression that uses binary variables.\n</p>\n<h3>\n 1.5.1 NOT Gate\n</h3>\n<p>\n The\n <strong>\n  NOT gate\n </strong>\n has one input (A) and one output (Y). It produces an output that is the opposite (inverse) of its input:\n</p>\n<ul>\n <li>\n  If A is FALSE, Y is TRUE.\n </li>\n <li>\n  If A is TRUE, Y is FALSE.\n </li>\n</ul>\n<p>\n This relationship can be summarized in a truth table and a Boolean equation:\n Y\n =\n A\n \u203e\n Y = \\overline{A}\n Y\n =\n A\n , pronounced \"Y equals NOT A.\" The NOT gate is also known as an inverter, and while we will consistently use\n Y\n =\n A\n \u203e\n Y = \\overline{A}\n Y\n =\n A\n , other notations like\n Y\n =\n A\n \u2032\n Y = A'\n Y\n =\n A\n \u2032\n ,\n Y\n =\n !\n A\n Y = !A\n Y\n =\n !\n A\n , or\n Y\n =\n A\n Y = ~A\n Y\n =\n A\n may appear in different texts.\n</p>\n<h3>\n 1.5.2 Buffer\n</h3>\n<p>\n The\n <strong>\n  buffer\n </strong>\n is another one-input logic gate that simply copies the input to the output. Logically, a buffer acts like a wire, which may seem unimportant. However, in practice, buffers can deliver large amounts of current or quickly distribute their output to multiple gates. This illustrates the need to consider different levels of abstraction in understanding digital systems. Buffers are represented by a triangle symbol, and a circle (or bubble) at the output indicates inversion, similar to the NOT gate.\n</p>\n<h3>\n 1.5.3 AND Gate\n</h3>\n<p>\n The\n <strong>\n  AND gate\n </strong>\n is a two-input logic gate that outputs TRUE (Y) only when both inputs (A and B) are TRUE. If either A or B is FALSE, the output is FALSE. The inputs are typically organized in binary order (00, 01, 10, 11). The Boolean equation for an AND gate can be expressed in several ways:\n</p>\n<ul>\n <li>\n  Y\n  =\n  A\n  \u22c5\n  B\n  Y = A \\cdot B\n  Y\n  =\n  A\n  \u22c5\n  B\n </li>\n <li>\n  Y\n  =\n  A\n  B\n  Y = AB\n  Y\n  =\n  A\n  B\n </li>\n <li>\n  Y\n  =\n  A\n  &amp;\n  B\n  Y = A \\&amp; B\n  Y\n  =\n  A\n  &amp;\n  B\n </li>\n</ul>\n<p>\n The dot symbol (\u2022) is referred to as \"intersection\" and is preferred in logical contexts. We use\n Y\n =\n A\n B\n Y = AB\n Y\n =\n A\n B\n , which can be read as \"Y equals A and B,\" for simplicity.\n</p>\n"}, "Page 27": {"response": "<h3>\n 1.5.4 OR Gate\n</h3>\n<p>\n The\n <strong>\n  OR gate\n </strong>\n produces a TRUE output (Y) if either input A or input B (or both) are TRUE. The Boolean equation for an OR gate can be written as\n Y\n =\n A\n +\n B\n Y = A + B\n Y\n =\n A\n +\n B\n or\n Y\n =\n A\n \u2228\n B\n Y = A \\lor B\n Y\n =\n A\n \u2228\n B\n . In this context, the\n \u2228\n \\lor\n \u2228\n symbol is called \"union\" and is preferred by logicians, while digital designers typically use the\n +\n +\n +\n notation, pronounced \"Y equals A or B.\"\n</p>\n<h3>\n 1.5.5 Other Two-Input Gates\n</h3>\n<p>\n Several other common two-input gates are shown in Figure 1.16:\n</p>\n<ul>\n <li>\n  <strong>\n   XOR Gate\n  </strong>\n  (exclusive OR): Outputs TRUE if either A or B is TRUE, but not both.\n </li>\n <li>\n  <strong>\n   NAND Gate\n  </strong>\n  : Outputs the opposite of AND; it is TRUE unless both inputs are TRUE.\n </li>\n <li>\n  <strong>\n   NOR Gate\n  </strong>\n  : Outputs the opposite of OR; it is TRUE only if neither A nor B is TRUE.\n </li>\n</ul>\n<h3>\n Example 1.15: XNOR Gate\n</h3>\n<p>\n The\n <strong>\n  XNOR gate\n </strong>\n (Figure 1.17) performs the inverse of an XOR gate. Its output is TRUE if both inputs are either FALSE or TRUE. The XNOR gate is sometimes called an \"equality gate\" because it outputs TRUE when the inputs are equal. The truth table for an XNOR gate is shown in Figure 1.18.\n</p>\n<h3>\n 1.5.6 Multiple-Input Gates\n</h3>\n<p>\n There are Boolean functions that work with three or more inputs. The most common types include:\n</p>\n<ul>\n <li>\n  <strong>\n   N-input AND Gate\n  </strong>\n  : Outputs TRUE only when all N inputs are TRUE.\n </li>\n <li>\n  <strong>\n   N-input OR Gate\n  </strong>\n  : Outputs TRUE if at least one of the N inputs is TRUE.\n </li>\n</ul>\n<p>\n These gates expand the capabilities of logic circuits, allowing for more complex operations.\n</p>\n"}, "Page 28": {"response": "<h3>\n N-Input XOR Gate\n</h3>\n<p>\n An\n <strong>\n  N-input XOR gate\n </strong>\n , also known as a parity gate, outputs TRUE if an odd number of its inputs are TRUE. The truth table for these gates lists input combinations in counting order.\n</p>\n<h3>\n Example 1.16: Three-Input NOR Gate\n</h3>\n<p>\n The\n <strong>\n  three-input NOR gate\n </strong>\n (shown in Figure 1.19) outputs TRUE only when none of its inputs are TRUE. The truth table for this gate is shown in Figure 1.20.\n</p>\n<h3>\n Example 1.17: Four-Input AND Gate\n</h3>\n<p>\n The\n <strong>\n  four-input AND gate\n </strong>\n (shown in Figure 1.21) outputs TRUE only when all four inputs are TRUE. The corresponding truth table is shown in Figure 1.22.\n</p>\n<h3>\n 1.6 Beneath the Digital Abstraction\n</h3>\n<p>\n Digital systems use discrete values but represent them with continuous physical quantities, such as voltage. Designers need to connect these continuous values to discrete values. For example, if a voltage of 0 volts (V) represents the binary value 0, then a voltage of 5 V represents the binary value 1. Real systems must handle noise, so a voltage like 4.97 V might also indicate a binary 1. However, there must be limits; for example, what does a voltage of 4.3 V or 2.5 V mean?\n</p>\n<h3>\n 1.6.1 Supply Voltage\n</h3>\n<p>\n The lowest voltage in a system is 0 V, also known as ground (GND). The highest voltage, provided by the power supply, is typically called VDD. In the 1970s and 1980s, VDD was commonly 5 V. As technology advanced and transistors became smaller, VDD decreased to levels like 3.3 V, 2.5 V, 1.8 V, and even lower, to save power and prevent transistor overload.\n</p>\n<h3>\n 1.6.2 Logic Levels\n</h3>\n<p>\n Mapping continuous voltages to discrete binary values is done by defining\n <strong>\n  logic levels\n </strong>\n . In a typical setup, the first gate is the driver, which outputs a voltage, while the second gate is the receiver, which interprets that voltage as either 0 or 1.\n</p>\n"}, "Page 29": {"response": "<h3>\n Driver and Receiver Connection\n</h3>\n<p>\n The driver connects to the input of the receiver. It can produce a LOW output (0) in the voltage range from 0 V to VOL, and a HIGH output (1) in the range from VOH to VDD. If the receiver sees a voltage between 0 V and VIL, it interprets this as LOW. Conversely, if the voltage is between VIH and VDD, it's interpreted as HIGH. If the input voltage falls between VIL and VIH due to noise or faulty components, the receiver's behavior becomes unpredictable. The values VOH, VOL, VIH, and VIL are known as the output and input logic levels.\n</p>\n<h3>\n 1.6.3 Noise Margins\n</h3>\n<p>\n To ensure the receiver interprets the driver\u2019s output correctly, the conditions VOL \u2264 VIL and VOH \u2265 VIH must be met. This way, even with noise affecting the output, the receiver can still detect the correct logic level. The noise margin is the maximum noise that can be tolerated while still allowing the signal to be read as valid. The low noise margin (NML) and high noise margin (NMH) can be calculated as follows:\n</p>\n<ul>\n <li>\n  N\n  M\n  L\n  =\n  V\n  I\n  L\n  \u2212\n  V\n  O\n  L\n  NML = VIL - VOL\n  NM\n  L\n  =\n  V\n  I\n  L\n  \u2212\n  V\n  O\n  L\n </li>\n <li>\n  N\n  M\n  H\n  =\n  V\n  O\n  H\n  \u2212\n  V\n  I\n  H\n  NMH = VOH - VIH\n  NM\n  H\n  =\n  V\n  O\n  H\n  \u2212\n  V\n  I\n  H\n </li>\n</ul>\n<h3>\n Example 1.18\n</h3>\n<p>\n In the inverter circuit (Figure 1.24), the output voltage of inverter I1 is VO1, and the input voltage of inverter I2 is VI2. The inverters have these characteristics:\n</p>\n<ul>\n <li>\n  V\n  D\n  D\n  =\n  5\n  V\n  VDD = 5 V\n  V\n  DD\n  =\n  5\n  V\n </li>\n <li>\n  V\n  I\n  L\n  =\n  1.35\n  V\n  VIL = 1.35 V\n  V\n  I\n  L\n  =\n  1.35\n  V\n </li>\n <li>\n  V\n  I\n  H\n  =\n  3.15\n  V\n  VIH = 3.15 V\n  V\n  I\n  H\n  =\n  3.15\n  V\n </li>\n <li>\n  V\n  O\n  L\n  =\n  0.33\n  V\n  VOL = 0.33 V\n  V\n  O\n  L\n  =\n  0.33\n  V\n </li>\n <li>\n  V\n  O\n  H\n  =\n  3.84\n  V\n  VOH = 3.84 V\n  V\n  O\n  H\n  =\n  3.84\n  V\n </li>\n</ul>\n<p>\n The noise margins can be calculated as:\n</p>\n<ul>\n <li>\n  N\n  M\n  L\n  =\n  1.35\n  V\n  \u2212\n  0.33\n  V\n  =\n  1.02\n  V\n  NML = 1.35 V - 0.33 V = 1.02 V\n  NM\n  L\n  =\n  1.35\n  V\n  \u2212\n  0.33\n  V\n  =\n  1.02\n  V\n </li>\n <li>\n  N\n  M\n  H\n  =\n  3.84\n  V\n  \u2212\n  3.15\n  V\n  =\n  0.69\n  V\n  NMH = 3.84 V - 3.15 V = 0.69 V\n  NM\n  H\n  =\n  3.84\n  V\n  \u2212\n  3.15\n  V\n  =\n  0.69\n  V\n </li>\n</ul>\n<p>\n The circuit can tolerate 1 V of noise when the output is LOW (1.02 V), but not when it\u2019s HIGH (0.69 V). For example, if I1 outputs its maximum HIGH value (3.84 V) and noise drops this by 1 V, then the input to I2 becomes 2.84 V, which is below the acceptable HIGH input (3.15 V). Hence, the receiver may not recognize it as a proper HIGH input.\n</p>\n<h3>\n 1.6.4 DC Transfer Characteristics\n</h3>\n<p>\n To grasp the limits of digital abstraction, we must examine the analog behavior of a gate. The\n <strong>\n  DC transfer characteristics\n </strong>\n of a gate show how the output voltage varies as a function of the input voltage when operating under DC conditions.\n</p>\n<p>\n <em>\n  Note: VDD refers to the voltage on the drain of a MOS transistor used in modern chips, while the power supply voltage is sometimes called VCC for older technologies. Ground is often called VSS, based on the source of a MOS transistor.\n </em>\n</p>\n"}, "Page 30": {"response": "<h3>\n DC Transfer Characteristics\n</h3>\n<p>\n DC transfer characteristics describe how the output voltage of a circuit changes in response to a slowly changing input voltage, allowing the output to keep up. An ideal inverter would switch sharply at the midpoint (VDD/2). For input voltages less than or equal to VDD/2, the output would be VDD; for input voltages greater than VDD/2, the output would drop to 0. In this ideal scenario, VIH (input high threshold) and VIL (input low threshold) would both equal VDD/2, while VOH (output high voltage) would be VDD and VOL (output low voltage) would be 0.\n</p>\n<p>\n However, real inverters transition more gradually between these extremes. For instance, when the input voltage (V(A)) is 0, the output voltage (V(Y)) is VDD. When V(A) is VDD, V(Y) becomes 0. The transition is smooth and may not be perfectly centered at VDD/2. To define the logic levels effectively, it\u2019s practical to choose them at points where the slope of the transfer characteristic (dV(Y) / dV(A)) equals -1. These points are known as unity gain points, and selecting logic levels here usually maximizes the noise margins. If VIL is decreased, VOH increases slightly. However, if VIL is increased, VOH can drop significantly.\n</p>\n<h3>\n 1.6.5 The Static Discipline\n</h3>\n<p>\n To prevent inputs from falling into an undefined or \"forbidden\" zone, digital logic gates follow the static discipline. This principle ensures that, with valid logical inputs, every component in the circuit produces valid logical outputs. By adhering to this static discipline, designers trade off the flexibility of using arbitrary analog components for the reliability of predictable digital behavior.\n</p>\n<p>\n <em>\n  Note: DC behavior refers to circuits operating with a constant input voltage or changing it slowly, while transient response involves rapid changes in input voltage.\n </em>\n</p>\n"}, "Page 31": {"response": "<p>\n Digital circuits are simpler and more reliable than analog ones. They increase design efficiency by abstracting unnecessary details, making it easier for designers to work.\n</p>\n<p>\n While the values for VDD (the supply voltage) and logic levels can be chosen arbitrarily, all gates that need to communicate must use compatible logic levels. This compatibility allows gates to be grouped into logic families, ensuring that gates within the same family work well together by adhering to the static discipline. Think of it like Lego blocks that fit together easily because they share the same dimensions and connections.\n</p>\n<p>\n Four major logic families were popular from the 1970s to the 1990s:\n</p>\n<ol>\n <li>\n  <strong>\n   Transistor-Transistor Logic (TTL)\n  </strong>\n </li>\n <li>\n  <strong>\n   Complementary Metal-Oxide-Semiconductor Logic (CMOS)\n  </strong>\n </li>\n <li>\n  <strong>\n   Low Voltage TTL Logic (LVTTL)\n  </strong>\n </li>\n <li>\n  <strong>\n   Low Voltage CMOS Logic (LVCMOS)\n  </strong>\n </li>\n</ol>\n<p>\n These families use consistent power supply voltages and logic levels, as shown in Table 1.4, which compares their logic levels. Over time, there has been an increase in the number of logic families, leading to even lower power supply voltages. More details on popular logic families can be found in Appendix A.6.\n</p>\n<h3>\n Table 1.4: Logic Levels for 5V and 3.3V Logic Families\n</h3>\n<table>\n <thead>\n  <tr>\n   <th>\n    Logic Family\n   </th>\n   <th>\n    VDD (V)\n   </th>\n   <th>\n    VIL (V)\n   </th>\n   <th>\n    VIH (V)\n   </th>\n   <th>\n    VOL (V)\n   </th>\n   <th>\n    VOH (V)\n   </th>\n  </tr>\n </thead>\n <tbody>\n  <tr>\n   <td>\n    TTL\n   </td>\n   <td>\n    5 (4.75\u20135.25)\n   </td>\n   <td>\n    0.8\n   </td>\n   <td>\n    2.0\n   </td>\n   <td>\n    0.4\n   </td>\n   <td>\n    2.4\n   </td>\n  </tr>\n  <tr>\n   <td>\n    CMOS\n   </td>\n   <td>\n    5 (4.5\u20136)\n   </td>\n   <td>\n    1.35\n   </td>\n   <td>\n    3.15\n   </td>\n   <td>\n    0.33\n   </td>\n   <td>\n    3.84\n   </td>\n  </tr>\n  <tr>\n   <td>\n    LVTTL\n   </td>\n   <td>\n    3.3 (3\u20133.6)\n   </td>\n   <td>\n    0.8\n   </td>\n   <td>\n    2.0\n   </td>\n   <td>\n    0.4\n   </td>\n   <td>\n    2.4\n   </td>\n  </tr>\n  <tr>\n   <td>\n    LVCMOS\n   </td>\n   <td>\n    3.3 (3\u20133.6)\n   </td>\n   <td>\n    0.9\n   </td>\n   <td>\n    1.8\n   </td>\n   <td>\n    0.36\n   </td>\n   <td>\n    2.7\n   </td>\n  </tr>\n </tbody>\n</table>\n"}, "Page 32": {"response": "<h3>\n Example 1.19: Logic Family Compatibility\n</h3>\n<p>\n To determine which logic families in Table 1.4 can communicate reliably, refer to Table 1.5, which shows the compatibility of their logic levels. A 5 V logic family, like TTL or CMOS, can output a signal as high as 5 V. If this signal is sent to a 3.3 V logic family, such as LVTTL or LVCMOS, it may damage the receiver unless that receiver is specifically designed to handle 5 V signals.\n</p>\n<h3>\n 1.7 CMOS Transistors*\n</h3>\n<p>\n <em>\n  Note: This section is optional and not essential for understanding the main content of the book.\n </em>\n</p>\n<p>\n Transistors are fundamental components in modern computers. Unlike earlier devices that used gears, relays, or vacuum tubes, transistors are small, cheap, and reliable electrical switches that can turn ON or OFF based on applied voltage or current. The two primary types of transistors are:\n</p>\n<ol>\n <li>\n  <strong>\n   Bipolar Transistors\n  </strong>\n </li>\n <li>\n  <strong>\n   Metal-Oxide-Semiconductor Field Effect Transistors (MOSFETs or MOS transistors)\n  </strong>\n </li>\n</ol>\n<p>\n In 1958, Jack Kilby at Texas Instruments created the first integrated circuit with two transistors. The following year, Robert Noyce at Fairchild Semiconductor patented a method to connect multiple transistors on a single silicon chip. Initially, transistors were costly, around $10 each. However, thanks to significant manufacturing advancements over the past few decades, engineers can now fit approximately one billion MOSFETs on a 1 cm\u00b2 chip of silicon, with each transistor costing less than 10 microcents. The capacity and cost of these transistors continue to improve dramatically every eight years or so. Today, MOSFETs are the core components of modern electronic devices.\n</p>\n<h3>\n Table 1.5: Compatibility of Logic Families\n</h3>\n<table>\n <thead>\n  <tr>\n   <th>\n    Receiver\n   </th>\n   <th>\n    TTL\n   </th>\n   <th>\n    CMOS\n   </th>\n   <th>\n    LVTTL\n   </th>\n   <th>\n    LVCMOS\n   </th>\n  </tr>\n </thead>\n <tbody>\n  <tr>\n   <td>\n    <strong>\n     Driver\n    </strong>\n   </td>\n   <td>\n   </td>\n   <td>\n   </td>\n   <td>\n   </td>\n   <td>\n   </td>\n  </tr>\n  <tr>\n   <td>\n    <strong>\n     TTL\n    </strong>\n   </td>\n   <td>\n    OK\n   </td>\n   <td>\n    NO: VOH \u2264 VIH\n   </td>\n   <td>\n    MAYBEa\n   </td>\n   <td>\n    MAYBEa\n   </td>\n  </tr>\n  <tr>\n   <td>\n    <strong>\n     CMOS\n    </strong>\n   </td>\n   <td>\n    OK\n   </td>\n   <td>\n    OK\n   </td>\n   <td>\n    MAYBEa\n   </td>\n   <td>\n    MAYBEa\n   </td>\n  </tr>\n  <tr>\n   <td>\n    <strong>\n     LVTTL\n    </strong>\n   </td>\n   <td>\n    OK\n   </td>\n   <td>\n    NO: VOH \u2264 VIH\n   </td>\n   <td>\n    OK\n   </td>\n   <td>\n    OK\n   </td>\n  </tr>\n  <tr>\n   <td>\n    <strong>\n     LVCMOS\n    </strong>\n   </td>\n   <td>\n    OK\n   </td>\n   <td>\n    NO: VOH \u2264 VIH\n   </td>\n   <td>\n    OK\n   </td>\n   <td>\n    OK\n   </td>\n  </tr>\n </tbody>\n</table>\n<p>\n <strong>\n  Note:\n </strong>\n \"MAYBE\" indicates compatibility only if a 5 V HIGH level does not damage the receiver input.\n</p>\n"}, "Page 33": {"response": "<h3>\n 1.7 CMOS Transistors\n</h3>\n<p>\n In this section, we\u2019ll explore how logic gates are constructed using MOSFETs (Metal-Oxide-Semiconductor Field Effect Transistors).\n</p>\n<h4>\n 1.7.1 Semiconductors\n</h4>\n<p>\n MOS transistors are primarily made from silicon, which is the main element found in rocks and sand. Silicon (Si) is a group IV element, meaning it has four electrons in its outer shell. These electrons bond with four neighboring silicon atoms, creating a crystalline structure. Although the silicon lattice can be simplified in two dimensions for illustration, it actually forms a cubic crystal structure.\n</p>\n<p>\n In its pure form, silicon does not conduct electricity well because its electrons are tightly bound in these covalent bonds. However, when small amounts of impurities, known as dopants, are added, the conductivity of silicon improves.\n</p>\n<ul>\n <li>\n  <p>\n   <strong>\n    N-type Dopants\n   </strong>\n   : When a group V element like arsenic (As) is introduced, it has an extra electron that does not participate in bonding. This free electron can move around within the lattice, leaving behind an ionized arsenic atom (As\u207b). Because this extra electron carries a negative charge, arsenic is classified as an n-type dopant.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    P-type Dopants\n   </strong>\n   : Conversely, when a group III element like boron (B) is added, it lacks one electron. This absence creates a \"hole\" in the lattice. An electron from a neighboring silicon atom can fill this hole, leaving another hole behind. This hole can also move throughout the lattice, acting as a positive charge carrier. Therefore, boron is referred to as a p-type dopant.\n  </p>\n </li>\n</ul>\n<p>\n Because the electrical conductivity of silicon can vary significantly based on the amount of doping, silicon is classified as a semiconductor.\n</p>\n<h4>\n 1.7.2 Diodes\n</h4>\n<p>\n The interface where p-type and n-type silicon meet is called a diode. The p-type region is known as the anode, while the n-type region is referred to as the cathode. When the voltage at the anode exceeds that at the cathode, the diode becomes forward-biased, allowing current to flow.\n</p>\n"}, "Page 34": {"response": "<h3>\n 1.7 CMOS Transistors\n</h3>\n<h4>\n Diodes\n</h4>\n<p>\n A diode allows current to flow from the anode to the cathode when the voltage at the anode is higher than at the cathode. In this case, the diode is forward-biased. However, if the voltage at the anode is lower, the diode is reverse-biased, and no current flows. The diode symbol indicates that current only moves in one direction.\n</p>\n<h4>\n 1.7.3 Capacitors\n</h4>\n<p>\n A capacitor consists of two conductive plates separated by an insulating material. When a voltage (V) is applied to one plate, it accumulates an electric charge (Q), while the opposite plate gathers an equal but opposite charge (\u2212Q). The capacitance (C) of a capacitor is calculated as the ratio of charge to voltage:\n C\n =\n Q\n /\n V\n C = Q/V\n C\n =\n Q\n /\n V\n . The capacitance increases with the size of the plates and decreases with the distance between them.\n</p>\n<p>\n Capacitance is significant because charging and discharging a capacitor takes time and energy. Higher capacitance means a circuit operates slower and requires more energy. These concepts of speed and energy will be important throughout the book.\n</p>\n<h4>\n 1.7.4 nMOS and pMOS Transistors\n</h4>\n<p>\n MOSFETs (Metal-Oxide-Semiconductor Field Effect Transistors) are made from multiple layers of conducting and insulating materials. They are built on silicon wafers, typically 15 to 30 cm in diameter. The manufacturing process starts with a bare silicon wafer and involves several steps, including:\n</p>\n<ol>\n <li>\n  Implanting dopants into the silicon.\n </li>\n <li>\n  Growing thin films of silicon dioxide (SiO2) and silicon.\n </li>\n <li>\n  Depositing metal layers.\n </li>\n</ol>\n<p>\n During these steps, the wafer is patterned to ensure materials appear only where needed. Because transistors are extremely small (measured in microns), it's economical to produce billions at once. After processing, the wafer is cut into smaller pieces called chips, which may contain thousands to billions of transistors. These chips are then tested and packaged with metal pins for connection to circuit boards.\n</p>\n<p>\n A typical MOSFET consists of a gate layer on top of an insulating layer of silicon dioxide, which is placed above the silicon substrate. Initially, the gate was made of metal, but modern processes use polycrystalline silicon, which withstands high temperatures. The silicon dioxide acts as a dielectric, separating the gate from the silicon layer, and forms a capacitor structure.\n</p>\n<p>\n In semiconductor manufacturing, cleanliness is crucial; technicians wear protective gear to prevent contamination of the microscopic transistors on silicon wafers.\n</p>\n"}, "Page 35": {"response": "<h3>\n 1.7 CMOS Transistors\n</h3>\n<p>\n There are two types of MOSFETs: nMOS and pMOS (pronounced \"n-moss\" and \"p-moss\"). In Figure 1.29, you can see cross-sections of each type, created by slicing through a wafer.\n</p>\n<ul>\n <li>\n  <strong>\n   nMOS Transistors:\n  </strong>\n  These have n-type dopants for the source and drain regions and are built on a p-type semiconductor substrate.\n </li>\n <li>\n  <strong>\n   pMOS Transistors:\n  </strong>\n  These are the opposite, featuring p-type source and drain regions on an n-type substrate.\n </li>\n</ul>\n<p>\n A MOSFET acts as a voltage-controlled switch, where the gate voltage creates an electric field that turns the connection between the source and drain ON or OFF. This is why it\u2019s called a field-effect transistor.\n</p>\n<h4>\n nMOS Transistor Operation\n</h4>\n<p>\n For an nMOS transistor, the substrate is usually connected to ground (GND), the lowest voltage.\n</p>\n<ol>\n <li>\n  <p>\n   <strong>\n    When the Gate is at 0 V:\n   </strong>\n  </p>\n  <ul>\n   <li>\n    As shown in Figure 1.30(a), both the source and drain are reverse-biased, meaning no current can flow between them. Therefore, the transistor is OFF.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    When the Gate is at VDD:\n   </strong>\n  </p>\n  <ul>\n   <li>\n    In Figure 1.30(b), when a positive voltage is applied to the gate, it creates an electric field that attracts charges. If this voltage is high enough, it can convert the p-type region underneath the gate into n-type. This newly formed n-type area is called the channel.\n   </li>\n   <li>\n    With the channel established, electrons can flow from the n-type source through the channel to the n-type drain, turning the transistor ON.\n   </li>\n  </ul>\n </li>\n</ol>\n<p>\n The voltage needed to switch the transistor ON is known as the\n <strong>\n  threshold voltage (Vt)\n </strong>\n , which is typically between 0.3 V and 0.7 V.\n</p>\n<h3>\n Charge Flow\n</h3>\n<p>\n Although the source and drain terminals are physically identical, charge flows from the source to the drain:\n</p>\n<ul>\n <li>\n  In an\n  <strong>\n   nMOS transistor\n  </strong>\n  , electrons (negative charges) move from the source (lower voltage) to the drain (higher voltage).\n </li>\n <li>\n  In a\n  <strong>\n   pMOS transistor\n  </strong>\n  , holes (positive charges) flow from the source (higher voltage) to the drain (lower voltage).\n </li>\n</ul>\n<p>\n In circuit schematics, the highest voltage is at the top and the lowest at the bottom. Therefore, in an nMOS transistor, the source is the bottom terminal (negative charge), while in a pMOS transistor, the source is the top terminal (positive charge).\n</p>\n"}, "Page 36": {"response": "<h3>\n pMOS Transistors\n</h3>\n<p>\n pMOS transistors operate differently from nMOS transistors. In a pMOS transistor:\n</p>\n<ul>\n <li>\n  The substrate is connected to VDD (the highest voltage).\n </li>\n <li>\n  When the gate is also at VDD, the transistor is OFF.\n </li>\n <li>\n  When the gate is at GND (0 V), the channel becomes p-type, and the transistor is ON.\n </li>\n</ul>\n<p>\n However, neither type of MOSFET is a perfect switch:\n</p>\n<ul>\n <li>\n  <strong>\n   nMOS transistors\n  </strong>\n  work well for passing 0's but poorly for passing 1's. When the gate is at VDD, the drain can only output between 0 and VDD minus the threshold voltage (Vt).\n </li>\n <li>\n  <strong>\n   pMOS transistors\n  </strong>\n  are the opposite; they pass 1's well but struggle with 0's.\n </li>\n</ul>\n<p>\n To address these limitations, logic gates can be designed to utilize each type of transistor in its effective mode.\n</p>\n<h3>\n Manufacturing CMOS Transistors\n</h3>\n<p>\n Both nMOS and pMOS transistors need different substrate types to function:\n</p>\n<ul>\n <li>\n  nMOS requires a p-type substrate.\n </li>\n <li>\n  pMOS needs an n-type substrate.\n </li>\n</ul>\n<p>\n To create both types on the same chip, manufacturers usually start with a p-type wafer and implant n-type regions (called wells) where pMOS transistors will be placed. This combined approach is known as\n <strong>\n  Complementary MOS (CMOS)\n </strong>\n , and it's widely used in modern transistor fabrication.\n</p>\n<h3>\n Summary of CMOS Functionality\n</h3>\n<p>\n CMOS technology provides two types of switches regulated by gate voltage:\n</p>\n<ul>\n <li>\n  <strong>\n   nMOS Transistors:\n  </strong>\n  <ul>\n   <li>\n    OFF when the gate (g) is at 0 (GND).\n   </li>\n   <li>\n    ON when the gate is at 1 (VDD).\n   </li>\n  </ul>\n </li>\n <li>\n  <strong>\n   pMOS Transistors:\n  </strong>\n  <ul>\n   <li>\n    OFF when the gate is at 1 (VDD).\n   </li>\n   <li>\n    ON when the gate is at 0 (GND).\n   </li>\n  </ul>\n </li>\n</ul>\n<p>\n This setup allows efficient control of current flow between the source (s) and drain (d) terminals of the transistors.\n</p>\n"}, "Page 37": {"response": "<h3>\n pMOS Transistors\n</h3>\n<p>\n pMOS transistors work oppositely compared to nMOS transistors. They are:\n</p>\n<ul>\n <li>\n  <strong>\n   ON\n  </strong>\n  when the gate is at 0 (GND).\n </li>\n <li>\n  <strong>\n   OFF\n  </strong>\n  when the gate is at 1 (VDD).\n </li>\n</ul>\n<h3>\n CMOS NOT Gate\n</h3>\n<p>\n A NOT gate using CMOS transistors is shown in Figure 1.32. Here's how it works:\n</p>\n<ul>\n <li>\n  The nMOS transistor (N1) connects GND to the output (Y).\n </li>\n <li>\n  The pMOS transistor (P1) connects VDD to the output (Y).\n </li>\n <li>\n  Both transistors are controlled by the input (A).\n </li>\n</ul>\n<p>\n <strong>\n  Operation:\n </strong>\n</p>\n<ul>\n <li>\n  When\n  <strong>\n   A = 0\n  </strong>\n  : N1 is OFF, and P1 is ON. Y connects to VDD, giving a logic 1.\n </li>\n <li>\n  When\n  <strong>\n   A = 1\n  </strong>\n  : N1 is ON, and P1 is OFF. Y connects to GND, giving a logic 0.\n </li>\n</ul>\n<p>\n This confirms the circuit functions as a NOT gate, as shown in the truth table.\n</p>\n<h3>\n Other CMOS Logic Gates\n</h3>\n<p>\n Figure 1.33 illustrates a two-input NAND gate. In this schematic:\n</p>\n<ul>\n <li>\n  nMOS transistors (N1 and N2) are connected in series. Both must be ON to pull the output (Y) down to GND.\n </li>\n <li>\n  pMOS transistors (P1 and P2) are in parallel. Only one needs to be ON to pull the output up to VDD.\n </li>\n</ul>\n<p>\n <strong>\n  Operation Example:\n </strong>\n</p>\n<ul>\n <li>\n  For\n  <strong>\n   A = 1\n  </strong>\n  and\n  <strong>\n   B = 0\n  </strong>\n  : N1 is ON, N2 is OFF, preventing Y from going to GND. P1 is OFF, but P2 is ON, pulling Y up to 1.\n </li>\n</ul>\n<p>\n Table 1.6 details the operations of the pull-down and pull-up networks, confirming that the gate functions as a NAND.\n</p>\n<h3>\n General Form of Inverting Logic Gates\n</h3>\n<p>\n Figure 1.34 shows the standard design for any inverting logic gate, like NOT, NAND, or NOR. The setup includes:\n</p>\n<ul>\n <li>\n  <strong>\n   nMOS Transistors\n  </strong>\n  : Form a pull-down network between the output and GND to pull the output down to 0.\n </li>\n <li>\n  <strong>\n   pMOS Transistors\n  </strong>\n  : Form a pull-up network to pull the output up to 1.\n </li>\n</ul>\n<p>\n This structure takes advantage of nMOS transistors being effective at passing 0's and pMOS transistors at passing 1's.\n</p>\n"}, "Page 38": {"response": "<h3>\n Pull-Up and Pull-Down Networks\n</h3>\n<p>\n In CMOS logic gates, pMOS transistors are used to pull the output up to 1 (VDD) and nMOS transistors are used to pull the output down to 0 (GND).\n</p>\n<ul>\n <li>\n  <strong>\n   Transistor Configuration\n  </strong>\n  :\n  <ul>\n   <li>\n    <strong>\n     Parallel Configuration\n    </strong>\n    : The network is ON if at least one transistor is ON.\n   </li>\n   <li>\n    <strong>\n     Series Configuration\n    </strong>\n    : The network is ON only if all transistors are ON.\n   </li>\n  </ul>\n </li>\n</ul>\n<p>\n A slash across the input wire indicates that the gate can accept multiple inputs.\n</p>\n<h3>\n Important Considerations\n</h3>\n<p>\n If both pull-up and pull-down networks are ON at the same time, it creates a short circuit between VDD and GND, leading to excessive power consumption that could damage the circuit. If both networks are OFF, the output \"floats,\" meaning it is not connected to either VDD or GND, resulting in an undefined value. Floating outputs are generally not ideal, but they can be used strategically in certain designs.\n</p>\n<p>\n For a logic gate to function correctly, one network should be ON while the other is OFF. This can be ensured using the rule of conduction complements:\n</p>\n<ul>\n <li>\n  When nMOS transistors are in series, the pMOS transistors must be in parallel.\n </li>\n <li>\n  When nMOS transistors are in parallel, the pMOS transistors must be in series.\n </li>\n</ul>\n<h3>\n Examples of CMOS Logic Gates\n</h3>\n<ol>\n <li>\n  <p>\n   <strong>\n    Three-Input NAND Gate\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Design\n    </strong>\n    : The pull-down network consists of three nMOS transistors in series, meaning the output will be 0 only when all three inputs are 1.\n   </li>\n   <li>\n    <strong>\n     pMOS Configuration\n    </strong>\n    : By the conduction complements rule, the pMOS transistors will be in parallel.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Two-Input NOR Gate\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Design\n    </strong>\n    : The pull-down network contains two nMOS transistors in parallel, ensuring the output is 0 if either input is 1.\n   </li>\n   <li>\n    <strong>\n     pMOS Configuration\n    </strong>\n    : The corresponding pMOS transistors must be in series.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Two-Input AND Gate\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Design\n    </strong>\n    : This requires a specific arrangement of nMOS and pMOS transistors based on the desired logic function.\n   </li>\n  </ul>\n </li>\n</ol>\n<h3>\n Conclusion\n</h3>\n<p>\n Understanding how pull-up and pull-down networks operate in CMOS gates is essential for designing effective digital circuits. Ensuring that one network is ON while the other is OFF prevents power waste and maintains proper output levels.\n</p>\n"}, "Page 39": {"response": "<h3>\n Building an AND Gate\n</h3>\n<p>\n It's not possible to create a standalone AND gate using just one CMOS gate. Instead, you can easily build NAND and NOT gates. The best way to create an AND gate with CMOS transistors is to first use a NAND gate followed by a NOT gate.\n</p>\n<h3>\n Transmission Gates\n</h3>\n<p>\n Sometimes, designers need a switch that can pass both 0 and 1 values effectively. nMOS transistors are good at passing 0s, while pMOS transistors are good at passing 1s. By combining both types of transistors in parallel, you create a transmission gate, also known as a pass gate.\n</p>\n<ul>\n <li>\n  <strong>\n   Operation\n  </strong>\n  :\n  <ul>\n   <li>\n    The two sides of the switch are labeled A and B, indicating that it's bidirectional.\n   </li>\n   <li>\n    There are two control signals, EN (enable) and\n    E\n    N\n    \u203e\n    \\overline{EN}\n    EN\n    (not enable).\n   </li>\n   <li>\n    When EN is 0 and\n    E\n    N\n    \u203e\n    \\overline{EN}\n    EN\n    is 1, both transistors are OFF, so A and B are not connected (the gate is disabled).\n   </li>\n   <li>\n    When EN is 1 and\n    E\n    N\n    \u203e\n    \\overline{EN}\n    EN\n    is 0, the transmission gate is ON, allowing logic values to flow freely between A and B.\n   </li>\n  </ul>\n </li>\n</ul>\n<h3>\n Pseudo-nMOS Logic\n</h3>\n<p>\n In a standard N-input CMOS NOR gate, nMOS transistors are connected in parallel and pMOS transistors in series. Series connections are slower than parallel ones, and pMOS transistors are generally slower than nMOS transistors because holes (in pMOS) move more slowly than electrons (in nMOS).\n</p>\n<p>\n <strong>\n  Pseudo-nMOS logic\n </strong>\n addresses this speed issue by using one weak pMOS transistor that is always ON, instead of multiple pMOS transistors in series. This weak pMOS, often called a weak pull-up, can pull the output (Y) high but only when none of the nMOS transistors are ON. If any nMOS transistor is ON, it will overpower the weak pull-up and pull Y down close to GND, resulting in a logic 0.\n</p>\n<ul>\n <li>\n  <strong>\n   Advantages\n  </strong>\n  : Pseudo-nMOS logic allows for fast NOR gates with many inputs, making it useful in certain memory and logic circuits.\n </li>\n <li>\n  <strong>\n   Disadvantages\n  </strong>\n  : A short circuit occurs between VDD and GND when the output is LOW because both the weak pMOS and nMOS transistors are ON. This draws continuous power, so pseudo-nMOS logic should be used carefully.\n </li>\n</ul>\n<h3>\n Summary\n</h3>\n<ul>\n <li>\n  To build an AND gate, use a combination of NAND and NOT gates.\n </li>\n <li>\n  Transmission gates enable bidirectional signal flow and can pass both 0s and 1s effectively.\n </li>\n <li>\n  Pseudo-nMOS logic speeds up NOR gate operations but has the drawback of potential power waste due to short circuits when the output is LOW.\n </li>\n</ul>\n"}, "Page 40": {"response": "<h3>\n Pseudo-nMOS Gates\n</h3>\n<p>\n Pseudo-nMOS gates were named in the 1970s when only nMOS transistors were available. At that time, a weak nMOS transistor was used to pull the output HIGH because pMOS transistors did not exist.\n</p>\n<h3>\n Power Consumption\n</h3>\n<p>\n Power consumption refers to the amount of energy used over time and is crucial in digital systems. It affects battery life in portable devices like cell phones and laptops. High power consumption can also lead to overheating in plugged-in devices and increases electricity costs.\n</p>\n<p>\n There are two main types of power consumption in digital systems:\n</p>\n<ol>\n <li>\n  <p>\n   <strong>\n    Dynamic Power\n   </strong>\n   : This is the power used when signals change from 0 to 1. Every logic gate and connecting wire has capacitance. The energy needed to charge a capacitance\n   C\n   C\n   C\n   to a voltage\n   V\n   D\n   D\n   V_{DD}\n   V\n   DD\n   \u200b\n   is\n   C\n   V\n   D\n   D\n   2\n   CV_{DD}^2\n   C\n   V\n   DD\n   2\n   \u200b\n   . If the capacitor switches at a frequency\n   f\n   f\n   f\n   , it charges and discharges\n   f\n   /\n   2\n   f/2\n   f\n   /2\n   times per second. The formula for dynamic power consumption is:\n  </p>\n  P\n  d\n  y\n  n\n  a\n  m\n  i\n  c\n  =\n  C\n  V\n  D\n  D\n  2\n  f\n  P_{dynamic} = CV_{DD}^2 f\n  P\n  d\n  y\n  nami\n  c\n  \u200b\n  =\n  C\n  V\n  DD\n  2\n  \u200b\n  f\n </li>\n <li>\n  <p>\n   <strong>\n    Static Power\n   </strong>\n   : This power is consumed even when signals are not changing and the system is idle. Transistors leak a small amount of current when they are OFF. Some circuits, like pseudo-nMOS gates, allow continuous current flow from\n   V\n   D\n   D\n   V_{DD}\n   V\n   DD\n   \u200b\n   to GND. The total static current,\n   I\n   D\n   D\n   I_{DD}\n   I\n   DD\n   \u200b\n   , is also known as leakage current. The static power consumption can be calculated with:\n  </p>\n  P\n  s\n  t\n  a\n  t\n  i\n  c\n  =\n  I\n  D\n  D\n  V\n  D\n  D\n  P_{static} = I_{DD} V_{DD}\n  P\n  s\n  t\n  a\n  t\n  i\n  c\n  \u200b\n  =\n  I\n  DD\n  \u200b\n  V\n  DD\n  \u200b\n </li>\n</ol>\n<h3>\n Example: Power Consumption in a Cell Phone\n</h3>\n<p>\n Consider a cell phone with a 6 watt-hour (W-hr) battery operating at 1.2 V. When in use, it runs at 300 MHz with an average capacitance of 10 nF (10^-8 Farads) and broadcasts 3 W of power. While in use, dynamic power consumption is significant, but when idle, it drops close to zero, though the phone still draws 40 mA of quiescent current.\n</p>\n<p>\n To determine the battery life:\n</p>\n<ul>\n <li>\n  <p>\n   <strong>\n    When Not in Use\n   </strong>\n   : Calculate the static power using the quiescent current:\n  </p>\n  P\n  s\n  t\n  a\n  t\n  i\n  c\n  =\n  0.04\n  A\n  \u00d7\n  1.2\n  V\n  =\n  0.048\n  W\n  P_{static} = 0.04 \\, \\text{A} \\times 1.2 \\, \\text{V} = 0.048 \\, \\text{W}\n  P\n  s\n  t\n  a\n  t\n  i\n  c\n  \u200b\n  =\n  0.04\n  A\n  \u00d7\n  1.2\n  V\n  =\n  0.048\n  W\n </li>\n <li>\n  <p>\n   <strong>\n    When in Use\n   </strong>\n   : Calculate both dynamic and static power. The dynamic power:\n  </p>\n  P\n  d\n  y\n  n\n  a\n  m\n  i\n  c\n  =\n  C\n  V\n  D\n  D\n  2\n  f\n  =\n  10\n  \u00d7\n  1\n  0\n  \u2212\n  9\n  F\n  \u00d7\n  (\n  1.2\n  V\n  )\n  2\n  \u00d7\n  300\n  \u00d7\n  1\n  0\n  6\n  Hz\n  \u2248\n  4.32\n  W\n  P_{dynamic} = C V_{DD}^2 f = 10 \\times 10^{-9} \\, \\text{F} \\times (1.2 \\, \\text{V})^2 \\times 300 \\times 10^6 \\, \\text{Hz} \\approx 4.32 \\, \\text{W}\n  P\n  d\n  y\n  nami\n  c\n  \u200b\n  =\n  C\n  V\n  DD\n  2\n  \u200b\n  f\n  =\n  10\n  \u00d7\n  1\n  0\n  \u2212\n  9\n  F\n  \u00d7\n  (\n  1.2\n  V\n  )\n  2\n  \u00d7\n  300\n  \u00d7\n  1\n  0\n  6\n  Hz\n  \u2248\n  4.32\n  W\n  <p>\n   Total power when in use:\n  </p>\n  P\n  t\n  o\n  t\n  a\n  l\n  =\n  P\n  d\n  y\n  n\n  a\n  m\n  i\n  c\n  +\n  P\n  b\n  r\n  o\n  a\n  d\n  c\n  a\n  s\n  t\n  \u2248\n  4.32\n  W\n  +\n  3\n  W\n  =\n  7.32\n  W\n  P_{total} = P_{dynamic} + P_{broadcast} \\approx 4.32 \\, \\text{W} + 3 \\, \\text{W} = 7.32 \\, \\text{W}\n  P\n  t\n  o\n  t\n  a\n  l\n  \u200b\n  =\n  P\n  d\n  y\n  nami\n  c\n  \u200b\n  +\n  P\n  b\n  ro\n  a\n  d\n  c\n  a\n  s\n  t\n  \u200b\n  \u2248\n  4.32\n  W\n  +\n  3\n  W\n  =\n  7.32\n  W\n </li>\n</ul>\n<p>\n Using these calculations, you can determine how long the battery lasts in each scenario.\n</p>\n"}, "Page 41": {"response": "<h3>\n Battery Life Calculation\n</h3>\n<ol>\n <li>\n  <p>\n   <strong>\n    Static Power Consumption\n   </strong>\n   : The static power of the phone is calculated as:\n  </p>\n  P\n  s\n  t\n  a\n  t\n  i\n  c\n  =\n  (\n  0.040\n  A\n  )\n  (\n  1.2\n  V\n  )\n  =\n  48\n  mW\n  P_{static} = (0.040 \\, \\text{A})(1.2 \\, \\text{V}) = 48 \\, \\text{mW}\n  P\n  s\n  t\n  a\n  t\n  i\n  c\n  \u200b\n  =\n  (\n  0.040\n  A\n  )\n  (\n  1.2\n  V\n  )\n  =\n  48\n  mW\n  <p>\n   When the phone is not in use, this is the only power it consumes. Therefore, the battery life can be calculated as:\n  </p>\n  Battery\u00a0Life\n  =\n  6\n  W-hr\n  0.048\n  W\n  \u2248\n  125\n  hours\n  (\n  about\u00a05\u00a0days\n  )\n  \\text{Battery Life} = \\frac{6 \\, \\text{W-hr}}{0.048 \\, \\text{W}} \\approx 125 \\, \\text{hours} \\quad (\\text{about 5 days})\n  Battery\u00a0Life\n  =\n  0.048\n  W\n  6\n  W-hr\n  \u200b\n  \u2248\n  125\n  hours\n  (\n  about\u00a05\u00a0days\n  )\n </li>\n <li>\n  <p>\n   <strong>\n    Dynamic Power Consumption\n   </strong>\n   : When the phone is in use, the dynamic power is:\n  </p>\n  P\n  d\n  y\n  n\n  a\n  m\n  i\n  c\n  =\n  (\n  0.5\n  )\n  (\n  1\n  0\n  \u2212\n  8\n  F\n  )\n  (\n  1.2\n  V\n  )\n  2\n  (\n  300\n  \u00d7\n  1\n  0\n  6\n  Hz\n  )\n  \u2248\n  2.16\n  W\n  P_{dynamic} = (0.5)(10^{-8} \\, \\text{F})(1.2 \\, \\text{V})^2(300 \\times 10^6 \\, \\text{Hz}) \\approx 2.16 \\, \\text{W}\n  P\n  d\n  y\n  nami\n  c\n  \u200b\n  =\n  (\n  0.5\n  )\n  (\n  1\n  0\n  \u2212\n  8\n  F\n  )\n  (\n  1.2\n  V\n  )\n  2\n  (\n  300\n  \u00d7\n  1\n  0\n  6\n  Hz\n  )\n  \u2248\n  2.16\n  W\n  <p>\n   Including static and broadcast power, the total active power becomes:\n  </p>\n  P\n  t\n  o\n  t\n  a\n  l\n  =\n  P\n  d\n  y\n  n\n  a\n  m\n  i\n  c\n  +\n  P\n  s\n  t\n  a\n  t\n  i\n  c\n  +\n  P\n  b\n  r\n  o\n  a\n  d\n  c\n  a\n  s\n  t\n  =\n  2.16\n  W\n  +\n  0.048\n  W\n  +\n  3\n  W\n  \u2248\n  5.2\n  W\n  P_{total} = P_{dynamic} + P_{static} + P_{broadcast} = 2.16 \\, \\text{W} + 0.048 \\, \\text{W} + 3 \\, \\text{W} \\approx 5.2 \\, \\text{W}\n  P\n  t\n  o\n  t\n  a\n  l\n  \u200b\n  =\n  P\n  d\n  y\n  nami\n  c\n  \u200b\n  +\n  P\n  s\n  t\n  a\n  t\n  i\n  c\n  \u200b\n  +\n  P\n  b\n  ro\n  a\n  d\n  c\n  a\n  s\n  t\n  \u200b\n  =\n  2.16\n  W\n  +\n  0.048\n  W\n  +\n  3\n  W\n  \u2248\n  5.2\n  W\n  <p>\n   Thus, the battery life when actively used is:\n  </p>\n  Battery\u00a0Life\n  =\n  6\n  W-hr\n  5.2\n  W\n  \u2248\n  1.15\n  hours\n  \\text{Battery Life} = \\frac{6 \\, \\text{W-hr}}{5.2 \\, \\text{W}} \\approx 1.15 \\, \\text{hours}\n  Battery\u00a0Life\n  =\n  5.2\n  W\n  6\n  W-hr\n  \u200b\n  \u2248\n  1.15\n  hours\n  <p>\n   This example simplifies the actual operation of a cell phone but effectively illustrates key power consumption concepts.\n  </p>\n </li>\n</ol>\n<h3>\n Summary and Future Topics\n</h3>\n<p>\n The chapter concludes with a humorous remark about binary counting: \"There are 10 kinds of people: those who can count in binary and those who can\u2019t.\"\n</p>\n<p>\n Key concepts introduced include:\n</p>\n<ul>\n <li>\n  <p>\n   <strong>\n    Binary Variables\n   </strong>\n   : Digital systems use discrete signals, specifically binary states: 0 (FALSE/LOW) and 1 (TRUE/HIGH).\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Logic Gates\n   </strong>\n   : These gates compute outputs based on binary inputs. Common gates include:\n  </p>\n  <ul>\n   <li>\n    <strong>\n     NOT\n    </strong>\n    : Outputs TRUE when the input is FALSE.\n   </li>\n   <li>\n    <strong>\n     AND\n    </strong>\n    : Outputs TRUE when all inputs are TRUE.\n   </li>\n   <li>\n    <strong>\n     OR\n    </strong>\n    : Outputs TRUE when any input is TRUE.\n   </li>\n   <li>\n    <strong>\n     XOR\n    </strong>\n    : Outputs TRUE when an odd number of inputs are TRUE.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    CMOS Transistors\n   </strong>\n   : These act as electrically controlled switches, with nMOS turning ON with a gate voltage of 1 and pMOS turning ON with a gate voltage of 0.\n  </p>\n </li>\n</ul>\n<h3>\n Looking Ahead\n</h3>\n<p>\n The next chapters will delve deeper into digital logic:\n</p>\n<ul>\n <li>\n  <p>\n   <strong>\n    Chapter 2\n   </strong>\n   : Focuses on combinational logic, where outputs depend solely on current inputs. You will learn to design circuits using multiple gates based on truth tables or Boolean equations.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Chapter 3\n   </strong>\n   : Covers sequential logic, where outputs depend on both current and past inputs. This includes elements like registers and finite state machines for more complex system design.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Chapter 4\n   </strong>\n   : Discusses hardware description languages (HDLs), which are used to design and simulate hardware, similar to programming languages but specifically for hardware systems. Verilog is one example of an HDL commonly used in digital design.\n  </p>\n </li>\n</ul>\n"}, "Page 42": {"response": "<h3>\n Future Chapters Overview\n</h3>\n<ul>\n <li>\n  <p>\n   <strong>\n    HDL Languages\n   </strong>\n   : The book covers two main hardware description languages: Verilog and VHDL. Both are essential for designing digital systems.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Chapter 5\n   </strong>\n   : Focuses on additional combinational and sequential components like adders, multipliers, and memory units.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Chapter 6\n   </strong>\n   : Introduces computer architecture, specifically the MIPS processor. This widely used microprocessor is found in consumer electronics, Silicon Graphics workstations, and various communication devices like TVs and networking hardware. You will learn about the MIPS architecture, including its registers and assembly language, and how to write programs in assembly for this processor.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Chapters 7 and 8\n   </strong>\n   : Connect digital logic to computer architecture.\n  </p>\n  <ul>\n   <li>\n    <strong>\n     Chapter 7\n    </strong>\n    : Explores microarchitecture, which is how digital components like adders and registers are organized to build a processor. You will have the opportunity to design your own MIPS processor and examine three different microarchitectures that showcase various trade-offs in performance and cost.\n   </li>\n   <li>\n    <strong>\n     Chapter 8\n    </strong>\n    : Discusses memory system architecture and explains how computers interact with peripheral devices like keyboards and printers.\n   </li>\n  </ul>\n </li>\n</ul>\n<p>\n These chapters provide a comprehensive understanding of digital systems, from basic logic gates to advanced processor design and memory architecture.\n</p>\n"}, "Page 43": {"response": "<h3>\n Exercises\n</h3>\n<ol>\n <li>\n  <p>\n   <strong>\n    Levels of Abstraction\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <p>\n     <strong>\n      a)\n     </strong>\n     For biologists studying cells, three levels of abstraction include:\n    </p>\n    <ol>\n     <li>\n      <strong>\n       Molecular Level\n      </strong>\n      : Understanding the interactions between proteins and DNA.\n     </li>\n     <li>\n      <strong>\n       Cellular Level\n      </strong>\n      : Analyzing how different types of cells function and interact within an organism.\n     </li>\n     <li>\n      <strong>\n       Organism Level\n      </strong>\n      : Studying the overall behavior and characteristics of an entire organism.\n     </li>\n    </ol>\n   </li>\n   <li>\n    <p>\n     <strong>\n      b)\n     </strong>\n     For chemists studying matter, three levels of abstraction are:\n    </p>\n    <ol>\n     <li>\n      <strong>\n       Atomic Level\n      </strong>\n      : Examining the properties and behavior of individual atoms.\n     </li>\n     <li>\n      <strong>\n       Molecular Level\n      </strong>\n      : Investigating how atoms bond to form molecules and the properties of these molecules.\n     </li>\n     <li>\n      <strong>\n       Macroscopic Level\n      </strong>\n      : Observing the bulk properties of substances, such as phase changes and reactions.\n     </li>\n    </ol>\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Techniques of Hierarchy, Modularity, and Regularity\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <p>\n     <strong>\n      a)\n     </strong>\n     In automobile design, these techniques can help by:\n    </p>\n    <ol>\n     <li>\n      <strong>\n       Hierarchy\n      </strong>\n      : Organizing design processes from general vehicle design down to specific components like engines and interiors.\n     </li>\n     <li>\n      <strong>\n       Modularity\n      </strong>\n      : Creating interchangeable parts that can be easily replaced or upgraded, like standardized engine sizes.\n     </li>\n     <li>\n      <strong>\n       Regularity\n      </strong>\n      : Implementing consistent design patterns that streamline production and maintenance.\n     </li>\n    </ol>\n   </li>\n   <li>\n    <p>\n     <strong>\n      b)\n     </strong>\n     In businesses, these techniques can be applied by:\n    </p>\n    <ol>\n     <li>\n      <strong>\n       Hierarchy\n      </strong>\n      : Structuring the organization into levels, from executives to employees, to clarify roles and responsibilities.\n     </li>\n     <li>\n      <strong>\n       Modularity\n      </strong>\n      : Developing independent departments that can operate semi-autonomously while contributing to the overall goals.\n     </li>\n     <li>\n      <strong>\n       Regularity\n      </strong>\n      : Establishing standard operating procedures that ensure consistency in processes and outputs.\n     </li>\n    </ol>\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Construction Principles\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Ben Bitdiddle can use hierarchy, modularity, and regularity by:\n    <ol>\n     <li>\n      <strong>\n       Hierarchy\n      </strong>\n      : Planning the construction process in stages, from site preparation to final touches.\n     </li>\n     <li>\n      <strong>\n       Modularity\n      </strong>\n      : Using prefabricated modules for sections of the house, which speeds up assembly and reduces waste.\n     </li>\n     <li>\n      <strong>\n       Regularity\n      </strong>\n      : Following standard dimensions and practices to simplify construction and minimize errors.\n     </li>\n    </ol>\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Analog Voltage Measurement\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    If an analog voltage ranges from 0 to 5 V with an accuracy of \u00b150 mV, it conveys a maximum of:\n    Number\u00a0of\u00a0levels\n    =\n    5\n    V\n    \u2212\n    0\n    V\n    0.050\n    V\n    =\n    100\n    levels\n    \\text{Number of levels} = \\frac{5 \\text{ V} - 0 \\text{ V}}{0.050 \\text{ V}} = 100 \\text{ levels}\n    Number\u00a0of\u00a0levels\n    =\n    0.050\n    V\n    5\n    V\n    \u2212\n    0\n    V\n    \u200b\n    =\n    100\n    levels\n    To find bits of information, use the formula:\n    Bits\n    =\n    log\n    \u2061\n    2\n    (\n    100\n    )\n    \u2248\n    6.64\n    bits\n    \\text{Bits} = \\log_2(100) \\approx 6.64 \\text{ bits}\n    Bits\n    =\n    lo\n    g\n    2\n    \u200b\n    (\n    100\n    )\n    \u2248\n    6.64\n    bits\n    So, it conveys about 6 bits of information.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Old Clock Information\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     a)\n    </strong>\n    If the hour hand can be read to the nearest 15 minutes, it conveys:\n    Possible\u00a0readings\n    =\n    4\n    (0,\u00a015,\u00a030,\u00a045\u00a0minutes)\n    \\text{Possible readings} = 4 \\text{ (0, 15, 30, 45 minutes)}\n    Possible\u00a0readings\n    =\n    4\n    (0,\u00a015,\u00a030,\u00a045\u00a0minutes)\n    Bits\n    =\n    log\n    \u2061\n    2\n    (\n    4\n    )\n    =\n    2\n    bits\n    \\text{Bits} = \\log_2(4) = 2 \\text{ bits}\n    Bits\n    =\n    lo\n    g\n    2\n    \u200b\n    (\n    4\n    )\n    =\n    2\n    bits\n   </li>\n   <li>\n    <strong>\n     b)\n    </strong>\n    Knowing if it's before or after noon adds 1 bit of information, making the total:\n    2\n    +\n    1\n    =\n    3\n    bits\n    2 + 1 = 3 \\text{ bits}\n    2\n    +\n    1\n    =\n    3\n    bits\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Sexagesimal System\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    One sexagesimal digit conveys:\n    Bits\n    =\n    log\n    \u2061\n    2\n    (\n    60\n    )\n    \u2248\n    5.91\n    bits\n    (\n    about\u00a06\u00a0bits\n    )\n    \\text{Bits} = \\log_2(60) \\approx 5.91 \\text{ bits} \\quad (\\text{about 6 bits})\n    Bits\n    =\n    lo\n    g\n    2\n    \u200b\n    (\n    60\n    )\n    \u2248\n    5.91\n    bits\n    (\n    about\u00a06\u00a0bits\n    )\n   </li>\n   <li>\n    The number 400010 in sexagesimal is written as:\n    <ul>\n     <li>\n      400010 = 4000 in decimal\n     </li>\n     <li>\n      4000 in sexagesimal is\n      66\n      40\n      66 \\, 40\n      66\n      40\n      , where\n      66\n      \u00d7\n      60\n      +\n      40\n      =\n      4000\n      66 \\times 60 + 40 = 4000\n      66\n      \u00d7\n      60\n      +\n      40\n      =\n      4000\n      .\n     </li>\n    </ul>\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    16-Bit Representation\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    The number of different values that can be represented with 16 bits is:\n    2\n    16\n    =\n    65\n    ,\n    536\n    different\u00a0numbers\n    2^{16} = 65,536 \\text{ different numbers}\n    2\n    16\n    =\n    65\n    ,\n    536\n    different\u00a0numbers\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Largest Unsigned 32-Bit Binary Number\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    The largest unsigned 32-bit binary number is:\n    2\n    32\n    \u2212\n    1\n    =\n    4\n    ,\n    294\n    ,\n    967\n    ,\n    295\n    2^{32} - 1 = 4,294,967,295\n    2\n    32\n    \u2212\n    1\n    =\n    4\n    ,\n    294\n    ,\n    967\n    ,\n    295\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Largest 16-Bit Binary Numbers\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     a)\n    </strong>\n    Unsigned:\n    2\n    16\n    \u2212\n    1\n    =\n    65\n    ,\n    535\n    2^{16} - 1 = 65,535\n    2\n    16\n    \u2212\n    1\n    =\n    65\n    ,\n    535\n   </li>\n   <li>\n    <strong>\n     b)\n    </strong>\n    Two\u2019s complement:\n    2\n    15\n    \u2212\n    1\n    =\n    32\n    ,\n    767\n    2^{15} - 1 = 32,767\n    2\n    15\n    \u2212\n    1\n    =\n    32\n    ,\n    767\n    (since the highest bit is for sign)\n   </li>\n   <li>\n    <strong>\n     c)\n    </strong>\n    Sign/magnitude:\n    2\n    15\n    \u2212\n    1\n    =\n    32\n    ,\n    767\n    2^{15} - 1 = 32,767\n    2\n    15\n    \u2212\n    1\n    =\n    32\n    ,\n    767\n    (also the highest bit is for sign)\n   </li>\n  </ul>\n </li>\n</ol>\n"}, "Page 44": {"response": "<h3>\n Exercises\n</h3>\n<ol start=\"10\">\n <li>\n  <strong>\n   Smallest (Most Negative) 16-Bit Binary Number\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  For unsigned numbers, the smallest value is:\n  <ul>\n   <li>\n    <strong>\n     0\n    </strong>\n    (since unsigned numbers cannot be negative).\n   </li>\n  </ul>\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  For two\u2019s complement numbers, the smallest value is:\n  <ul>\n   <li>\n    <strong>\n     -32,768\n    </strong>\n    (represented as 1000 0000 0000 0000 in binary).\n   </li>\n  </ul>\n </li>\n <li>\n  <strong>\n   c)\n  </strong>\n  For sign/magnitude numbers, the smallest value is:\n  <ul>\n   <li>\n    <strong>\n     -32,767\n    </strong>\n    (represented as 1000 0000 0000 0001 in binary).\n   </li>\n  </ul>\n </li>\n</ul>\n<ol start=\"11\">\n <li>\n  <strong>\n   Convert Unsigned Binary to Decimal\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  101\n  0\n  2\n  1010_2\n  101\n  0\n  2\n  \u200b\n  =\n  1\n  0\n  10\n  10_{10}\n  1\n  0\n  10\n  \u200b\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  11011\n  0\n  2\n  110110_2\n  11011\n  0\n  2\n  \u200b\n  =\n  5\n  4\n  10\n  54_{10}\n  5\n  4\n  10\n  \u200b\n </li>\n <li>\n  <strong>\n   c)\n  </strong>\n  1111000\n  0\n  2\n  11110000_2\n  1111000\n  0\n  2\n  \u200b\n  =\n  24\n  0\n  10\n  240_{10}\n  24\n  0\n  10\n  \u200b\n </li>\n <li>\n  <strong>\n   d)\n  </strong>\n  000110001010011\n  1\n  2\n  0001100010100111_2\n  000110001010011\n  1\n  2\n  \u200b\n  =\n  19\n  9\n  10\n  199_{10}\n  19\n  9\n  10\n  \u200b\n </li>\n</ul>\n<ol start=\"12\">\n <li>\n  <strong>\n   Convert Unsigned Binary to Hexadecimal\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  101\n  0\n  2\n  1010_2\n  101\n  0\n  2\n  \u200b\n  =\n  A\n  16\n  A_{16}\n  A\n  16\n  \u200b\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  11011\n  0\n  2\n  110110_2\n  11011\n  0\n  2\n  \u200b\n  =\n  3\n  6\n  16\n  36_{16}\n  3\n  6\n  16\n  \u200b\n </li>\n <li>\n  <strong>\n   c)\n  </strong>\n  1111000\n  0\n  2\n  11110000_2\n  1111000\n  0\n  2\n  \u200b\n  =\n  F\n  0\n  16\n  F0_{16}\n  F\n  0\n  16\n  \u200b\n </li>\n <li>\n  <strong>\n   d)\n  </strong>\n  000110001010011\n  1\n  2\n  0001100010100111_2\n  000110001010011\n  1\n  2\n  \u200b\n  =\n  C\n  7\n  16\n  C7_{16}\n  C\n  7\n  16\n  \u200b\n </li>\n</ul>\n<ol start=\"13\">\n <li>\n  <strong>\n   Convert Hexadecimal to Decimal\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  A\n  5\n  16\n  A5_{16}\n  A\n  5\n  16\n  \u200b\n  =\n  16\n  5\n  10\n  165_{10}\n  16\n  5\n  10\n  \u200b\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  3\n  B\n  16\n  3B_{16}\n  3\n  B\n  16\n  \u200b\n  =\n  5\n  9\n  10\n  59_{10}\n  5\n  9\n  10\n  \u200b\n </li>\n <li>\n  <strong>\n   c)\n  </strong>\n  F\n  F\n  F\n  F\n  16\n  FFFF_{16}\n  FFF\n  F\n  16\n  \u200b\n  =\n  65\n  ,\n  53\n  5\n  10\n  65,535_{10}\n  65\n  ,\n  53\n  5\n  10\n  \u200b\n </li>\n <li>\n  <strong>\n   d)\n  </strong>\n  D\n  000000\n  0\n  16\n  D0000000_{16}\n  D\n  000000\n  0\n  16\n  \u200b\n  =\n  3\n  ,\n  221\n  ,\n  225\n  ,\n  09\n  7\n  10\n  3,221,225,097_{10}\n  3\n  ,\n  221\n  ,\n  225\n  ,\n  09\n  7\n  10\n  \u200b\n </li>\n</ul>\n<ol start=\"14\">\n <li>\n  <strong>\n   Convert Hexadecimal to Unsigned Binary\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  A\n  5\n  16\n  A5_{16}\n  A\n  5\n  16\n  \u200b\n  =\n  1010010\n  1\n  2\n  10100101_2\n  1010010\n  1\n  2\n  \u200b\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  3\n  B\n  16\n  3B_{16}\n  3\n  B\n  16\n  \u200b\n  =\n  0011101\n  1\n  2\n  00111011_2\n  0011101\n  1\n  2\n  \u200b\n </li>\n <li>\n  <strong>\n   c)\n  </strong>\n  F\n  F\n  F\n  F\n  16\n  FFFF_{16}\n  FFF\n  F\n  16\n  \u200b\n  =\n  111111111111111\n  1\n  2\n  1111111111111111_2\n  111111111111111\n  1\n  2\n  \u200b\n </li>\n <li>\n  <strong>\n   d)\n  </strong>\n  D\n  000000\n  0\n  16\n  D0000000_{16}\n  D\n  000000\n  0\n  16\n  \u200b\n  =\n  1101000000000000000000000000000\n  0\n  2\n  11010000 00000000 00000000 00000000_2\n  1101000000000000000000000000000\n  0\n  2\n  \u200b\n </li>\n</ul>\n<ol start=\"15\">\n <li>\n  <strong>\n   Convert Two\u2019s Complement Binary to Decimal\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  101\n  0\n  2\n  1010_2\n  101\n  0\n  2\n  \u200b\n  =\n  \u2212\n  6\n  10\n  -6_{10}\n  \u2212\n  6\n  10\n  \u200b\n  (since it's a negative number).\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  11011\n  0\n  2\n  110110_2\n  11011\n  0\n  2\n  \u200b\n  =\n  \u2212\n  4\n  2\n  10\n  -42_{10}\n  \u2212\n  4\n  2\n  10\n  \u200b\n  (negative).\n </li>\n <li>\n  <strong>\n   c)\n  </strong>\n  0111000\n  0\n  2\n  01110000_2\n  0111000\n  0\n  2\n  \u200b\n  =\n  11\n  2\n  10\n  112_{10}\n  11\n  2\n  10\n  \u200b\n  (positive).\n </li>\n <li>\n  <strong>\n   d)\n  </strong>\n  1001111\n  1\n  2\n  10011111_2\n  1001111\n  1\n  2\n  \u200b\n  =\n  \u2212\n  11\n  3\n  10\n  -113_{10}\n  \u2212\n  11\n  3\n  10\n  \u200b\n  (negative).\n </li>\n</ul>\n<ol start=\"16\">\n <li>\n  <strong>\n   Convert Sign/Magnitude Binary to Decimal\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  101\n  0\n  2\n  1010_2\n  101\n  0\n  2\n  \u200b\n  =\n  \u2212\n  2\n  10\n  -2_{10}\n  \u2212\n  2\n  10\n  \u200b\n  (indicating negative).\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  11011\n  0\n  2\n  110110_2\n  11011\n  0\n  2\n  \u200b\n  =\n  \u2212\n  5\n  4\n  10\n  -54_{10}\n  \u2212\n  5\n  4\n  10\n  \u200b\n  (indicating negative).\n </li>\n <li>\n  <strong>\n   c)\n  </strong>\n  0111000\n  0\n  2\n  01110000_2\n  0111000\n  0\n  2\n  \u200b\n  =\n  11\n  2\n  10\n  112_{10}\n  11\n  2\n  10\n  \u200b\n  (positive).\n </li>\n <li>\n  <strong>\n   d)\n  </strong>\n  1001111\n  1\n  2\n  10011111_2\n  1001111\n  1\n  2\n  \u200b\n  =\n  \u2212\n  11\n  3\n  10\n  -113_{10}\n  \u2212\n  11\n  3\n  10\n  \u200b\n  (indicating negative).\n </li>\n</ul>\n<ol start=\"17\">\n <li>\n  <strong>\n   Convert Decimal to Unsigned Binary\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  4\n  2\n  10\n  42_{10}\n  4\n  2\n  10\n  \u200b\n  =\n  0010101\n  0\n  2\n  00101010_2\n  0010101\n  0\n  2\n  \u200b\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  6\n  3\n  10\n  63_{10}\n  6\n  3\n  10\n  \u200b\n  =\n  0011111\n  1\n  2\n  00111111_2\n  0011111\n  1\n  2\n  \u200b\n </li>\n</ul>\n"}, "Page 45": {"response": "<h3>\n Exercises\n</h3>\n<ol start=\"18\">\n <li>\n  <strong>\n   Convert Decimal to Unsigned Binary\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  <strong>\n   c)\n  </strong>\n  22\n  9\n  10\n  229_{10}\n  22\n  9\n  10\n  \u200b\n  =\n  1110010\n  1\n  2\n  11100101_2\n  1110010\n  1\n  2\n  \u200b\n </li>\n <li>\n  <strong>\n   d)\n  </strong>\n  84\n  5\n  10\n  845_{10}\n  84\n  5\n  10\n  \u200b\n  =\n  110100110\n  1\n  2\n  1101001101_2\n  110100110\n  1\n  2\n  \u200b\n </li>\n</ul>\n<ol start=\"19\">\n <li>\n  <strong>\n   Convert Decimal to 8-Bit Two's Complement\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  4\n  2\n  10\n  42_{10}\n  4\n  2\n  10\n  \u200b\n  =\n  0010101\n  0\n  2\n  00101010_2\n  0010101\n  0\n  2\n  \u200b\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  6\n  3\n  10\n  63_{10}\n  6\n  3\n  10\n  \u200b\n  =\n  0011111\n  1\n  2\n  00111111_2\n  0011111\n  1\n  2\n  \u200b\n </li>\n <li>\n  <strong>\n   c)\n  </strong>\n  12\n  4\n  10\n  124_{10}\n  12\n  4\n  10\n  \u200b\n  =\n  <strong>\n   Overflow\n  </strong>\n  (exceeds 8-bit range).\n </li>\n <li>\n  <strong>\n   d)\n  </strong>\n  \u2212\n  12\n  8\n  10\n  -128_{10}\n  \u2212\n  12\n  8\n  10\n  \u200b\n  =\n  1000000\n  0\n  2\n  10000000_2\n  1000000\n  0\n  2\n  \u200b\n  (represents the lowest negative value).\n </li>\n <li>\n  <strong>\n   e)\n  </strong>\n  13\n  3\n  10\n  133_{10}\n  13\n  3\n  10\n  \u200b\n  =\n  <strong>\n   Overflow\n  </strong>\n  (exceeds 8-bit range).\n </li>\n</ul>\n<ol start=\"20\">\n <li>\n  <strong>\n   Convert Decimal to 8-Bit Sign/Magnitude\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  4\n  2\n  10\n  42_{10}\n  4\n  2\n  10\n  \u200b\n  =\n  0010101\n  0\n  2\n  00101010_2\n  0010101\n  0\n  2\n  \u200b\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  6\n  3\n  10\n  63_{10}\n  6\n  3\n  10\n  \u200b\n  =\n  0011111\n  1\n  2\n  00111111_2\n  0011111\n  1\n  2\n  \u200b\n </li>\n <li>\n  <strong>\n   c)\n  </strong>\n  12\n  4\n  10\n  124_{10}\n  12\n  4\n  10\n  \u200b\n  =\n  <strong>\n   Overflow\n  </strong>\n  (exceeds 8-bit range).\n </li>\n <li>\n  <strong>\n   d)\n  </strong>\n  \u2212\n  12\n  8\n  10\n  -128_{10}\n  \u2212\n  12\n  8\n  10\n  \u200b\n  =\n  1000000\n  0\n  2\n  10000000_2\n  1000000\n  0\n  2\n  \u200b\n </li>\n <li>\n  <strong>\n   e)\n  </strong>\n  13\n  3\n  10\n  133_{10}\n  13\n  3\n  10\n  \u200b\n  =\n  <strong>\n   Overflow\n  </strong>\n  (exceeds 8-bit range).\n </li>\n</ul>\n<ol start=\"21\">\n <li>\n  <strong>\n   Convert 4-Bit Two's Complement to 8-Bit\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  010\n  1\n  2\n  0101_2\n  010\n  1\n  2\n  \u200b\n  =\n  0000010\n  1\n  2\n  00000101_2\n  0000010\n  1\n  2\n  \u200b\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  101\n  0\n  2\n  1010_2\n  101\n  0\n  2\n  \u200b\n  =\n  1111101\n  0\n  2\n  11111010_2\n  1111101\n  0\n  2\n  \u200b\n </li>\n</ul>\n<ol start=\"22\">\n <li>\n  <strong>\n   Convert 4-Bit Unsigned to 8-Bit\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  010\n  1\n  2\n  0101_2\n  010\n  1\n  2\n  \u200b\n  =\n  0000010\n  1\n  2\n  00000101_2\n  0000010\n  1\n  2\n  \u200b\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  101\n  0\n  2\n  1010_2\n  101\n  0\n  2\n  \u200b\n  =\n  0000101\n  0\n  2\n  00001010_2\n  0000101\n  0\n  2\n  \u200b\n </li>\n</ul>\n<ol start=\"23\">\n <li>\n  <strong>\n   Convert Decimal to Octal\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  4\n  2\n  10\n  42_{10}\n  4\n  2\n  10\n  \u200b\n  =\n  5\n  2\n  8\n  52_8\n  5\n  2\n  8\n  \u200b\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  6\n  3\n  10\n  63_{10}\n  6\n  3\n  10\n  \u200b\n  =\n  7\n  7\n  8\n  77_8\n  7\n  7\n  8\n  \u200b\n </li>\n <li>\n  <strong>\n   c)\n  </strong>\n  12\n  4\n  10\n  124_{10}\n  12\n  4\n  10\n  \u200b\n  =\n  17\n  4\n  8\n  174_8\n  17\n  4\n  8\n  \u200b\n </li>\n <li>\n  <strong>\n   d)\n  </strong>\n  \u2212\n  12\n  8\n  10\n  -128_{10}\n  \u2212\n  12\n  8\n  10\n  \u200b\n  =\n  <strong>\n   Overflow\n  </strong>\n  (not applicable in octal).\n </li>\n</ul>\n<ol start=\"24\">\n <li>\n  <strong>\n   Convert Octal to Other Number Systems\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  4\n  2\n  8\n  42_8\n  4\n  2\n  8\n  \u200b\n  =\n  10001\n  0\n  2\n  100010_2\n  10001\n  0\n  2\n  \u200b\n  =\n  3\n  4\n  10\n  34_{10}\n  3\n  4\n  10\n  \u200b\n  =\n  2\n  2\n  16\n  22_{16}\n  2\n  2\n  16\n  \u200b\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  6\n  3\n  8\n  63_8\n  6\n  3\n  8\n  \u200b\n  =\n  11001\n  1\n  2\n  110011_2\n  11001\n  1\n  2\n  \u200b\n  =\n  5\n  1\n  10\n  51_{10}\n  5\n  1\n  10\n  \u200b\n  =\n  3\n  3\n  16\n  33_{16}\n  3\n  3\n  16\n  \u200b\n </li>\n <li>\n  <strong>\n   c)\n  </strong>\n  25\n  5\n  8\n  255_8\n  25\n  5\n  8\n  \u200b\n  =\n  10101010\n  1\n  2\n  101010101_2\n  10101010\n  1\n  2\n  \u200b\n  =\n  17\n  3\n  10\n  173_{10}\n  17\n  3\n  10\n  \u200b\n  =\n  A\n  D\n  16\n  AD_{16}\n  A\n  D\n  16\n  \u200b\n </li>\n <li>\n  <strong>\n   d)\n  </strong>\n  304\n  7\n  8\n  3047_8\n  304\n  7\n  8\n  \u200b\n  =\n  11000010011\n  1\n  2\n  110000100111_2\n  11000010011\n  1\n  2\n  \u200b\n  =\n  201\n  5\n  10\n  2015_{10}\n  201\n  5\n  10\n  \u200b\n  =\n  7\n  E\n  7\n  16\n  7E7_{16}\n  7\n  E\n  7\n  16\n  \u200b\n </li>\n</ul>\n<ol start=\"25\">\n <li>\n  <strong>\n   5-Bit Two's Complement Counts\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  Greater than 0:\n  <strong>\n   16 numbers\n  </strong>\n  (1 to 15).\n </li>\n <li>\n  Less than 0:\n  <strong>\n   16 numbers\n  </strong>\n  (-1 to -16).\n </li>\n <li>\n  For sign/magnitude:\n  <ul>\n   <li>\n    Greater than 0:\n    <strong>\n     15 numbers\n    </strong>\n    (1 to 15).\n   </li>\n   <li>\n    Less than 0:\n    <strong>\n     15 numbers\n    </strong>\n    (-1 to -15).\n   </li>\n  </ul>\n </li>\n</ul>\n"}, "Page 46": {"response": "<h3>\n Exercises\n</h3>\n<ol start=\"26\">\n <li>\n  <strong>\n   Bytes and Nibbles in a 32-Bit Word\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  A 32-bit word contains\n  <strong>\n   4 bytes\n  </strong>\n  (since 1 byte = 8 bits) and\n  <strong>\n   8 nibbles\n  </strong>\n  (since 1 nibble = 4 bits).\n </li>\n</ul>\n<ol start=\"27\">\n <li>\n  <strong>\n   Bytes in a 64-Bit Word\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  A 64-bit word contains\n  <strong>\n   8 bytes\n  </strong>\n  .\n </li>\n</ul>\n<ol start=\"28\">\n <li>\n  <strong>\n   Bytes Received by a DSL Modem\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  A DSL modem operating at\n  <strong>\n   768 kbits/sec\n  </strong>\n  can receive\n  <strong>\n   5,760 bytes in 1 minute\n  </strong>\n  (calculated as\n  768\n  ,\n  000\n  bits/sec\n  \u00d7\n  60\n  sec\n  \u00f7\n  8\n  bits/byte\n  768,000 \\text{ bits/sec} \\times 60 \\text{ sec} \\div 8 \\text{ bits/byte}\n  768\n  ,\n  000\n  bits/sec\n  \u00d7\n  60\n  sec\n  \u00f7\n  8\n  bits/byte\n  ).\n </li>\n</ul>\n<ol start=\"29\">\n <li>\n  <strong>\n   Real GBs of Music on a 50 GB Hard Disk\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  A hard disk labeled as\n  <strong>\n   50 GB\n  </strong>\n  using manufacturer definitions (where 1 GB =\n  1\n  0\n  9\n  10^9\n  1\n  0\n  9\n  bytes) actually holds about\n  <strong>\n   50 real GB\n  </strong>\n  (as opposed to the binary definition).\n </li>\n</ul>\n<ol start=\"30\">\n <li>\n  <strong>\n   Estimate the Value of\n   2\n   31\n   2^{31}\n   2\n   31\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  Without a calculator,\n  2\n  31\n  2^{31}\n  2\n  31\n  is approximately\n  <strong>\n   2 billion\n  </strong>\n  (as\n  2\n  30\n  \u2248\n  1\n  b\n  i\n  l\n  l\n  i\n  o\n  n\n  2^{30} \\approx 1 billion\n  2\n  30\n  \u2248\n  1\n  bi\n  ll\n  i\n  o\n  n\n  ).\n </li>\n</ul>\n<ol start=\"31\">\n <li>\n  <strong>\n   Estimate Memory Bits on Pentium II\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  The Pentium II memory with\n  <strong>\n   28 rows and 29 columns\n  </strong>\n  contains about\n  <strong>\n   536 million bits\n  </strong>\n  (calculated as\n  2\n  8\n  \u00d7\n  2\n  9\n  =\n  2\n  17\n  2^8 \\times 2^9 = 2^{17}\n  2\n  8\n  \u00d7\n  2\n  9\n  =\n  2\n  17\n  , so\n  2\n  28\n  \u00d7\n  2\n  29\n  =\n  2\n  57\n  2^{28} \\times 2^{29} = 2^{57}\n  2\n  28\n  \u00d7\n  2\n  29\n  =\n  2\n  57\n  ).\n </li>\n</ul>\n<ol start=\"32\">\n <li>\n  <strong>\n   Number Line for 3-Bit Numbers\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  Create a number line for\n  <strong>\n   3-bit unsigned\n  </strong>\n  ,\n  <strong>\n   two\u2019s complement\n  </strong>\n  , and\n  <strong>\n   sign/magnitude\n  </strong>\n  numbers showing their ranges and key values.\n </li>\n</ul>\n<ol start=\"33\">\n <li>\n  <strong>\n   Addition of 4-Bit Unsigned Numbers\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  100\n  1\n  2\n  +\n  010\n  0\n  2\n  1001_2 + 0100_2\n  100\n  1\n  2\n  \u200b\n  +\n  010\n  0\n  2\n  \u200b\n  =\n  110\n  1\n  2\n  1101_2\n  110\n  1\n  2\n  \u200b\n  (no overflow).\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  110\n  1\n  2\n  +\n  101\n  1\n  2\n  1101_2 + 1011_2\n  110\n  1\n  2\n  \u200b\n  +\n  101\n  1\n  2\n  \u200b\n  =\n  1100\n  0\n  2\n  11000_2\n  1100\n  0\n  2\n  \u200b\n  (overflows).\n </li>\n</ul>\n<ol start=\"34\">\n <li>\n  <strong>\n   Addition of 8-Bit Unsigned Numbers\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  1001100\n  1\n  2\n  +\n  0100010\n  0\n  2\n  10011001_2 + 01000100_2\n  1001100\n  1\n  2\n  \u200b\n  +\n  0100010\n  0\n  2\n  \u200b\n  =\n  1101110\n  1\n  2\n  11011101_2\n  1101110\n  1\n  2\n  \u200b\n  (no overflow).\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  1101001\n  0\n  2\n  +\n  1011011\n  0\n  2\n  11010010_2 + 10110110_2\n  1101001\n  0\n  2\n  \u200b\n  +\n  1011011\n  0\n  2\n  \u200b\n  =\n  11010100\n  0\n  2\n  110101000_2\n  11010100\n  0\n  2\n  \u200b\n  (overflows).\n </li>\n</ul>\n<ol start=\"35\">\n <li>\n  <strong>\n   Addition of 8-Bit Two's Complement Numbers\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  1001100\n  1\n  2\n  +\n  0100010\n  0\n  2\n  10011001_2 + 01000100_2\n  1001100\n  1\n  2\n  \u200b\n  +\n  0100010\n  0\n  2\n  \u200b\n  =\n  1101110\n  1\n  2\n  11011101_2\n  1101110\n  1\n  2\n  \u200b\n  (no overflow).\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  1101001\n  0\n  2\n  +\n  1011011\n  0\n  2\n  11010010_2 + 10110110_2\n  1101001\n  0\n  2\n  \u200b\n  +\n  1011011\n  0\n  2\n  \u200b\n  =\n  11010100\n  0\n  2\n  110101000_2\n  11010100\n  0\n  2\n  \u200b\n  (overflows).\n </li>\n</ul>\n<ol start=\"36\">\n <li>\n  <strong>\n   Convert Decimal to 6-Bit Two's Complement and Add\n  </strong>\n  :\n </li>\n</ol>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  1\n  6\n  10\n  +\n  9\n  10\n  16_{10} + 9_{10}\n  1\n  6\n  10\n  \u200b\n  +\n  9\n  10\n  \u200b\n  =\n  2\n  5\n  10\n  25_{10}\n  2\n  5\n  10\n  \u200b\n  =\n  <strong>\n   Overflow\n  </strong>\n  .\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  2\n  7\n  10\n  +\n  3\n  1\n  10\n  27_{10} + 31_{10}\n  2\n  7\n  10\n  \u200b\n  +\n  3\n  1\n  10\n  \u200b\n  =\n  5\n  8\n  10\n  58_{10}\n  5\n  8\n  10\n  \u200b\n  =\n  <strong>\n   Overflow\n  </strong>\n  .\n </li>\n <li>\n  <strong>\n   c)\n  </strong>\n  \u2212\n  4\n  10\n  +\n  1\n  9\n  10\n  -4_{10} + 19_{10}\n  \u2212\n  4\n  10\n  \u200b\n  +\n  1\n  9\n  10\n  \u200b\n  =\n  1\n  5\n  10\n  15_{10}\n  1\n  5\n  10\n  \u200b\n  =\n  <strong>\n   No overflow\n  </strong>\n  .\n </li>\n</ul>\n"}, "Page 47": {"response": "<h3>\n Exercises\n</h3>\n<p>\n <strong>\n  36. Subtracting Decimal Numbers (continued)\n </strong>\n :\n</p>\n<ul>\n <li>\n  <strong>\n   d)\n  </strong>\n  3\n  10\n  \u2212\n  3\n  2\n  10\n  3_{10} - 32_{10}\n  3\n  10\n  \u200b\n  \u2212\n  3\n  2\n  10\n  \u200b\n  : Result is\n  <strong>\n   -29\n  </strong>\n  (check for overflow).\n </li>\n <li>\n  <strong>\n   e)\n  </strong>\n  \u2212\n  1\n  6\n  10\n  \u2212\n  9\n  10\n  -16_{10} - 9_{10}\n  \u2212\n  1\n  6\n  10\n  \u200b\n  \u2212\n  9\n  10\n  \u200b\n  : Result is\n  <strong>\n   -25\n  </strong>\n  (check for overflow).\n </li>\n <li>\n  <strong>\n   f)\n  </strong>\n  \u2212\n  2\n  7\n  10\n  \u2212\n  3\n  1\n  10\n  -27_{10} - 31_{10}\n  \u2212\n  2\n  7\n  10\n  \u200b\n  \u2212\n  3\n  1\n  10\n  \u200b\n  : Result is\n  <strong>\n   -58\n  </strong>\n  (check for overflow).\n </li>\n</ul>\n<p>\n <strong>\n  37. Adding Unsigned Hexadecimal Numbers\n </strong>\n :\n</p>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  7\n  1\n  16\n  +\n  9\n  1\n  16\n  =\n  E\n  2\n  16\n  71_{16} + 91_{16} = E2_{16}\n  7\n  1\n  16\n  \u200b\n  +\n  9\n  1\n  16\n  \u200b\n  =\n  E\n  2\n  16\n  \u200b\n  (no overflow).\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  1\n  3\n  16\n  +\n  2\n  8\n  16\n  =\n  3\n  B\n  16\n  13_{16} + 28_{16} = 3B_{16}\n  1\n  3\n  16\n  \u200b\n  +\n  2\n  8\n  16\n  \u200b\n  =\n  3\n  B\n  16\n  \u200b\n  (no overflow).\n </li>\n <li>\n  <strong>\n   c)\n  </strong>\n  A\n  B\n  16\n  +\n  3\n  E\n  16\n  =\n  E\n  9\n  16\n  AB_{16} + 3E_{16} = E9_{16}\n  A\n  B\n  16\n  \u200b\n  +\n  3\n  E\n  16\n  \u200b\n  =\n  E\n  9\n  16\n  \u200b\n  (no overflow).\n </li>\n <li>\n  <strong>\n   d)\n  </strong>\n  8\n  F\n  16\n  +\n  A\n  D\n  16\n  =\n  1\n  C\n  4\n  16\n  8F_{16} + AD_{16} = 1C4_{16}\n  8\n  F\n  16\n  \u200b\n  +\n  A\n  D\n  16\n  \u200b\n  =\n  1\n  C\n  4\n  16\n  \u200b\n  (overflows).\n </li>\n</ul>\n<p>\n <strong>\n  38. Subtracting 5-Bit Two's Complement Numbers\n </strong>\n :\n</p>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  9\n  10\n  \u2212\n  7\n  10\n  =\n  2\n  10\n  9_{10} - 7_{10} = 2_{10}\n  9\n  10\n  \u200b\n  \u2212\n  7\n  10\n  \u200b\n  =\n  2\n  10\n  \u200b\n  (no overflow).\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  1\n  2\n  10\n  \u2212\n  1\n  5\n  10\n  =\n  \u2212\n  3\n  10\n  12_{10} - 15_{10} = -3_{10}\n  1\n  2\n  10\n  \u200b\n  \u2212\n  1\n  5\n  10\n  \u200b\n  =\n  \u2212\n  3\n  10\n  \u200b\n  (no overflow).\n </li>\n <li>\n  <strong>\n   c)\n  </strong>\n  \u2212\n  6\n  10\n  \u2212\n  1\n  1\n  10\n  =\n  \u2212\n  1\n  7\n  10\n  -6_{10} - 11_{10} = -17_{10}\n  \u2212\n  6\n  10\n  \u200b\n  \u2212\n  1\n  1\n  10\n  \u200b\n  =\n  \u2212\n  1\n  7\n  10\n  \u200b\n  (overflows).\n </li>\n <li>\n  <strong>\n   d)\n  </strong>\n  4\n  10\n  \u2212\n  (\n  \u2212\n  8\n  10\n  )\n  =\n  1\n  2\n  10\n  4_{10} - (-8_{10}) = 12_{10}\n  4\n  10\n  \u200b\n  \u2212\n  (\n  \u2212\n  8\n  10\n  \u200b\n  )\n  =\n  1\n  2\n  10\n  \u200b\n  (no overflow).\n </li>\n</ul>\n<p>\n <strong>\n  39. Biased N-Bit Binary Numbers\n </strong>\n :\n</p>\n<ul>\n <li>\n  For an 8-bit system with a bias of\n  <strong>\n   127\n  </strong>\n  :\n  <ul>\n   <li>\n    <strong>\n     a)\n    </strong>\n    The binary number\n    1000001\n    0\n    2\n    10000010_2\n    1000001\n    0\n    2\n    \u200b\n    represents\n    <strong>\n     130\n    </strong>\n    in decimal (130 - 127).\n   </li>\n   <li>\n    <strong>\n     b)\n    </strong>\n    The binary number representing 0 is\n    0111111\n    1\n    2\n    01111111_2\n    0111111\n    1\n    2\n    \u200b\n    (0 + 127).\n   </li>\n   <li>\n    <strong>\n     c)\n    </strong>\n    The most negative number is\n    0000000\n    0\n    2\n    00000000_2\n    0000000\n    0\n    2\n    \u200b\n    , which is\n    <strong>\n     -127\n    </strong>\n    (0 - 127).\n   </li>\n   <li>\n    <strong>\n     d)\n    </strong>\n    The most positive number is\n    1111111\n    1\n    2\n    11111111_2\n    1111111\n    1\n    2\n    \u200b\n    , which is\n    <strong>\n     128\n    </strong>\n    (255 - 127).\n   </li>\n  </ul>\n </li>\n</ul>\n<p>\n <strong>\n  40. Number Line for 3-Bit Biased Numbers\n </strong>\n :\n</p>\n<ul>\n <li>\n  Draw a number line for 3-bit biased numbers with a bias of\n  <strong>\n   3\n  </strong>\n  , showing values from\n  <strong>\n   -3\n  </strong>\n  to\n  <strong>\n   5\n  </strong>\n  .\n </li>\n</ul>\n<p>\n <strong>\n  41. Binary Coded Decimal (BCD)\n </strong>\n :\n</p>\n<ul>\n <li>\n  In BCD, each decimal digit from 0 to 9 is represented by 4 bits. For example, the number\n  3\n  7\n  10\n  37_{10}\n  3\n  7\n  10\n  \u200b\n  is represented as\n  0011011\n  1\n  B\n  C\n  D\n  0011 0111_{BCD}\n  0011011\n  1\n  BC\n  D\n  \u200b\n  .\n </li>\n</ul>\n"}, "Page 48": {"response": "<h3>\n Exercises\n</h3>\n<p>\n <strong>\n  a)\n </strong>\n To write\n 28\n 9\n 10\n 289_{10}\n 28\n 9\n 10\n \u200b\n in Binary Coded Decimal (BCD), you break it down into its decimal digits:\n</p>\n<ul>\n <li>\n  2\n  2\n  2\n  is\n  0010\n  0010\n  0010\n </li>\n <li>\n  8\n  8\n  8\n  is\n  1000\n  1000\n  1000\n </li>\n <li>\n  9\n  9\n  9\n  is\n  1001\n  1001\n  1001\n  So,\n  28\n  9\n  10\n  289_{10}\n  28\n  9\n  10\n  \u200b\n  in BCD is\n  001010001001\n  0010 1000 1001\n  001010001001\n  .\n </li>\n</ul>\n<p>\n <strong>\n  b)\n </strong>\n To convert\n 10010101000\n 1\n B\n C\n D\n 100101010001_{BCD}\n 10010101000\n 1\n BC\n D\n \u200b\n to decimal, interpret each group of four bits as a decimal digit:\n</p>\n<ul>\n <li>\n  1001\n  1001\n  1001\n  is\n  9\n  9\n  9\n </li>\n <li>\n  0101\n  0101\n  0101\n  is\n  5\n  5\n  5\n </li>\n <li>\n  0011\n  0011\n  0011\n  is\n  3\n  3\n  3\n  Thus,\n  10010101000\n  1\n  B\n  C\n  D\n  =\n  95\n  3\n  10\n  100101010001_{BCD} = 953_{10}\n  10010101000\n  1\n  BC\n  D\n  \u200b\n  =\n  95\n  3\n  10\n  \u200b\n  .\n </li>\n</ul>\n<p>\n <strong>\n  c)\n </strong>\n To convert\n 0110100\n 1\n B\n C\n D\n 01101001_{BCD}\n 0110100\n 1\n BC\n D\n \u200b\n to binary, group the BCD digits:\n</p>\n<ul>\n <li>\n  0110\n  0110\n  0110\n  is\n  6\n  6\n  6\n </li>\n <li>\n  1001\n  1001\n  1001\n  is\n  9\n  9\n  9\n  Therefore,\n  0110100\n  1\n  B\n  C\n  D\n  01101001_{BCD}\n  0110100\n  1\n  BC\n  D\n  \u200b\n  in binary is\n  6\n  9\n  10\n  69_{10}\n  6\n  9\n  10\n  \u200b\n  .\n </li>\n</ul>\n<p>\n <strong>\n  d)\n </strong>\n BCD (Binary Coded Decimal) is useful because it represents decimal digits directly in binary. This makes it easier to perform decimal arithmetic and display decimal numbers, as each digit can be manipulated independently.\n</p>\n<p>\n <strong>\n  Exercise 1.42\n </strong>\n : A Martian equation\n 325\n \u00d7\n 42\n =\n 411\n 325 \\times 42 = 411\n 325\n \u00d7\n 42\n =\n 411\n in their number system suggests they likely have\n <strong>\n  3 fingers\n </strong>\n . (Since\n 3\n \u00d7\n 2\n =\n 6\n 3 \\times 2 = 6\n 3\n \u00d7\n 2\n =\n 6\n in decimal).\n</p>\n<p>\n <strong>\n  Exercise 1.43\n </strong>\n : Ben claims that all integers greater than zero and divisible by six have exactly two 1's in their binary representation. Alyssa counters that they all have an even number of 1's. The answer is:\n <strong>\n  Alyssa is correct\n </strong>\n . For example,\n 6\n 10\n =\n 11\n 0\n 2\n 6_{10} = 110_{2}\n 6\n 10\n \u200b\n =\n 11\n 0\n 2\n \u200b\n (2 ones),\n 1\n 2\n 10\n =\n 110\n 0\n 2\n 12_{10} = 1100_{2}\n 1\n 2\n 10\n \u200b\n =\n 110\n 0\n 2\n \u200b\n (2 ones), etc., but\n 1\n 8\n 10\n =\n 1001\n 0\n 2\n 18_{10} = 10010_{2}\n 1\n 8\n 10\n \u200b\n =\n 1001\n 0\n 2\n \u200b\n (3 ones).\n</p>\n<p>\n <strong>\n  Exercise 1.44\n </strong>\n : Ben believes you can find the two\u2019s complement by subtracting 1 and then inverting all bits. Alyssa suggests inverting bits after the first 1 from the right.\n <strong>\n  Both methods work\n </strong>\n to find two's complement, but Alyssa's method is more straightforward.\n</p>\n<p>\n <strong>\n  Exercise 1.45\n </strong>\n : Write a program that converts a binary number to decimal. The user inputs an unsigned binary number, and the program outputs the decimal equivalent.\n</p>\n<p>\n <strong>\n  Exercise 1.46\n </strong>\n : Create a program that converts a decimal number to hexadecimal. The user inputs a decimal number, and the program outputs its hexadecimal representation.\n</p>\n<p>\n <strong>\n  Exercise 1.47\n </strong>\n : Develop a program to convert numbers between arbitrary bases\n b\n 1\n b_1\n b\n 1\n \u200b\n and\n b\n 2\n b_2\n b\n 2\n \u200b\n , supporting bases up to 16. The user specifies the input and output bases and the number to convert, and the program outputs the equivalent number in the target base.\n</p>\n<p>\n <strong>\n  Exercise 1.48\n </strong>\n :\n</p>\n<ul>\n <li>\n  <strong>\n   a)\n  </strong>\n  For a three-input OR gate, the symbol is a standard OR shape, the Boolean equation is\n  A\n  +\n  B\n  +\n  C\n  A + B + C\n  A\n  +\n  B\n  +\n  C\n  , and the truth table shows output\n  1\n  1\n  1\n  when any input is\n  1\n  1\n  1\n  .\n </li>\n <li>\n  <strong>\n   b)\n  </strong>\n  A three-input exclusive OR (XOR) gate's symbol resembles an OR gate with an extra curve, the equation is\n  A\n  \u2295\n  B\n  \u2295\n  C\n  A \\oplus B \\oplus C\n  A\n  \u2295\n  B\n  \u2295\n  C\n  , and the truth table shows output\n  1\n  1\n  1\n  when an odd number of inputs are\n  1\n  1\n  1\n  .\n </li>\n <li>\n  <strong>\n   c)\n  </strong>\n  A four-input XNOR gate's symbol is similar to the XOR gate with a small circle at the output, the equation is\n  A\n  \u2295\n  B\n  \u2295\n  C\n  \u2295\n  D\n  \u203e\n  \\overline{A \\oplus B \\oplus C \\oplus D}\n  A\n  \u2295\n  B\n  \u2295\n  C\n  \u2295\n  D\n  \u200b\n  , and the truth table shows output\n  1\n  1\n  1\n  when all inputs are equal.\n </li>\n</ul>\n"}, "Page 49": {"response": "<h3>\n Exercises\n</h3>\n<p>\n <strong>\n  Exercise 1.49\n </strong>\n : A\n <strong>\n  majority gate\n </strong>\n outputs TRUE if more than half of its inputs are TRUE. For a three-input majority gate, the truth table shows:\n</p>\n<table>\n <thead>\n  <tr>\n   <th>\n    A\n   </th>\n   <th>\n    B\n   </th>\n   <th>\n    C\n   </th>\n   <th>\n    Output (Y)\n   </th>\n  </tr>\n </thead>\n <tbody>\n  <tr>\n   <td>\n    0\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    0\n   </td>\n  </tr>\n  <tr>\n   <td>\n    0\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    0\n   </td>\n  </tr>\n  <tr>\n   <td>\n    0\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    0\n   </td>\n  </tr>\n  <tr>\n   <td>\n    0\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n  </tr>\n  <tr>\n   <td>\n    1\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    0\n   </td>\n  </tr>\n  <tr>\n   <td>\n    1\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n  </tr>\n  <tr>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    1\n   </td>\n  </tr>\n  <tr>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n  </tr>\n </tbody>\n</table>\n<p>\n <strong>\n  Exercise 1.50\n </strong>\n : An\n <strong>\n  AND-OR (AO) gate\n </strong>\n outputs TRUE if both A and B are TRUE, or if C is TRUE. The truth table is:\n</p>\n<table>\n <thead>\n  <tr>\n   <th>\n    A\n   </th>\n   <th>\n    B\n   </th>\n   <th>\n    C\n   </th>\n   <th>\n    Output (Y)\n   </th>\n  </tr>\n </thead>\n <tbody>\n  <tr>\n   <td>\n    0\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    0\n   </td>\n  </tr>\n  <tr>\n   <td>\n    0\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n  </tr>\n  <tr>\n   <td>\n    0\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    0\n   </td>\n  </tr>\n  <tr>\n   <td>\n    0\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n  </tr>\n  <tr>\n   <td>\n    1\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    0\n   </td>\n  </tr>\n  <tr>\n   <td>\n    1\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n  </tr>\n  <tr>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    1\n   </td>\n  </tr>\n  <tr>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n  </tr>\n </tbody>\n</table>\n<p>\n <strong>\n  Exercise 1.51\n </strong>\n : An\n <strong>\n  OR-AND-INVERT (OAI) gate\n </strong>\n outputs FALSE if C is TRUE and either A or B is TRUE; otherwise, it outputs TRUE. The truth table is:\n</p>\n<table>\n <thead>\n  <tr>\n   <th>\n    A\n   </th>\n   <th>\n    B\n   </th>\n   <th>\n    C\n   </th>\n   <th>\n    Output (Y)\n   </th>\n  </tr>\n </thead>\n <tbody>\n  <tr>\n   <td>\n    0\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    1\n   </td>\n  </tr>\n  <tr>\n   <td>\n    0\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    0\n   </td>\n  </tr>\n  <tr>\n   <td>\n    0\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    1\n   </td>\n  </tr>\n  <tr>\n   <td>\n    0\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    0\n   </td>\n  </tr>\n  <tr>\n   <td>\n    1\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    1\n   </td>\n  </tr>\n  <tr>\n   <td>\n    1\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    0\n   </td>\n  </tr>\n  <tr>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    0\n   </td>\n   <td>\n    1\n   </td>\n  </tr>\n  <tr>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    1\n   </td>\n   <td>\n    0\n   </td>\n  </tr>\n </tbody>\n</table>\n<p>\n <strong>\n  Exercise 1.52\n </strong>\n : There are 16 different truth tables for Boolean functions of two variables. Here they are, along with descriptive names:\n</p>\n<ol>\n <li>\n  <strong>\n   AND\n  </strong>\n  : 00 \u2192 0, 01 \u2192 0, 10 \u2192 0, 11 \u2192 1\n </li>\n <li>\n  <strong>\n   OR\n  </strong>\n  : 00 \u2192 0, 01 \u2192 1, 10 \u2192 1, 11 \u2192 1\n </li>\n <li>\n  <strong>\n   NAND\n  </strong>\n  : 00 \u2192 1, 01 \u2192 1, 10 \u2192 1, 11 \u2192 0\n </li>\n <li>\n  <strong>\n   NOR\n  </strong>\n  : 00 \u2192 1, 01 \u2192 0, 10 \u2192 0, 11 \u2192 0\n </li>\n <li>\n  <strong>\n   XOR\n  </strong>\n  : 00 \u2192 0, 01 \u2192 1, 10 \u2192 1, 11 \u2192 0\n </li>\n <li>\n  <strong>\n   XNOR\n  </strong>\n  : 00 \u2192 1, 01 \u2192 0, 10 \u2192 0, 11 \u2192 1\n </li>\n <li>\n  <strong>\n   Buffer\n  </strong>\n  : 00 \u2192 0, 01 \u2192 1, 10 \u2192 1, 11 \u2192 1\n </li>\n <li>\n  <strong>\n   Inverter\n  </strong>\n  : 00 \u2192 1, 01 \u2192 0, 10 \u2192 0, 11 \u2192 0\n </li>\n <li>\n  <strong>\n   Identity\n  </strong>\n  : 00 \u2192 0, 01 \u2192 1, 10 \u2192 0, 11 \u2192 1\n </li>\n <li>\n  <strong>\n   Constant 0\n  </strong>\n  : Always outputs 0\n </li>\n <li>\n  <strong>\n   Constant 1\n  </strong>\n  : Always outputs 1\n </li>\n <li>\n  <strong>\n   Implication\n  </strong>\n  : 00 \u2192 1, 01 \u2192 1, 10 \u2192 0, 11 \u2192 1\n </li>\n <li>\n  <strong>\n   Inverse Implication\n  </strong>\n  : 00 \u2192 1, 01 \u2192 0, 10 \u2192 1, 11 \u2192 1\n </li>\n <li>\n  <strong>\n   Co-Implication\n  </strong>\n  : 00 \u2192 1, 01 \u2192 0, 10 \u2192 0, 11 \u2192 1\n </li>\n <li>\n  <strong>\n   Greater Than\n  </strong>\n  : 00 \u2192 0, 01 \u2192 0, 10 \u2192 1, 11 \u2192 1\n </li>\n <li>\n  <strong>\n   Less Than\n  </strong>\n  : 00 \u2192 0, 01 \u2192 1, 10 \u2192 0, 11 \u2192 0\n </li>\n</ol>\n<p>\n <strong>\n  Exercise 1.53\n </strong>\n : The number of different truth tables for Boolean functions of\n N\n N\n N\n variables is\n 2\n (\n 2\n N\n )\n 2^{(2^N)}\n 2\n (\n 2\n N\n )\n . Each combination of inputs can have an output of either 0 or 1.\n</p>\n<p>\n <strong>\n  Exercise 1.54\n </strong>\n : To determine if a device with specific transfer characteristics can function as an inverter, you need to analyze its input and output levels (VIL, VOL, VIH, VOH) and noise margins (NML, NMH). If it meets the required conditions for switching states, it can serve as an inverter. If not, explain why the levels or margins don't allow for proper inversion.\n</p>\n"}, "Page 50": {"response": "<p>\n <strong>\n  Exercise 1.55\n </strong>\n : For the transfer characteristics shown in Figure 1.45, repeat the analysis to determine if the device can function as an inverter. Check the input and output levels, along with the noise margins to see if it meets the inverter requirements.\n</p>\n<p>\n <strong>\n  Exercise 1.56\n </strong>\n : Determine if a device with the transfer characteristics in Figure 1.46 can work as a buffer. If it can, specify the input low (VIL), input high (VIH), output low (VOL), output high (VOH), and the noise margins (NML and NMH). If it cannot serve as a buffer, explain why the device's characteristics do not allow for proper buffering.\n</p>\n"}, "Page 51": {"response": "<p>\n <strong>\n  Exercise 1.57\n </strong>\n : Ben Bitdiddle created a circuit with specific transfer characteristics (shown in Figure 1.47) that he hopes to use as a buffer. To determine if it will work, assess whether the circuit can properly handle input and output levels according to the LVCMOS and LVTTL logic families. Explain whether Ben\u2019s buffer can accurately receive inputs from these families and if it can drive outputs to them effectively.\n</p>\n<p>\n <strong>\n  Exercise 1.58\n </strong>\n : While walking in a dark alley, Ben discovers a two-input gate with a transfer function illustrated in Figure 1.48. He needs to identify:\na) What type of logic gate he found.\nb) The approximate high and low logic levels of the gate\u2019s output.\n</p>\n"}, "Page 52": {"response": "<p>\n <strong>\n  Exercise 1.59\n </strong>\n : Repeat the tasks from Exercise 1.58 for the transfer characteristics shown in Figure 1.49.\n</p>\n<p>\n <strong>\n  Exercise 1.60\n </strong>\n : Create sketches for transistor-level circuits of the following CMOS gates, using the fewest transistors possible:\na) A four-input NAND gate.\nb) A three-input OR-AND-INVERT gate.\nc) A three-input AND-OR gate.\n</p>\n<p>\n <strong>\n  Exercise 1.61\n </strong>\n : Design a CMOS circuit for a minority gate, which outputs TRUE only if fewer than half of its inputs are TRUE. Use a minimum number of transistors for the design.\n</p>\n"}, "Page 53": {"response": "<p>\n <strong>\n  Exercise 1.62\n </strong>\n : Create a truth table for the gate shown in Figure 1.50, which has two inputs, A and B. Identify the function performed by this gate.\n</p>\n<p>\n <strong>\n  Exercise 1.63\n </strong>\n : Develop a truth table for the gate in Figure 1.51, which has three inputs: A, B, and C.\n</p>\n<p>\n <strong>\n  Exercise 1.64\n </strong>\n : Design three-input gates using only pseudo-nMOS logic gates, minimizing the number of transistors. The gates needed are:\na) A three-input NOR gate.\nb) A three-input NAND gate.\nc) A three-input AND gate.\n</p>\n<p>\n <strong>\n  Exercise 1.65\n </strong>\n : Resistor-Transistor Logic (RTL) utilizes nMOS transistors to pull the output low, while a weak resistor pulls it high when no paths to ground are active. Sketch a three-input RTL NOR gate using the fewest transistors possible.\n</p>\n"}, "Page 54": {"response": "<p>\n <strong>\n  Interview Questions\n </strong>\n</p>\n<p>\n These are questions commonly asked in interviews for digital design positions:\n</p>\n<p>\n <strong>\n  Question 1.1\n </strong>\n : Draw a circuit diagram for a CMOS four-input NOR gate at the transistor level.\n</p>\n<p>\n <strong>\n  Question 1.2\n </strong>\n : A king has 64 gold coins and suspects one might be fake. Using a balance scale that can hold coins on either side, how many weighings do you need to determine which coin is counterfeit?\n</p>\n<p>\n <strong>\n  Question 1.3\n </strong>\n : Four people\u2014a professor, a teaching assistant, a digital design student, and a freshman track star\u2014need to cross a shaky bridge at night with only one flashlight. The bridge can only hold two people at a time, and the flashlight must be carried back and forth. The crossing times are:\n</p>\n<ul>\n <li>\n  Freshman track star: 1 minute\n </li>\n <li>\n  Digital design student: 2 minutes\n </li>\n <li>\n  Teaching assistant: 5 minutes\n </li>\n <li>\n  Professor: 10 minutes\nWhat is the quickest way to get all of them across the bridge?\n </li>\n</ul>\n"}, "Page 55": {"response": "<p>\n <strong>\n  2.1 Introduction\n </strong>\n</p>\n<p>\n In digital electronics, a circuit processes discrete values and can be thought of as a \"black box\" with the following features:\n</p>\n<ul>\n <li>\n  <strong>\n   Inputs\n  </strong>\n  : One or more terminals that receive discrete values.\n </li>\n <li>\n  <strong>\n   Outputs\n  </strong>\n  : One or more terminals that deliver discrete values.\n </li>\n <li>\n  <strong>\n   Functional Specification\n  </strong>\n  : Describes how the inputs relate to the outputs.\n </li>\n <li>\n  <strong>\n   Timing Specification\n  </strong>\n  : Indicates the delay between when inputs change and when outputs respond.\n </li>\n</ul>\n<p>\n Inside this black box, circuits are made up of nodes and elements. An\n <strong>\n  element\n </strong>\n is a smaller circuit with its own inputs, outputs, and specifications. A\n <strong>\n  node\n </strong>\n represents a wire, which carries a discrete value. Nodes are categorized as:\n</p>\n<ul>\n <li>\n  <strong>\n   Input Nodes\n  </strong>\n  : Receive values from the outside.\n </li>\n <li>\n  <strong>\n   Output Nodes\n  </strong>\n  : Send values to the outside.\n </li>\n <li>\n  <strong>\n   Internal Nodes\n  </strong>\n  : Wires that are neither inputs nor outputs.\n </li>\n</ul>\n<p>\n This structure helps in understanding how circuits function and interact with each other.\n</p>\n"}, "Page 56": {"response": "<p>\n The circuit depicted consists of three elements (E1, E2, E3) and six nodes, where A, B, and C are the input nodes, Y and Z are the output nodes, and n1 is an internal node connecting E1 and E3.\n</p>\n<p>\n Digital circuits fall into two categories:\n <strong>\n  combinational\n </strong>\n and\n <strong>\n  sequential\n </strong>\n .\n</p>\n<ul>\n <li>\n  <p>\n   <strong>\n    Combinational Circuits\n   </strong>\n   : These circuits produce outputs based only on the current input values, meaning they combine inputs to generate an output. For example, logic gates are combinational circuits and are considered memoryless.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Sequential Circuits\n   </strong>\n   : These depend on both current and past input values, meaning they take the sequence of inputs into account and possess memory.\n  </p>\n </li>\n</ul>\n<p>\n This chapter focuses on combinational circuits, while sequential circuits will be covered in Chapter 3.\n</p>\n<p>\n The\n <strong>\n  functional specification\n </strong>\n of a combinational circuit describes how the output values relate to the current input values. The\n <strong>\n  timing specification\n </strong>\n sets limits on the delay between input changes and output responses. Initially, we'll focus on the functional aspect, returning to timing later.\n</p>\n<p>\n In a simple combinational circuit example (Figure 2.3), there are two inputs (A and B) and one output (Y). The function is specified as OR: Y = A OR B, indicating the output is based on these two inputs.\n</p>\n<p>\n Figures 2.4 illustrates two ways to implement this combinational logic, emphasizing that multiple implementations can exist for a single function, depending on design constraints like area, speed, power, and time.\n</p>\n<p>\n Figure 2.5 shows a full adder, a type of combinational circuit with multiple outputs (S and Cout) defined by the inputs A, B, and Cin.\n</p>\n<p>\n To simplify circuit drawings, a slash with a number can represent a bus\u2014a group of multiple signals. For instance, Figure 2.6(a) shows a combinational logic block with three inputs and two outputs. If the number of signals is clear from the context, the number can be omitted.\n</p>\n<p>\n Lastly, the rules of\n <strong>\n  combinational composition\n </strong>\n explain how to build larger circuits from smaller ones.\n</p>\n"}, "Page 57": {"response": "<p>\n A combinational circuit is one that follows these rules:\n</p>\n<ol>\n <li>\n  <strong>\n   All elements must be combinational\n  </strong>\n  : Each component in the circuit is itself a combinational circuit.\n </li>\n <li>\n  <strong>\n   Input and output connections\n  </strong>\n  : Each node in the circuit must either be an input or connect to exactly one output of a circuit element.\n </li>\n <li>\n  <strong>\n   No cyclic paths\n  </strong>\n  : The circuit cannot have loops; each path must visit each node only once.\n </li>\n</ol>\n<p>\n <strong>\n  Example Analysis of Combinational Circuits\n </strong>\n :\nIn Figure 2.7, we determine which circuits are combinational:\n</p>\n<ul>\n <li>\n  <p>\n   <strong>\n    Circuit (a)\n   </strong>\n   is combinational because it is made from two combinational elements (inverters I1 and I2) and has three nodes:\n  </p>\n  <ul>\n   <li>\n    n1 is an input,\n   </li>\n   <li>\n    n2 is an internal node (output of I1 and input to I2),\n   </li>\n   <li>\n    n3 is the output.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Circuit (b)\n   </strong>\n   is not combinational due to a cyclic path: the XOR's output feeds back into one of its inputs, creating a loop from n4 to n5 and back to n4.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Circuit (c)\n   </strong>\n   is combinational.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Circuit (d)\n   </strong>\n   is not combinational because node n6 connects to the outputs of both I3 and I4, violating the rules.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Circuit (e)\n   </strong>\n   is combinational as it shows two combinational circuits linked together.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Circuit (f)\n   </strong>\n   does not follow the combinational rules due to a cyclic path through its elements. Depending on the elements' functions, it may or may not be considered combinational.\n  </p>\n </li>\n</ul>\n<p>\n For complex circuits like microprocessors, we use earlier principles to manage complexity, often viewing them as black boxes with defined functions and interfaces.\n</p>\n<p>\n While the rules of combinational composition are a good guideline, they are not strictly necessary. Some circuits that don't follow these rules can still be combinational as long as their outputs depend only on the current input values. However, identifying these exceptions can be more complex, so we generally stick to the established rules when constructing combinational circuits.\n</p>\n"}, "Page 58": {"response": "<p>\n The concepts of abstraction and modularity in circuit design allow us to build complex circuits from smaller, simpler components, which is known as hierarchy. The rules of combinational composition ensure that this process is disciplined.\n</p>\n<h3>\n Functional Specification\n</h3>\n<p>\n The functional specification of a combinational circuit is typically presented as a truth table or a Boolean equation. This chapter will explain how to create a Boolean equation from any truth table and how to simplify these equations using Boolean algebra and Karnaugh maps. We will also cover how to implement these equations with logic gates and analyze the speed of the resulting circuits.\n</p>\n<h3>\n 2.2 Boolean Equations\n</h3>\n<p>\n Boolean equations use variables that can only be TRUE or FALSE, making them ideal for digital logic. This section introduces key terms related to Boolean equations and explains how to write a Boolean equation for a logic function based on its truth table.\n</p>\n<h4>\n 2.2.1 Terminology\n</h4>\n<ul>\n <li>\n  The\n  <strong>\n   complement\n  </strong>\n  of a variable, like A, is its opposite, denoted as\n  A\n  \u203e\n  \\overline{A}\n  A\n  . Both a variable and its complement are called\n  <strong>\n   literals\n  </strong>\n  (e.g., A,\n  A\n  \u203e\n  \\overline{A}\n  A\n  , B,\n  B\n  \u203e\n  \\overline{B}\n  B\n  ).\n </li>\n <li>\n  A variable like A is its\n  <strong>\n   true form\n  </strong>\n  , while\n  A\n  \u203e\n  \\overline{A}\n  A\n  is its\n  <strong>\n   complementary form\n  </strong>\n  . \"True form\" doesn\u2019t imply that A is TRUE, just that it\u2019s not negated.\n </li>\n <li>\n  The\n  <strong>\n   AND\n  </strong>\n  of one or more literals is called a\n  <strong>\n   product\n  </strong>\n  or\n  <strong>\n   implicant\n  </strong>\n  . For example,\n  A\n  B\n  \u203e\n  A \\overline{B}\n  A\n  B\n  and B are implicants for a function of three variables.\n </li>\n <li>\n  A\n  <strong>\n   minterm\n  </strong>\n  is a product that includes all inputs to the function. For instance,\n  A\n  B\n  \u203e\n  C\n  A \\overline{B} C\n  A\n  B\n  C\n  is a minterm for the variables A, B, and C, while\n  A\n  B\n  \u203e\n  A \\overline{B}\n  A\n  B\n  is not, as it lacks C.\n </li>\n <li>\n  The\n  <strong>\n   OR\n  </strong>\n  of one or more literals is called a\n  <strong>\n   sum\n  </strong>\n  . A\n  <strong>\n   maxterm\n  </strong>\n  is a sum that includes all inputs to the function; for example,\n  A\n  +\n  B\n  +\n  C\n  A + B + C\n  A\n  +\n  B\n  +\n  C\n  is a maxterm for A, B, and C.\n </li>\n</ul>\n<p>\n The\n <strong>\n  order of operations\n </strong>\n in Boolean equations matters. For example, does\n Y\n =\n A\n +\n B\n C\n Y = A + BC\n Y\n =\n A\n +\n BC\n mean\n Y\n =\n (\n A\n +\n B\n )\n C\n Y = (A + B)C\n Y\n =\n (\n A\n +\n B\n )\n C\n or\n Y\n =\n A\n +\n (\n B\n \u22c5\n C\n )\n Y = A + (B \\cdot C)\n Y\n =\n A\n +\n (\n B\n \u22c5\n C\n )\n ? In Boolean logic, NOT operations have the highest priority, followed by AND, and then OR. Thus,\n Y\n =\n A\n +\n (\n B\n \u22c5\n C\n )\n Y = A + (B \\cdot C)\n Y\n =\n A\n +\n (\n B\n \u22c5\n C\n )\n .\n</p>\n<h4>\n 2.2.2 Sum-of-Products Form\n</h4>\n<p>\n A truth table with N inputs has\n 2\n N\n 2^N\n 2\n N\n rows, corresponding to every possible combination of input values. Each row in a truth table is tied to a minterm.\n</p>\n"}, "Page 59": {"response": "<p>\n A\n <strong>\n  minterm\n </strong>\n is a specific product term in a Boolean equation that corresponds to a row in a truth table where the output is TRUE. For example, in a truth table with inputs A and B, each row has a corresponding minterm. If the first row has A = 0 and B = 0, its minterm is\n A\n \u203e\n \u22c5\n B\n \u203e\n \\overline{A} \\cdot \\overline{B}\n A\n \u22c5\n B\n .\n</p>\n<p>\n To create a\n <strong>\n  Boolean equation\n </strong>\n from a truth table, sum the minterms where the output (Y) is TRUE. For instance, in a truth table with only one TRUE output, the equation would be just that single minterm. If there are multiple TRUE outputs, as shown in another truth table, you would add all the corresponding minterms together. This method of expressing a function is called the\n <strong>\n  sum-of-products canonical form\n </strong>\n because it sums (ORs) products (ANDs) that form minterms.\n</p>\n<h3>\n Example: Ben\u2019s Picnic\n</h3>\n<p>\n Let\u2019s say Ben Bitdiddle wants to enjoy his picnic, but he won't if it rains (R) or if there are ants (A). We define the inputs:\n</p>\n<ul>\n <li>\n  A: TRUE if there are ants\n </li>\n <li>\n  R: TRUE if it rains\n </li>\n</ul>\n<p>\n The output, E, is TRUE if Ben enjoys the picnic. The truth table for this scenario shows that E is TRUE only when it is not raining and there are no ants.\n</p>\n<p>\n Using the\n <strong>\n  sum-of-products form\n </strong>\n , the equation can be written as:\n E\n =\n A\n \u203e\n \u22c5\n R\n \u203e\n E = \\overline{A} \\cdot \\overline{R}\n E\n =\n A\n \u22c5\n R\n To implement this, you can use two inverters (for A and R) and a two-input AND gate.\n</p>\n<p>\n This truth table corresponds to the NOR function, which can also be expressed as:\n E\n =\n A\n NOR\n R\n E = A \\text{ NOR } R\n E\n =\n A\n NOR\n R\n</p>\n<p>\n The\n <strong>\n  sum-of-products form\n </strong>\n can represent any logic function, regardless of the number of variables. However, while this method provides a valid equation, it may not yield the simplest or most efficient equation. Future sections will explore how to simplify these equations using fewer terms.\n</p>\n<h3>\n Summary\n</h3>\n<ul>\n <li>\n  <strong>\n   Minterm\n  </strong>\n  : A product that represents a specific combination of input values.\n </li>\n <li>\n  <strong>\n   Sum-of-Products Form\n  </strong>\n  : The addition of all minterms where the output is TRUE.\n </li>\n <li>\n  <strong>\n   Canonical Form\n  </strong>\n  : A standard way to express a Boolean equation.\n </li>\n <li>\n  This method is helpful, but simplification techniques will be discussed later to create more efficient logic functions.\n </li>\n</ul>\n"}, "Page 60": {"response": "<h3>\n 2.2.3 Product-of-Sums Form\n</h3>\n<p>\n The\n <strong>\n  product-of-sums canonical form\n </strong>\n is another way to express Boolean functions. In this form, each row of a truth table corresponds to a\n <strong>\n  maxterm\n </strong>\n that is FALSE for that row. For example, in a two-input truth table, the maxterm for the first row, where both A and B are 0, is written as\n (\n A\n +\n B\n )\n (A + B)\n (\n A\n +\n B\n )\n because this expression is FALSE when A = 0 and B = 0.\n</p>\n<p>\n To create a\n <strong>\n  Boolean equation\n </strong>\n from a truth table, you take the AND of all maxterms where the output is FALSE.\n</p>\n<h3>\n Example 2.3: Product-of-Sums Form\n</h3>\n<p>\n Consider a truth table (Figure 2.13) where the output is FALSE in two rows. The function can be expressed in product-of-sums form as:\n Y\n =\n (\n A\n +\n B\n )\n (\n A\n \u203e\n +\n B\n )\n Y = (A + B)(\\overline{A} + B)\n Y\n =\n (\n A\n +\n B\n )\n (\n A\n +\n B\n )\n</p>\n<ul>\n <li>\n  The first maxterm\n  (\n  A\n  +\n  B\n  )\n  (A + B)\n  (\n  A\n  +\n  B\n  )\n  ensures that Y = 0 when A = 0 and B = 0.\n </li>\n <li>\n  The second maxterm\n  (\n  A\n  \u203e\n  +\n  B\n  )\n  (\\overline{A} + B)\n  (\n  A\n  +\n  B\n  )\n  ensures that Y = 0 when A = 1 and B = 0.\n </li>\n</ul>\n<p>\n This truth table illustrates that the same function can be represented in different forms.\n</p>\n<p>\n Similarly, for Ben's picnic example, the product-of-sums form can be written by identifying the rows where the output is 0:\n E\n =\n (\n A\n +\n R\n )\n (\n A\n +\n R\n \u203e\n )\n (\n A\n \u203e\n +\n R\n )\n E = (A + R)(A + \\overline{R})(\\overline{A} + R)\n E\n =\n (\n A\n +\n R\n )\n (\n A\n +\n R\n )\n (\n A\n +\n R\n )\n Although this form may look more complex than the sum-of-products form\n E\n =\n A\n \u203e\n \u22c5\n R\n \u203e\n E = \\overline{A} \\cdot \\overline{R}\n E\n =\n A\n \u22c5\n R\n , both expressions are logically equivalent.\n</p>\n<h3>\n When to Use Each Form\n</h3>\n<ul>\n <li>\n  <strong>\n   Sum-of-Products (SOP)\n  </strong>\n  : Best when the output is TRUE for only a few rows.\n </li>\n <li>\n  <strong>\n   Product-of-Sums (POS)\n  </strong>\n  : More efficient when the output is FALSE for only a few rows.\n </li>\n</ul>\n<h3>\n 2.3 Boolean Algebra\n</h3>\n<p>\n While we learned to write Boolean expressions from truth tables, those expressions might not yield the simplest logic gate configurations. Like regular algebra,\n <strong>\n  Boolean algebra\n </strong>\n helps us simplify these expressions.\n</p>\n<h4>\n Key Points about Boolean Algebra:\n</h4>\n<ul>\n <li>\n  It operates on variables that can only be 0 or 1.\n </li>\n <li>\n  It is based on axioms that are accepted as true but cannot be proved. From these axioms, we can derive theorems that guide us in simplifying logic circuits.\n </li>\n <li>\n  Using these simplifications can lead to smaller and cheaper circuit designs.\n </li>\n</ul>\n<p>\n In summary, understanding both product-of-sums and sum-of-products forms allows for flexibility in digital design, while Boolean algebra provides the tools to optimize those designs.\n</p>\n"}, "Page 61": {"response": "<h3>\n Axioms and Theorems of Boolean Algebra\n</h3>\n<p>\n <strong>\n  Duality Principle\n </strong>\n : In Boolean algebra, there's a principle called duality. This means that if you switch the symbols 0 and 1, as well as the operators AND (\u2022) and OR (\u2228), the resulting statement will still hold true. The dual of a statement is indicated with a prime symbol (\u2032).\n</p>\n<h3>\n 2.3.1 Axioms\n</h3>\n<p>\n Table 2.1 outlines five key axioms of Boolean algebra, which define the basic operations of Boolean variables and the meanings of NOT, AND, and OR:\n</p>\n<ol>\n <li>\n  <strong>\n   Axiom A1\n  </strong>\n  : A Boolean variable\n  B\n  B\n  B\n  is 0 if it is not 1. Its dual,\n  A\n  1\n  \u2032\n  A1'\n  A\n  1\n  \u2032\n  , states that\n  B\n  B\n  B\n  is 1 if it is not 0. Together, they clarify that we are working within a binary framework of 0s and 1s.\n </li>\n <li>\n  <strong>\n   Axioms A2 and A2\u2032\n  </strong>\n  : These define the NOT operation.\n </li>\n <li>\n  <strong>\n   Axioms A3 to A5\n  </strong>\n  : These define the AND operation. Their duals (A3\u2032 to A5\u2032) define the OR operation.\n </li>\n</ol>\n<h3>\n 2.3.2 Theorems of One Variable\n</h3>\n<p>\n Table 2.2 lists several theorems that help simplify equations involving a single variable:\n</p>\n<ul>\n <li>\n  <p>\n   <strong>\n    The Identity Theorem (T1)\n   </strong>\n   : States that for any Boolean variable\n   B\n   B\n   B\n   ,\n   B\n   B\n   B\n   AND 1 =\n   B\n   B\n   B\n   . Its dual states that\n   B\n   B\n   B\n   OR 0 =\n   B\n   B\n   B\n   . This means if one input of an AND gate is always 1, we can simplify the circuit by replacing the gate with a direct wire connected to\n   B\n   B\n   B\n   . Similarly, if an OR gate has one input always 0, we can replace it with a wire connected to\n   B\n   B\n   B\n   . This simplification is beneficial because it saves costs, power, and reduces delay.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    The Null Element Theorem (T2)\n   </strong>\n   : States that\n   B\n   B\n   B\n   AND 0 is always 0, making 0 the null element for AND operations, as it negates any other input. Its dual states that\n   B\n   B\n   B\n   OR 1 is always 1, so 1 is the null element for OR operations. In hardware, if one input of an AND gate is 0, it can also be replaced with a wire tied to 0.\n  </p>\n </li>\n</ul>\n<h3>\n Visual Representations\n</h3>\n<p>\n Figures illustrating these theorems in hardware help visualize these concepts. For example, in the identity theorem, one can see how replacing gates with wires simplifies the circuit.\n</p>\n<p>\n In summary, the axioms and theorems of Boolean algebra provide foundational rules that help in designing and simplifying digital circuits, allowing for efficient implementations.\n</p>\n"}, "Page 62": {"response": "<h3>\n 2.3.2 Theorems of One Variable (Continued)\n</h3>\n<ul>\n <li>\n  <p>\n   <strong>\n    Replacement of Gates\n   </strong>\n   : If one input of an OR gate is 1, we can simplify the circuit by replacing the OR gate with a wire connected to 1.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Idempotency (T3)\n   </strong>\n   : This theorem states that if you AND a variable with itself, the result is just that variable. Similarly, OR-ing a variable with itself gives the same variable. The name comes from Latin, meaning \"same power.\" This allows us to replace gates with wires, as shown in Figure 2.16.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Involution (T4)\n   </strong>\n   : This theorem explains that if you complement a variable twice, you get the original variable back. In practical terms, using two inverters in a row cancels each other out, making them equivalent to a direct wire, as shown in Figure 2.17. The dual of this theorem is the same.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Complement Theorem (T5)\n   </strong>\n   : This theorem states that a variable ANDed with its complement is always 0 (since one must be 0). By duality, a variable ORed with its complement is always 1 (since one must be 1). Figure 2.18 illustrates this.\n  </p>\n </li>\n</ul>\n<h3>\n 2.3.3 Theorems of Several Variables\n</h3>\n<ul>\n <li>\n  <p>\n   <strong>\n    Commutativity (T6)\n   </strong>\n   : The order of inputs in an AND or OR function does not change the output.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Associativity (T7)\n   </strong>\n   : The grouping of inputs does not affect the output, similar to traditional algebra.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Distributivity (T8)\n   </strong>\n   : AND distributes over OR, but the dual (T8\u2032) does not follow traditional rules\u2014OR does not distribute over AND. For example,\n   (\n   B\n   \u2228\n   C\n   )\n   \u2022\n   (\n   B\n   \u2228\n   D\n   )\n   (B \u2228 C) \u2022 (B \u2228 D)\n   (\n   B\n   \u2228\n   C\n   )\n   \u2022\n   (\n   B\n   \u2228\n   D\n   )\n   does not simplify like\n   B\n   \u2228\n   (\n   C\n   \u2022\n   D\n   )\n   B \u2228 (C \u2022 D)\n   B\n   \u2228\n   (\n   C\n   \u2022\n   D\n   )\n   does in normal algebra.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Covering, Combining, and Consensus Theorems (T9 to T11)\n   </strong>\n   : These theorems help eliminate redundant variables in equations. With careful consideration, their validity can be understood.\n  </p>\n </li>\n</ul>\n<h3>\n Summary of Theorems\n</h3>\n<p>\n Theorems T1 to T5 help simplify equations with one variable, while T6 to T12 extend those principles to multiple variables. The rules for commutativity, associativity, and distributivity are similar to traditional algebra, with some differences. Overall, these theorems are essential for efficient digital circuit design and simplification.\n</p>\n"}, "Page 63": {"response": "<h3>\n De Morgan\u2019s Theorem (T12)\n</h3>\n<p>\n De Morgan's Theorem is an important principle in digital design. It states two key points:\n</p>\n<ol>\n <li>\n  <p>\n   The complement of the product of terms is equal to the sum of the complements of those terms. In simpler terms, if you have terms multiplied together (AND operation), taking the NOT (complement) of the result gives you the same thing as taking the NOT of each term individually and then adding (ORing) them together.\n  </p>\n </li>\n <li>\n  <p>\n   The complement of the sum of terms is equal to the product of the complements of those terms. So, if you have terms added together (OR operation), taking the NOT of that result gives you the same thing as taking the NOT of each term and then multiplying (ANDing) them together.\n  </p>\n </li>\n</ol>\n<h3>\n Practical Implications\n</h3>\n<ul>\n <li>\n  <p>\n   A\n   <strong>\n    NAND gate\n   </strong>\n   can be viewed as an\n   <strong>\n    OR gate\n   </strong>\n   with inverted inputs. This means you can think of a NAND gate as giving the output of an OR gate but with all inputs flipped to their opposite values.\n  </p>\n </li>\n <li>\n  <p>\n   A\n   <strong>\n    NOR gate\n   </strong>\n   is like an\n   <strong>\n    AND gate\n   </strong>\n   with inverted inputs. This means a NOR gate produces the output of an AND gate, again with all inputs flipped.\n  </p>\n </li>\n</ul>\n<h3>\n Visual Representation\n</h3>\n<p>\n Figure 2.19 illustrates these relationships, showing how the NAND and NOR gates are equivalent to the corresponding OR and AND gates with inverted inputs. The symbols for each function represent their duals, meaning they can be used interchangeably while maintaining logical equivalence.\n</p>\n<h3>\n Summary of Theorems\n</h3>\n<p>\n Table 2.3 summarizes theorems related to several variables. Here are a few key points:\n</p>\n<ul>\n <li>\n  <p>\n   <strong>\n    Commutativity (T6)\n   </strong>\n   : The order of inputs doesn't affect the output for AND or OR operations.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Associativity (T7)\n   </strong>\n   : Grouping of inputs doesn't change the output.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Distributivity (T8)\n   </strong>\n   : AND distributes over OR, while the dual shows OR distributes over AND.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Covering (T9)\n   </strong>\n   ,\n   <strong>\n    Combining (T10)\n   </strong>\n   , and\n   <strong>\n    Consensus (T11)\n   </strong>\n   theorems help eliminate unnecessary variables from expressions.\n  </p>\n </li>\n</ul>\n<h3>\n Historical Note\n</h3>\n<p>\n Augustus De Morgan was a British mathematician known for his work in logic and algebra. He faced personal challenges, including blindness in one eye, but made significant contributions to mathematics. De Morgan's crater on the moon is named after him, and he famously posed a riddle about his age.\n</p>\n"}, "Page 64": {"response": "<h3>\n Inversion Circle (Bubble)\n</h3>\n<p>\n In digital logic, an inversion circle is referred to as a \"bubble.\" You can think of a bubble as being \"pushed\" through a logic gate, which changes the gate's type from AND to OR or vice versa. For example, a NAND gate looks like an AND gate with a bubble on its output. If you push that bubble to the left, it turns the AND gate into an OR gate with bubbles on its inputs. Here are the main rules for how bubbles work:\n</p>\n<ol>\n <li>\n  <p>\n   <strong>\n    Bubble Direction\n   </strong>\n   : Moving a bubble backward from the output or forward from the inputs changes the gate from AND to OR or the other way around.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Output Bubbles\n   </strong>\n   : If you push a bubble from the output back to the inputs, it puts bubbles on all inputs of the gate.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Input Bubbles\n   </strong>\n   : If you push bubbles on all gate inputs toward the output, it adds a bubble on the output.\n  </p>\n </li>\n</ol>\n<h3>\n Example: Deriving Product-of-Sums Form\n</h3>\n<p>\n To illustrate these concepts, let's look at how to derive the product-of-sums form of a Boolean function\n Y\n Y\n Y\n using De Morgan's Theorem.\n</p>\n<ol>\n <li>\n  <p>\n   <strong>\n    Truth Table\n   </strong>\n   : Figure 2.20 shows the truth table for\n   Y\n   Y\n   Y\n   and its complement\n   Y\n   \u2032\n   Y'\n   Y\n   \u2032\n   .\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Sum-of-Products Form\n   </strong>\n   : The sum-of-products canonical form of\n   Y\n   \u2032\n   Y'\n   Y\n   \u2032\n   is represented in Figure 2.21, where specific minterms are circled.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Using De Morgan's Theorem\n   </strong>\n   : By applying De Morgan's Theorem twice to the sum-of-products form, we can derive the product-of-sums canonical form of\n   Y\n   Y\n   Y\n   .\n  </p>\n </li>\n</ol>\n<h3>\n Proving Theorems in Boolean Algebra\n</h3>\n<p>\n To prove that a theorem is true in Boolean algebra, you can use a method called perfect induction. This involves showing that the theorem holds for all possible combinations of its variables, which can be easily demonstrated using a truth table.\n</p>\n<h3>\n Example: Proving the Consensus Theorem\n</h3>\n<p>\n To prove the consensus theorem (T11) from Table 2.3:\n</p>\n<ol>\n <li>\n  <p>\n   <strong>\n    Combinations\n   </strong>\n   : Check both sides of the theorem for all eight combinations of variables\n   B\n   B\n   B\n   ,\n   C\n   C\n   C\n   , and\n   D\n   D\n   D\n   .\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Truth Table\n   </strong>\n   : Figure 2.22 provides a truth table that illustrates all combinations.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Conclusion\n   </strong>\n   : Since both sides of the theorem yield the same result in all cases, the theorem is successfully proven.\n  </p>\n </li>\n</ol>\n"}, "Page 65": {"response": "<h3>\n Simplifying Equations in Boolean Algebra\n</h3>\n<p>\n Boolean algebra theorems are useful for simplifying Boolean equations. For instance, consider a sum-of-products expression derived from a truth table. By applying Theorem T10, we can simplify the equation step by step. This might seem straightforward with simpler expressions, but more complex equations often require multiple steps for simplification.\n</p>\n<h4>\n Basic Principles\n</h4>\n<p>\n The main goal in simplifying sum-of-products equations is to combine terms using the relationship\n P\n P\n P\n , where\n P\n P\n P\n can be any implicant. An equation is considered minimized if it uses the least number of implicants. If there are multiple equations with the same number of implicants, the one with the fewest literals is the minimal one.\n</p>\n<p>\n An implicant is termed a\n <strong>\n  prime implicant\n </strong>\n if it can't be combined with any other implicants to create a new implicant with fewer literals. In a minimal equation, all implicants must be prime; otherwise, they could still be combined to reduce the number of literals.\n</p>\n<h3>\n Example: Equation Minimization\n</h3>\n<p>\n Let's minimize a specific equation:\n</p>\n<ol>\n <li>\n  <p>\n   <strong>\n    Starting Point\n   </strong>\n   : Begin with the original equation and apply Boolean theorems step-by-step to simplify it.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Combining Minterms\n   </strong>\n   : From the original equation, observe that two minterms differ only by variable\n   A\n   A\n   A\n   , so they can be combined.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Further Combination\n   </strong>\n   : Similarly, the last two minterms differ by a single literal (C). We can combine these as well.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Multiple Simplifications\n   </strong>\n   : We can use the idempotency theorem, which allows us to duplicate terms as needed. This means we can simplify the equation fully to its two prime implicants.\n  </p>\n </li>\n</ol>\n<p>\n By applying these principles and techniques, we arrive at the simplified form of the original equation, demonstrating how Boolean algebra can efficiently reduce complexity in equations.\n</p>\n"}, "Page 66": {"response": "<h3>\n Expanding Implicants and Simplifying Equations\n</h3>\n<p>\n Although it may seem unusual, expanding an implicant (like turning\n A\n B\n AB\n A\n B\n into\n A\n \u22c5\n B\n A \\cdot B\n A\n \u22c5\n B\n ) can be helpful for minimizing equations. This approach allows you to repeat an expanded minterm, making it possible to combine it with another minterm.\n</p>\n<p>\n Simplifying a Boolean equation using theorems of Boolean algebra can involve some trial and error. To make this process easier, the next section introduces a systematic technique called\n <strong>\n  Karnaugh maps\n </strong>\n .\n</p>\n<h4>\n Why Simplify?\n</h4>\n<p>\n Even though a simplified equation is still logically equivalent to the original, simplification is important because it reduces the number of gates needed to physically implement the function. This leads to smaller, cheaper, and potentially faster circuits.\n</p>\n<h3>\n From Logic to Gates\n</h3>\n<p>\n A\n <strong>\n  schematic\n </strong>\n is a diagram that shows a digital circuit's components and how they are connected. For instance, Figure 2.23 illustrates a hardware implementation of a logic function represented by the equation:\n</p>\n<p>\n Y\n =\n A\n \u22c5\n B\n +\n C\n +\n A\n B\n \u22c5\n C\n +\n A\n B\n C\n .\n Y = A \\cdot B + C + AB \\cdot C + ABC.\n Y\n =\n A\n \u22c5\n B\n +\n C\n +\n A\n B\n \u22c5\n C\n +\n A\n BC\n .\n</p>\n<h3>\n Example of Equation Minimization\n</h3>\n<p>\n Here\u2019s a breakdown of the steps involved in minimizing an equation:\n</p>\n<ol>\n <li>\n  <strong>\n   Step 1\n  </strong>\n  : Apply the\n  <strong>\n   Distributivity\n  </strong>\n  theorem (T8).\n </li>\n <li>\n  <strong>\n   Step 2\n  </strong>\n  : Use the\n  <strong>\n   Complements\n  </strong>\n  theorem (T5).\n </li>\n <li>\n  <strong>\n   Step 3\n  </strong>\n  : Apply the\n  <strong>\n   Identity\n  </strong>\n  theorem (T1).\n </li>\n</ol>\n<p>\n These steps progressively simplify the equation, illustrating the process of improving the expression while maintaining its logical integrity.\n</p>\n"}, "Page 67": {"response": "<h3>\n Guidelines for Drawing Schematics\n</h3>\n<p>\n To make schematics easier to read and troubleshoot, we should follow these guidelines:\n</p>\n<ol>\n <li>\n  <strong>\n   Input Placement\n  </strong>\n  : Inputs should be on the left or top side of the schematic.\n </li>\n <li>\n  <strong>\n   Output Placement\n  </strong>\n  : Outputs should be on the right or bottom side.\n </li>\n <li>\n  <strong>\n   Flow Direction\n  </strong>\n  : Gates should generally flow from left to right.\n </li>\n <li>\n  <strong>\n   Wire Straightness\n  </strong>\n  : Use straight wires instead of jagged ones to make it easier to follow the circuit.\n </li>\n <li>\n  <strong>\n   T Junctions\n  </strong>\n  : Wires should connect at T junctions.\n </li>\n <li>\n  <strong>\n   Connection Dots\n  </strong>\n  : A dot at the intersection of wires indicates they are connected.\n </li>\n <li>\n  <strong>\n   Non-connection\n  </strong>\n  : Wires crossing without a dot do not connect.\n </li>\n</ol>\n<h3>\n Creating Schematic from Boolean Equations\n</h3>\n<p>\n Any Boolean equation in sum-of-products form can be systematically drawn as a schematic. Here\u2019s how:\n</p>\n<ol>\n <li>\n  <strong>\n   Draw Input Columns\n  </strong>\n  : Start with columns for the inputs.\n </li>\n <li>\n  <strong>\n   Add Inverters\n  </strong>\n  : Place inverters next to the inputs to provide complementary values if needed.\n </li>\n <li>\n  <strong>\n   Draw AND Gates\n  </strong>\n  : Create rows of AND gates for each minterm.\n </li>\n <li>\n  <strong>\n   Draw OR Gates\n  </strong>\n  : For each output, draw an OR gate connected to the relevant minterms.\n </li>\n</ol>\n<p>\n This approach is known as a\n <strong>\n  Programmable Logic Array (PLA)\n </strong>\n , where inverters, AND gates, and OR gates are arranged systematically.\n</p>\n<h3>\n Example Implementation\n</h3>\n<p>\n Figure 2.25 shows a simplified circuit based on the Boolean algebra example from earlier. This circuit uses significantly less hardware than the earlier schematic in Figure 2.23 and may also operate faster due to fewer input gates.\n</p>\n<p>\n We can reduce the number of gates even more by using inverting gates. For example, by using an inverter effectively, we can simplify the circuit further.\n</p>\n"}, "Page 68": {"response": "<h3>\n Optimizing Logic Circuits\n</h3>\n<p>\n Using an AND gate with inverted inputs can sometimes eliminate the need for an inverter, making the circuit simpler. According to De Morgan's theorem, this configuration is equivalent to a NOR gate. Depending on the technology used for implementation, it might be more cost-effective to use fewer gates or specific types of gates, such as NANDs and NORs, instead of traditional ANDs and ORs, especially in CMOS technology.\n</p>\n<h3>\n Multiple-Output Circuits\n</h3>\n<p>\n Many circuits have several outputs, each performing a different Boolean function based on the same inputs. Instead of creating a separate truth table for each output, it's often easier to combine them into a single truth table and sketch one schematic for all outputs.\n</p>\n<h3>\n Example: Room Reservation System\n</h3>\n<p>\n A room reservation system was designed to prevent scheduling conflicts among users, like the dean, department chair, teaching assistant, and dorm social chair. The system has four inputs (A3, A2, A1, A0) and four outputs (Y3, Y2, Y1, Y0), where each input represents a request for the auditorium. Only one output is asserted at a time, granting access to the highest priority user:\n</p>\n<ul>\n <li>\n  <strong>\n   Y3\n  </strong>\n  (highest priority) is active when\n  <strong>\n   A3\n  </strong>\n  is asserted.\n </li>\n <li>\n  <strong>\n   Y2\n  </strong>\n  is active when\n  <strong>\n   A2\n  </strong>\n  is asserted and\n  <strong>\n   A3\n  </strong>\n  is not.\n </li>\n <li>\n  <strong>\n   Y1\n  </strong>\n  is active when\n  <strong>\n   A1\n  </strong>\n  is asserted, and neither\n  <strong>\n   A3\n  </strong>\n  nor\n  <strong>\n   A2\n  </strong>\n  is active.\n </li>\n <li>\n  <strong>\n   Y0\n  </strong>\n  is active when\n  <strong>\n   A0\n  </strong>\n  is asserted, and none of the higher priority inputs are active.\n </li>\n</ul>\n<p>\n The priority circuit's truth table and schematic are shown in the figures. An experienced designer can often derive the necessary equations directly from the functional description, converting them into gates efficiently.\n</p>\n"}, "Page 69": {"response": "<p>\n In the priority circuit, if input A3 is active, the output doesn't depend on the other inputs. We use the symbol \"X\" to represent inputs that the output ignores, simplifying the truth table. Figure 2.29 shows how this makes the truth table smaller. From this table, we can easily derive Boolean equations in sum-of-products form by disregarding inputs marked with \"X.\"\n</p>\n<p>\n \"Don't care\" conditions can also occur in the outputs, which will be explained in more detail in Section 2.7.3.\n</p>\n<h3>\n Multilevel Combinational Logic\n</h3>\n<p>\n Logic in sum-of-products form is referred to as two-level logic. This consists of literals connected to a layer of AND gates, which then connect to a layer of OR gates.\n</p>\n"}, "Page 70": {"response": "<h3>\n Multilevel Combinational Logic\n</h3>\n<p>\n Circuits can be designed with more than two levels of logic gates, known as multilevel combinational circuits. These circuits can use less hardware than two-level circuits. Bubble pushing is a useful technique for analyzing and designing these more complex circuits.\n</p>\n<h4>\n Hardware Reduction\n</h4>\n<p>\n Some logic functions, like the XOR function for multiple variables, can require a lot of hardware if built using just two-level logic. For example, a three-input XOR outputs TRUE when an odd number of inputs are TRUE. The truth table for a three-input XOR is shown in Figure 2.30, with the TRUE output rows circled. The corresponding Boolean equation in sum-of-products form cannot be simplified to use fewer implicants.\n</p>\n<p>\n Instead of a two-level approach, the three-input XOR can be efficiently constructed using a cascade of two-input XOR gates, as depicted in Figure 2.31. For larger inputs, like an eight-input XOR, a two-level implementation would need 128 eight-input AND gates and one 128-input OR gate, which is impractical. A better solution is to use a tree structure of two-input XOR gates, as illustrated in Figure 2.32.\n</p>\n"}, "Page 71": {"response": "<h3>\n Selecting the Best Multilevel Implementation\n</h3>\n<p>\n Choosing the best multilevel design for a specific logic function can be complex because \"best\" can mean different things, such as:\n</p>\n<ul>\n <li>\n  Fewest gates\n </li>\n <li>\n  Fastest performance\n </li>\n <li>\n  Shortest design time\n </li>\n <li>\n  Lowest cost\n </li>\n <li>\n  Least power consumption\n </li>\n</ul>\n<p>\n In Chapter 5, you'll learn that the optimal circuit can vary based on the technology used. For instance, while ANDs and ORs are common, NANDs and NORs are often more efficient in CMOS technology. With experience, you'll be able to design good multilevel circuits by inspection, and you will gain this experience as you study various examples in the book. It's beneficial to explore different design options and consider the trade-offs involved. Additionally, computer-aided design (CAD) tools can help you explore a wide range of possible multilevel designs and find the best fit based on your specific constraints and available components.\n</p>\n<h3>\n Bubble Pushing\n</h3>\n<p>\n In CMOS circuits, NANDs and NORs are preferred over ANDs and ORs, but analyzing multilevel circuits with these gates can be challenging. Figure 2.33 illustrates a multilevel circuit where the function isn't immediately clear. Bubble pushing is a technique that simplifies the analysis of such circuits by canceling out bubbles to clarify the function.\n</p>\n<p>\n Here are the guidelines for bubble pushing:\n</p>\n<ol>\n <li>\n  Start at the output and work towards the inputs.\n </li>\n <li>\n  Push any bubbles on the final output back toward the inputs, allowing you to read the equation in terms of the output (Y) instead of its complement (\n  Y\n  \u2032\n  Y'\n  Y\n  \u2032\n  ).\n </li>\n <li>\n  As you work backward, draw each gate in a way that cancels the bubbles. If the current gate has an input bubble, the preceding gate should have an output bubble, and vice versa.\n </li>\n</ol>\n<p>\n Figure 2.34 shows how to apply these guidelines to the circuit in Figure 2.33. Starting from the output\n Y\n Y\n Y\n , the NAND gate has a bubble on its output that needs to be eliminated. By pushing this bubble back, you transform it into an OR gate with inverted inputs.\n</p>\n"}, "Page 72": {"response": "<h3>\n Bubble Pushing Steps\n</h3>\n<p>\n In Figure 2.34(a), as we work from right to left, we see that the rightmost gate has an input bubble that cancels with the output bubble of the middle NAND gate. This means we don't need to make any changes, as shown in Figure 2.34(b).\n</p>\n<p>\n Next, since the middle gate has no input bubble, we modify the leftmost gate to also have no output bubble, as shown in Figure 2.34(c). Now, all bubbles in the circuit cancel out except those at the inputs, allowing us to easily read the circuit's function as a combination of ANDs and ORs with true or inverted inputs.\n</p>\n<p>\n To emphasize this point, Figure 2.35 presents a circuit that is logically equivalent to the one in Figure 2.34. In this diagram, the functions of the internal nodes are labeled in blue. Because bubbles in series cancel each other, we can ignore the bubble on the output of the middle gate and the input of the rightmost gate, resulting in the equivalent circuit in Figure 2.35.\n</p>\n<p>\n The final output can be expressed as:\n Y\n =\n A\n B\n C\n +\n D\n Y = ABC + D\n Y\n =\n A\n BC\n +\n D\n</p>\n"}, "Page 73": {"response": "<h3>\n Example 2.8: Bubble Pushing for CMOS Logic\n</h3>\n<p>\n Designers typically work with AND and OR gates, but if you want to implement a circuit in CMOS logic, which prefers NAND and NOR gates, bubble pushing can help convert the circuit.\n</p>\n<p>\n <strong>\n  Solution:\n </strong>\n</p>\n<ol>\n <li>\n  <p>\n   <strong>\n    Brute Force Approach:\n   </strong>\n   The simplest way is to replace each AND gate with a NAND gate followed by an inverter, and each OR gate with a NOR gate followed by an inverter. This approach requires eight gates, as shown in Figure 2.37. Note that the inverter is drawn with its bubble in front to highlight how it can cancel with the preceding inverting gate.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Optimized Approach:\n   </strong>\n   A more efficient solution is to add bubbles to the output of a gate and the input of the next gate without changing the circuit\u2019s function, as shown in Figure 2.38(a). For the final AND gate, convert it to a NAND gate and an inverter, as depicted in Figure 2.38(b). This method reduces the total to only five gates.\n  </p>\n </li>\n</ol>\n<h3>\n 2.6 X\u2019s and Z\u2019s, Oh My\n</h3>\n<p>\n While Boolean algebra is limited to values of 0 and 1, real circuits can also have illegal and floating values, represented as X and Z.\n</p>\n<h4>\n 2.6.1 Illegal Value: X\n</h4>\n<p>\n The symbol X represents an unknown or illegal value at a circuit node. This situation usually occurs when a node is driven by both HIGH (1) and LOW (0) signals simultaneously, leading to a conflict known as contention. Figure 2.39 illustrates this, showing node Y being driven both HIGH and LOW, which is considered an error.\n</p>\n"}, "Page 74": {"response": "<p>\n Contention can occur when two gates are trying to drive a node to different values (one HIGH and one LOW). The actual voltage at that node may be between 0 and VDD, depending on which gate is stronger, and it often ends up in an unstable, forbidden state. This situation can cause excessive power flow between the conflicting gates, leading to overheating and potential damage to the circuit.\n</p>\n<p>\n In circuit simulation, an X value might also indicate an uninitialized state. For instance, if you forget to set an input value, the simulator may mark it as X to alert you to the issue. It\u2019s important not to confuse this with the \"don\u2019t care\" symbol X used in truth tables, where it signifies that the value is irrelevant.\n</p>\n<h3>\n 2.6.2: Floating Value: Z\n</h3>\n<p>\n The symbol Z indicates that a node is not being driven HIGH or LOW, meaning it is floating or in a high-impedance state. Many people mistakenly think that a floating node is equivalent to logic 0. In reality, it could be at 0, 1, or any voltage in between, depending on what has happened in the circuit. A floating node is not necessarily an error, as long as another part of the circuit can set it to a valid level when needed.\n</p>\n<p>\n Floating nodes can occur if you forget to connect a voltage to an input, or if you incorrectly assume that an unconnected input acts like a logic 0. This can lead to erratic circuit behavior as the floating input fluctuates between 0 and 1. For example, touching the circuit can introduce static electricity, causing changes in the floating state. Some circuits may only function correctly when someone is physically touching them.\n</p>\n<p>\n A\n <strong>\n  tristate buffer\n </strong>\n (shown in Figure 2.40) has three output states: HIGH (1), LOW (0), and floating (Z). It has an input (A), an output (Y), and an enable signal (E). When E is HIGH (1), the buffer acts as a regular buffer, passing the input value to the output. When E is LOW (0), the output is allowed to float (Z).\n</p>\n<p>\n There are also tristate buffers with active low enables, as shown in Figure 2.41. In this case, the buffer is enabled when E is LOW (0).\n</p>\n"}, "Page 75": {"response": "<p>\n The tristate buffer can be enabled by applying a LOW signal to its input, which we indicate with a bubble on the wire. Active low signals are often represented by placing a bar over their name (e.g., E\u0305) or by adding the word \u201cbar\u201d after the name.\n</p>\n<p>\n Tristate buffers are frequently used in bus systems that connect multiple chips. For instance, a microprocessor, a video controller, and an Ethernet controller may all need to communicate with the same memory in a personal computer. Each chip can connect to a shared memory bus using tristate buffers, as shown in Figure 2.42. Only one chip can enable its buffer at a time to send data onto the bus, while the others must have their outputs in a floating state to prevent contention. Any chip can read data from the bus whenever needed. Although tristate buses were common, modern computers often use faster point-to-point links that directly connect chips instead of using a shared bus.\n</p>\n<h3>\n 2.7: Karnaugh Maps\n</h3>\n<p>\n After trying to simplify Boolean equations with algebra, you might find that you sometimes end up with a completely different equation rather than a simpler one. Karnaugh maps (K-maps) are a graphical tool for simplifying Boolean equations, created by Maurice Karnaugh in 1953 at Bell Labs. K-maps are particularly effective for problems with up to four variables and help provide clarity in manipulating Boolean equations.\n</p>\n"}, "Page 76": {"response": "<p>\n Logic minimization involves combining terms to simplify expressions. When you have two terms that include an implicant\n P\n P\n P\n along with both the true and complementary forms of a variable\n A\n A\n A\n , you can combine them to eliminate\n A\n A\n A\n .\n</p>\n<p>\n Karnaugh maps (K-maps) help visualize these combinable terms by organizing them in a grid format. For instance, Figure 2.43 displays the truth table and K-map for a three-input function. The top row of the K-map shows the four possible combinations of the inputs\n A\n A\n A\n and\n B\n B\n B\n , while the left column shows the two possible values for input\n C\n C\n C\n . Each square in the K-map corresponds to a row in the truth table and contains the output value\n Y\n Y\n Y\n for that combination of inputs. For example, the top left square indicates that when\n A\n ,\n B\n ,\n C\n A, B, C\n A\n ,\n B\n ,\n C\n are\n 000\n 000\n 000\n , the output\n Y\n Y\n Y\n is\n 1\n 1\n 1\n . Each square represents a single minterm, as shown in Figure 2.43(c).\n</p>\n<p>\n Adjacent squares in the K-map differ by only one variable, meaning they share all the same literals except for that one. For example, two squares that represent the minterms\n P\n P\n P\n and\n \u00ac\n P\n \\neg P\n \u00ac\n P\n differ only in variable\n C\n C\n C\n . The order of the\n A\n A\n A\n and\n B\n B\n B\n combinations follows a pattern called Gray code, where adjacent values differ in just one variable. For instance,\n 01\n 01\n 01\n to\n 11\n 11\n 11\n changes only\n A\n A\n A\n from 0 to 1, while\n 01\n 01\n 01\n to\n 10\n 10\n 10\n changes both\n A\n A\n A\n and\n B\n B\n B\n .\n</p>\n<p>\n The K-map also wraps around, meaning that the squares on the far right are adjacent to those on the far left, differing by only one variable\n A\n A\n A\n . You can imagine rolling the K-map into a cylinder or torus, ensuring that adjacent squares still differ by just one variable.\n</p>\n<h3>\n 2.7.1 Circular Thinking\n</h3>\n<p>\n In the K-map from Figure 2.43, only two minterms, represented by 1's in the left column, are included in the equation. Reading these minterms from the K-map is equivalent to reading the sum-of-products form directly from the truth table.\n</p>\n<p>\n <strong>\n  Additional Note on Gray Codes\n </strong>\n : Gray codes, patented by Frank Gray in 1953, are especially useful in mechanical encoders because slight misalignments result in errors in only one bit. A 3-bit Gray code sequence includes: 000, 001, 011, 010, 110, 111, 101, 100. This concept is related to a puzzle proposed by Lewis Carroll in 1879, which involves transforming one word into another by changing one letter at a time. For example, transforming \"SHIP\" to \"DOCK\" could follow the sequence: SHIP, SLIP, SLOP, SLOT, SOOT, LOOT, LOOK, LOCK, DOCK.\n</p>\n"}, "Page 77": {"response": "<p>\n You can use Boolean algebra to simplify equations in sum-of-products form, just like before. However, Karnaugh maps (K-maps) offer a visual way to do this by circling the 1's in adjacent squares, as illustrated in Figure 2.44. For each circle you draw, write down the corresponding implicant.\n</p>\n<p>\n An implicant is made up of one or more literals. If both the true and complementary forms of a variable are present in a circle, that variable is excluded from the implicant. For example, if variable\n C\n C\n C\n has both 1 and 0 in the circle, it won't be included. This means that\n Y\n Y\n Y\n is TRUE when\n A\n A\n A\n and\n B\n B\n B\n are both 0, regardless of\n C\n C\n C\n . So, the implicant is\n A\n \u2032\n B\n \u2032\n A'B'\n A\n \u2032\n B\n \u2032\n . This result matches what you would find using Boolean algebra.\n</p>\n<h3>\n 2.7.2 Logic Minimization with K-Maps\n</h3>\n<p>\n K-maps simplify logic minimization visually. To do this, circle all the rectangular blocks of 1's on the map using the smallest number of circles, making each circle as large as possible. After circling, you can read off the implicants from the circles.\n</p>\n<p>\n Formally, a Boolean equation is considered minimized when it is expressed as a sum of the fewest prime implicants. Each circle on the K-map represents an implicant, and the largest circles correspond to prime implicants.\n</p>\n<p>\n In summary, using K-maps is an effective way to visually minimize logical expressions by identifying and circling the largest groups of 1's.\n</p>\n"}, "Page 78": {"response": "<p>\n In the K-map from Figure 2.44, the implicants\n A\n B\n \u2032\n C\n \u2032\n AB'C'\n A\n B\n \u2032\n C\n \u2032\n and\n A\n \u2032\n B\n C\n A'BC\n A\n \u2032\n BC\n are not prime implicants, while only\n A\n \u2032\n B\n \u2032\n A'B'\n A\n \u2032\n B\n \u2032\n is a prime implicant. Here are the rules for finding a minimized equation from a K-map:\n</p>\n<ol>\n <li>\n  Use the fewest circles necessary to cover all the 1's.\n </li>\n <li>\n  All squares within each circle must contain 1's.\n </li>\n <li>\n  Each circle must form a rectangular block that covers a number of squares that is a power of 2 (such as 1, 2, or 4).\n </li>\n <li>\n  Each circle should be as large as possible.\n </li>\n <li>\n  Circles can wrap around the edges of the K-map.\n </li>\n <li>\n  A 1 in the K-map may be circled multiple times if this helps reduce the total number of circles needed.\n </li>\n</ol>\n<h3>\n Example 2.9: Minimizing a Three-Variable Function Using a K-Map\n</h3>\n<p>\n Consider the function\n Y\n =\n F\n (\n A\n ,\n B\n ,\n C\n )\n Y = F(A, B, C)\n Y\n =\n F\n (\n A\n ,\n B\n ,\n C\n )\n with the K-map shown in Figure 2.45. To minimize the equation using the K-map:\n</p>\n<ol>\n <li>\n  <p>\n   Circle the 1's in the K-map with as few circles as possible, as seen in Figure 2.46. Each circle represents a prime implicant, and the size of each circle must be a power of two (like 2x1 or 2x2).\n  </p>\n </li>\n <li>\n  <p>\n   Form the prime implicant for each circle by including only those variables that appear in true or complementary form within the circle. For instance, in a 2x1 circle, both true and complementary forms of variable\n   B\n   B\n   B\n   are present, so\n   B\n   B\n   B\n   is excluded from the prime implicant. However, since only the true form of\n   A\n   A\n   A\n   and the complementary form of\n   C\n   C\n   C\n   are present, we include\n   A\n   A\n   A\n   and\n   C\n   \u2032\n   C'\n   C\n   \u2032\n   in the prime implicant, resulting in\n   A\n   C\n   \u2032\n   AC'\n   A\n   C\n   \u2032\n   .\n  </p>\n </li>\n <li>\n  <p>\n   The 2x2 circle covers all squares where\n   B\n   =\n   0\n   B = 0\n   B\n   =\n   0\n   , making its prime implicant\n   A\n   \u2032\n   C\n   \u2032\n   A'C'\n   A\n   \u2032\n   C\n   \u2032\n   .\n  </p>\n </li>\n <li>\n  <p>\n   Notice that the top-right square (minterm) is covered twice to allow the prime implicant circles to be as large as possible. This is similar to sharing a minterm when using Boolean algebra techniques to reduce equation size.\n  </p>\n </li>\n</ol>\n"}, "Page 79": {"response": "<p>\n In the K-map example, one circle covers four squares and wraps around the edges of the map.\n</p>\n<h3>\n Example 2.10: Seven-Segment Display Decoder\n</h3>\n<p>\n A seven-segment display decoder takes a 4-bit input (D3:0) and produces seven outputs to control light-emitting diodes that display digits from 0 to 9. The outputs, labeled segments a through g (or S_a to S_g), are defined in Figure 2.47, while the corresponding digit displays are shown in Figure 2.48.\n</p>\n<h4>\n Truth Table and K-maps\n</h4>\n<ol>\n <li>\n  <p>\n   <strong>\n    Truth Table\n   </strong>\n   : The truth table is presented in Table 2.6. For example, when the input is 0000, all segments except S_g should light up.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Independent Outputs\n   </strong>\n   : Each of the seven outputs is based on four input variables. The K-maps for outputs S_a and S_b are illustrated in Figure 2.49. The rows and columns are labeled in Gray code order: 00, 01, 11, 10, which ensures that adjacent squares differ by only one variable.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Circle Prime Implicants\n   </strong>\n   : Next, circle the prime implicants while using the fewest circles to cover all 1\u2019s. Circles can wrap around the edges, and a 1 can be included in multiple circles. Figure 2.50 displays the prime implicants and the simplified Boolean equations.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Non-unique Minimal Sets\n   </strong>\n   : The minimal set of prime implicants is not unique. For instance, in the S_a K-map, the entry for 0000 could be combined with 1000 to produce a minterm. Alternatively, it could combine with 0010, resulting in a different minterm, shown with dashed lines in Figure 2.51.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Common Errors\n   </strong>\n   : Figure 2.52 illustrates a common mistake where a non-prime implicant was selected to cover a 1 in the upper left corner. This leads to a sum-of-products equation that isn't minimal. Instead, the minterm could have been combined with adjacent ones to form a larger circle, as shown in previous figures.\n  </p>\n </li>\n</ol>\n"}, "Page 80": {"response": "<h3>\n Seven-Segment Display Decoder Overview\n</h3>\n<p>\n The seven-segment display decoder converts a 4-bit input (D3:0) into seven outputs to control light-emitting diodes, allowing it to display digits from 0 to 9. The outputs are labeled segments a through g (S_a to S_g).\n</p>\n<h4>\n Truth Table\n</h4>\n<p>\n The truth table (Table 2.6) outlines the input-output relationships. For instance, when the input is 0000 (which represents the digit 0), all segments except S_g light up.\n</p>\n<h4>\n K-Maps for Outputs\n</h4>\n<p>\n Figures 2.49 shows the Karnaugh maps for outputs S_a and S_b. The rows and columns are arranged in Gray code order (00, 01, 11, 10), ensuring adjacent squares differ by only one variable.\n</p>\n<h4>\n Input Combinations and Outputs\n</h4>\n<ul>\n <li>\n  <strong>\n   Inputs and Outputs\n  </strong>\n  : The truth table also specifies the output for each 4-bit input combination:\n  <ul>\n   <li>\n    For 0000: S_a to S_f are ON, S_g is OFF.\n   </li>\n   <li>\n    For 0001: S_b to S_f are ON, S_a is OFF.\n   </li>\n   <li>\n    And so forth for each input from 0000 to 1001.\n   </li>\n  </ul>\n </li>\n</ul>\n<p>\n Figure 2.48 displays how these outputs correspond to the digits 0 through 9.\n</p>\n<h3>\n Summary\n</h3>\n<p>\n In summary, the seven-segment decoder takes 4-bit binary inputs and translates them into visual outputs by controlling seven segments, facilitating the display of decimal digits. The K-maps help simplify and visualize the logic behind the outputs.\n</p>\n"}, "Page 81": {"response": "<h3>\n Don\u2019t Cares in Logic Design\n</h3>\n<p>\n <strong>\n  Definition\n </strong>\n : \"Don\u2019t care\" entries in truth tables represent situations where certain input combinations do not affect the output. These are marked with an X, indicating that the entry can be either 0 or 1, depending on the designer's choice.\n</p>\n<p>\n <strong>\n  Usage\n </strong>\n : Don\u2019t care conditions can also occur in the output of a truth table, where the output is unimportant or certain input combinations can never occur. In these cases, designers can treat these entries as either 0 or 1 to simplify logic expressions.\n</p>\n<h3>\n Example with K-Maps\n</h3>\n<p>\n In Karnaugh maps (K-maps), don\u2019t cares can be used strategically to minimize the number of terms in a Boolean equation. By treating these entries flexibly, designers can create simpler and more efficient logic expressions.\n</p>\n<p>\n <strong>\n  Key Points\n </strong>\n :\n</p>\n<ul>\n <li>\n  <strong>\n   Symbol\n  </strong>\n  : Don\u2019t care values are represented by X.\n </li>\n <li>\n  <strong>\n   Flexibility\n  </strong>\n  : Designers can choose to treat these values as either 0 or 1 when simplifying expressions.\n </li>\n <li>\n  <strong>\n   Impact on Minimization\n  </strong>\n  : Using don\u2019t cares effectively can lead to fewer terms and a more streamlined logic design.\n </li>\n</ul>\n"}, "Page 82": {"response": "<h3>\n Using Don\u2019t Cares in K-Maps\n</h3>\n<p>\n In Karnaugh maps (K-maps), \"don\u2019t care\" values (marked as X) enhance logic minimization. You can circle these X\u2019s if doing so helps cover the 1's with fewer or larger circles. However, it\u2019s not necessary to circle them if they don\u2019t contribute to simplification.\n</p>\n<h3>\n Example of a Seven-Segment Display Decoder with Don\u2019t Cares\n</h3>\n<p>\n <strong>\n  Context\n </strong>\n : In this example, we\u2019ll consider the seven-segment display decoder from a previous example, but this time we\u2019ll include don\u2019t care conditions for illegal input values (10 to 15).\n</p>\n<p>\n <strong>\n  Solution\n </strong>\n : The K-map with don\u2019t care entries is shown in Figure 2.53. Here, the X's represent these don\u2019t cares. Since these values can be treated as either 0 or 1, you can choose to circle a don\u2019t care if it helps create larger or fewer circles covering the 1's. Don\u2019t cares that are circled are treated as 1's, while those that are not circled are treated as 0's. For instance, a 2x2 square wrapping around all four corners can be circled for segment Sa, which significantly simplifies the logic.\n</p>\n<h3>\n The Bigger Picture\n</h3>\n<p>\n Both Boolean algebra and K-maps are tools for simplifying logic functions. The main objective is to find a cost-effective way to implement a specific logic function.\n</p>\n<p>\n In today\u2019s engineering, logic synthesizers\u2014computer programs that automatically create simplified circuits from a logic function description\u2014are commonly used. These tools are more efficient for large problems compared to manual methods. For smaller problems, an experienced person can often find a good solution through observation. Interestingly, the authors mention that they have never used K-maps in practical situations.\n</p>\n"}, "Page 83": {"response": "<h3>\n Practical Applications of Karnaugh Maps\n</h3>\n<p>\n While Karnaugh maps (K-maps) may not be used in every practical problem, the understanding of their principles is important. They often come up in job interviews, so it\u2019s useful to be familiar with them.\n</p>\n<h3>\n 2.8 Combinational Building Blocks\n</h3>\n<p>\n Combinational logic circuits can be grouped into larger components, known as building blocks. This grouping simplifies the design by focusing on the block's function rather than the details of individual gates. We\u2019ve already looked at three building blocks: full adders, priority circuits, and seven-segment display decoders. Now, we\u2019ll introduce two more common building blocks: multiplexers and decoders. More building blocks will be covered in Chapter 5.\n</p>\n<h3>\n 2.8.1 Multiplexers\n</h3>\n<p>\n Multiplexers, or \"muxes,\" are widely used combinational circuits. They select one output from multiple inputs based on a control signal.\n</p>\n<h4>\n 2:1 Multiplexer\n</h4>\n<p>\n The 2:1 multiplexer has two data inputs (D0 and D1), a select input (S), and one output (Y). Its operation is straightforward:\n</p>\n<ul>\n <li>\n  If the select input (S) is 0, the output (Y) will be D0.\n </li>\n <li>\n  If S is 1, then Y will be D1.\n </li>\n</ul>\n<p>\n The select input is also called the control signal because it determines which data input is routed to the output.\n</p>\n"}, "Page 84": {"response": "<h3>\n 2:1 Multiplexer Basics\n</h3>\n<p>\n A\n <strong>\n  2:1 multiplexer\n </strong>\n can be created using sum-of-products logic. The output (Y) is 1 if:\n</p>\n<ul>\n <li>\n  The select input (S) is 0 and data input D0 is 1,\n  <strong>\n   OR\n  </strong>\n </li>\n <li>\n  The select input (S) is 1 and data input D1 is 1.\n </li>\n</ul>\n<p>\n You can derive the Boolean equation for the multiplexer using a K-map or by visual inspection.\n</p>\n<p>\n Another way to build a multiplexer is by using\n <strong>\n  tristate buffers\n </strong>\n . In this setup, only one tristate buffer is active at any time. For example:\n</p>\n<ul>\n <li>\n  When S is 0, tristate buffer T0 is active, allowing D0 to be outputted as Y.\n </li>\n <li>\n  When S is 1, tristate buffer T1 is active, allowing D1 to be outputted as Y.\n </li>\n</ul>\n<h3>\n Wider Multiplexers\n</h3>\n<p>\n A\n <strong>\n  4:1 multiplexer\n </strong>\n has four data inputs and one output. It requires two select signals to choose which data input to route to the output. Like the 2:1 version, the 4:1 multiplexer can be built using:\n</p>\n<ul>\n <li>\n  Sum-of-products logic\n </li>\n <li>\n  Tristate buffers\n </li>\n <li>\n  Multiple 2:1 multiplexers\n </li>\n</ul>\n<p>\n The enabling signals for the tristate buffers can be created using AND gates and inverters or a decoder, which will be discussed in the next section.\n</p>\n<p>\n For even larger multiplexers, like\n <strong>\n  8:1\n </strong>\n and\n <strong>\n  16:1\n </strong>\n , you can expand the methods used for the 4:1 multiplexer. Generally, an N:1 multiplexer requires\n <strong>\n  log2N\n </strong>\n select lines. The best construction method depends on the technology being used.\n</p>\n<h3>\n Multiplexer Logic\n</h3>\n<p>\n Multiplexers can also function as lookup tables for performing logic operations. For instance, a 4:1 multiplexer can implement a two-input logic function.\n</p>\n<p>\n <strong>\n  Note:\n </strong>\n Connecting the outputs of multiple gates together is usually against the rules for combinational circuits. However, since only one output is active at a time in this case, this practice is acceptable.\n</p>\n"}, "Page 85": {"response": "<h3>\n Multiplexers as Logic Functions\n</h3>\n<p>\n A\n <strong>\n  multiplexer\n </strong>\n can function as an\n <strong>\n  AND gate\n </strong>\n by using its inputs (A and B) as select lines. The data inputs of the multiplexer are connected to either 0 or 1 based on the truth table for the desired logic function. Generally, a\n <strong>\n  2N-input multiplexer\n </strong>\n can be set up to perform any N-input logic function by assigning the correct 0\u2019s and 1\u2019s to the data inputs. This means that the multiplexer can be easily reprogrammed to perform different functions just by changing the data inputs.\n</p>\n<p>\n To simplify design, you can also use a\n <strong>\n  2N-1-input multiplexer\n </strong>\n to achieve the same result. This approach involves providing one of the variables as a constant input along with 0\u2019s and 1\u2019s to the multiplexer data inputs.\n</p>\n<h4>\n Example: Implementing AND and XOR Functions\n</h4>\n<p>\n For example, a two-input\n <strong>\n  AND\n </strong>\n function can be implemented with\n <strong>\n  2:1 multiplexers\n </strong>\n . You can analyze the truth table and combine rows to reduce the number of variables. For AND:\n</p>\n<ul>\n <li>\n  When A = 0, the output Y = 0 regardless of B.\n </li>\n <li>\n  When A = 1, Y = B (if B = 1, Y = 1; if B = 0, Y = 0).\n </li>\n</ul>\n<p>\n Using this smaller truth table, you can use the multiplexer as a lookup table.\n</p>\n<h3>\n Example: Alyssa's Implementation\n</h3>\n<p>\n In\n <strong>\n  Example 2.12\n </strong>\n , Alyssa needs to implement the function\n Y\n =\n A\n B\n +\n B\n \u2032\n C\n +\n A\n B\n C\n Y = AB + B'C + ABC\n Y\n =\n A\n B\n +\n B\n \u2032\n C\n +\n A\n BC\n using an\n <strong>\n  8:1 multiplexer\n </strong>\n . The multiplexer will act as a lookup table where each row corresponds to an entry in the truth table.\n</p>\n<p>\n The diagram (not shown) illustrates how she sets up the multiplexer to achieve her desired logic function. By aligning the truth table with the multiplexer inputs, she effectively implements the required logic with the available component.\n</p>\n"}, "Page 86": {"response": "<h3>\n Alyssa's Circuit Redesign\n</h3>\n<p>\n In\n <strong>\n  Example 2.13\n </strong>\n , Alyssa's 8:1 multiplexer is damaged after she mistakenly powered it with 20V instead of 5V. With only a\n <strong>\n  4:1 multiplexer\n </strong>\n and an\n <strong>\n  inverter\n </strong>\n available, she needs to find a way to build her circuit.\n</p>\n<p>\n To adapt, Alyssa simplifies her truth table to just four rows by making the output depend on variable C. She could have also rearranged the truth table to depend on A or B, but she chose C. This approach allows her to effectively use the available parts to recreate her logic design.\n</p>\n<h3>\n Understanding Decoders\n</h3>\n<p>\n A\n <strong>\n  decoder\n </strong>\n has N inputs and produces\n 2\n N\n 2^N\n 2\n N\n outputs, activating only one output based on the input combination. For example, in a\n <strong>\n  2:4 decoder\n </strong>\n :\n</p>\n<ul>\n <li>\n  When the inputs\n  A\n  1\n  :\n  0\n  =\n  00\n  A1:0 = 00\n  A\n  1\n  :\n  0\n  =\n  00\n  , output\n  Y\n  0\n  Y0\n  Y\n  0\n  is activated (set to 1).\n </li>\n <li>\n  When\n  A\n  1\n  :\n  0\n  =\n  01\n  A1:0 = 01\n  A\n  1\n  :\n  0\n  =\n  01\n  , output\n  Y\n  1\n  Y1\n  Y\n  1\n  is activated, and so on.\n </li>\n</ul>\n<p>\n This means only one output is \"hot\" (or HIGH) at any time, making it\n</p>\n"}, "Page 87": {"response": "<h3>\n Example 2.14: Implementing a 2:4 Decoder\n</h3>\n<p>\n To create a\n <strong>\n  2:4 decoder\n </strong>\n using AND, OR, and NOT gates, we can follow the method shown in\n <strong>\n  Figure 2.64\n </strong>\n . This decoder uses four AND gates, with each gate taking either the true or the complementary form of the inputs\n A\n 1\n A1\n A\n 1\n and\n A\n 0\n A0\n A\n 0\n .\n</p>\n<p>\n In general, for an\n N\n :\n 2\n N\n N:2^N\n N\n :\n 2\n N\n decoder, you will need\n 2\n N\n 2^N\n 2\n N\n AND gates to cover all possible combinations of the inputs. Each output corresponds to a specific minterm; for instance,\n Y\n 0\n Y0\n Y\n 0\n represents the minterm where both inputs are low.\n</p>\n<h3>\n Combining Decoders with Other Logic\n</h3>\n<p>\n Decoders can be integrated with OR gates to create complex logic functions.\n <strong>\n  Figure 2.65\n </strong>\n illustrates how to use a 2:4 decoder to construct a two-input XNOR function. Since each decoder output corresponds to a minterm, the desired function is formed by OR-ing together the relevant minterms.\n</p>\n<p>\n In this case, the output\n Y\n Y\n Y\n is determined by the combination of\n A\n A\n A\n and\n B\n B\n B\n :\n</p>\nY\n=\nA\n\u2295\nB\n+\nA\nB\nY = A \\oplus B + AB\nY\n=\nA\n\u2295\nB\n+\nA\nB\n<p>\n This means\n Y\n Y\n Y\n is true when either\n A\n A\n A\n and\n B\n B\n B\n are equal or both are true.\n</p>\n"}, "Page 88": {"response": "<h3>\n Using Decoders in Logic Design\n</h3>\n<p>\n When creating logic functions with decoders, it's easiest to start with a truth table or express the function in canonical sum-of-products form. If you have an\n N\n N\n N\n -input function with\n M\n M\n M\n outputs set to 1 in the truth table, you can use an\n N\n :\n 2\n N\n N:2^N\n N\n :\n 2\n N\n decoder. Attach an\n M\n M\n M\n -input OR gate to the outputs corresponding to the minterms where the truth table has 1\u2019s. This approach will be applied when building Read-Only Memories (ROMs) later in the content.\n</p>\n<h3>\n Timing in Circuit Design\n</h3>\n<p>\n Previously, the focus was on whether a circuit functions correctly and efficiently, using the fewest gates. However, a key challenge in circuit design is timing\u2014ensuring that the circuit operates quickly.\n</p>\n<p>\n When an input changes, there is a delay before the output reflects that change.\n <strong>\n  Figure 2.66\n </strong>\n illustrates this delay for a buffer circuit. The timing diagram shows how the output (Y) changes in response to the input (A). The point where the input goes from LOW to HIGH is known as the rising edge, and the opposite transition (from HIGH to LOW) is the falling edge. The diagram measures the delay from the midpoint (50% point) of the input signal to the midpoint of the output signal. This midpoint represents when the signal is halfway between its LOW and HIGH values.\n</p>\n<h3>\n Propagation and Contamination Delay\n</h3>\n<p>\n In combinational logic, two key types of delay are important:\n</p>\n<ol>\n <li>\n  <p>\n   <strong>\n    Propagation Delay (\n    t\n    p\n    d\n    t_{pd}\n    t\n    p\n    d\n    \u200b\n    )\n   </strong>\n   : This is the maximum time it takes for the output to change after an input change. It reflects how long it takes to reach the final output value.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Contamination Delay (\n    t\n    c\n    d\n    t_{cd}\n    t\n    c\n    d\n    \u200b\n    )\n   </strong>\n   : This is the minimum time before any output begins to change after an input changes.\n  </p>\n </li>\n</ol>\n<p>\n When circuit designers talk about calculating delay, they usually refer to the worst-case scenario, which is the propagation delay, unless stated otherwise.\n</p>\n"}, "Page 89": {"response": "<h3>\n Propagation and Contamination Delay in Buffers\n</h3>\n<p>\n <strong>\n  Figure 2.67\n </strong>\n shows how a buffer's propagation delay (\n t\n p\n d\n t_{pd}\n t\n p\n d\n \u200b\n ) and contamination delay (\n t\n c\n d\n t_{cd}\n t\n c\n d\n \u200b\n ) are represented. When the input\n A\n A\n A\n changes from HIGH to LOW or vice versa, the output\n Y\n Y\n Y\n will respond after a certain time. The blue arcs indicate that\n Y\n Y\n Y\n may start to change after\n t\n c\n d\n t_{cd}\n t\n c\n d\n \u200b\n following the change in\n A\n A\n A\n , and it will definitely reach its new value within\n t\n p\n d\n t_{pd}\n t\n p\n d\n \u200b\n .\n</p>\n<h3>\n Causes of Delay\n</h3>\n<p>\n Delays in circuits are influenced by several factors:\n</p>\n<ul>\n <li>\n  The time needed to charge the circuit\u2019s capacitance.\n </li>\n <li>\n  The speed of light, which affects how quickly signals can travel.\n </li>\n <li>\n  Differences in rising and falling edges of signals.\n </li>\n <li>\n  Variations in delays due to multiple inputs and outputs.\n </li>\n <li>\n  Temperature effects, where circuits may slow down when hot and speed up when cold.\n </li>\n</ul>\n<p>\n Calculating\n t\n p\n d\n t_{pd}\n t\n p\n d\n \u200b\n and\n t\n c\n d\n t_{cd}\n t\n c\n d\n \u200b\n involves a more detailed understanding of circuit design, which is beyond this text. However, manufacturers usually provide data sheets that specify these delays for different gates.\n</p>\n<h3>\n Signal Path and Timing\n</h3>\n<p>\n The delays are also affected by the signal's path from input to output.\n <strong>\n  Figure 2.68\n </strong>\n illustrates a four-input logic circuit. The critical path, shown in blue, is the longest path from inputs\n A\n A\n A\n or\n B\n B\n B\n to output\n Y\n Y\n Y\n . This path is the slowest because it takes the longest time for the signal to travel.\n</p>\n<h3>\n Typical Delay Values\n</h3>\n<p>\n Circuit delays typically range from picoseconds (1 ps =\n 1\n 0\n \u2212\n 12\n 10^{-12}\n 1\n 0\n \u2212\n 12\n seconds) to nanoseconds (1 ns =\n 1\n 0\n \u2212\n 9\n 10^{-9}\n 1\n 0\n \u2212\n 9\n seconds). While reading this explanation, trillions of picoseconds have passed!\n</p>\n"}, "Page 90": {"response": "<h3>\n Critical Path and Short Path in Circuits\n</h3>\n<p>\n In a circuit, the\n <strong>\n  critical path\n </strong>\n is the longest route through multiple gates to the output. This path determines the maximum speed at which the circuit can operate. Conversely, the\n <strong>\n  short path\n </strong>\n , shown in gray, is the quickest route from an input (like\n D\n D\n D\n ) to the output (\n Y\n Y\n Y\n ), as it only goes through one gate.\n</p>\n<h3>\n Delays in Combinational Circuits\n</h3>\n<ul>\n <li>\n  <strong>\n   Propagation Delay (\n   t\n   p\n   d\n   t_{pd}\n   t\n   p\n   d\n   \u200b\n   )\n  </strong>\n  : This is the total time it takes for a signal to travel through all elements on the critical path. It's calculated by adding the propagation delays of each gate on that path.\n </li>\n <li>\n  <strong>\n   Contamination Delay (\n   t\n   c\n   d\n   t_{cd}\n   t\n   c\n   d\n   \u200b\n  </strong>\n  ): This is the earliest time any output can start to change after an input changes, calculated by summing the contamination delays of each gate on the short path.\n </li>\n</ul>\n<h3>\n Example: Calculating Delays\n</h3>\n<p>\n <strong>\n  Example 2.15\n </strong>\n describes Ben Bitdiddle's task of finding both the propagation and contamination delays for a specific circuit. Each gate has a propagation delay of 100 picoseconds (ps) and a contamination delay of 60 ps.\n</p>\n<p>\n <strong>\n  Solution Steps\n </strong>\n :\n</p>\n<ol>\n <li>\n  <strong>\n   Identify the Paths\n  </strong>\n  : Ben first determines the critical path, which is highlighted in blue.\n </li>\n <li>\n  <strong>\n   Calculating Delays\n  </strong>\n  :\n  <ul>\n   <li>\n    <strong>\n     Propagation Delay\n    </strong>\n    :\n    t\n    p\n    d\n    =\n    2\n    \u00d7\n    100\n    ps\u00a0(from\u00a0AND\u00a0gates)\n    +\n    100\n    ps\u00a0(from\u00a0OR\u00a0gate)\n    =\n    300\n    ps\n    t_{pd} = 2 \\times 100 \\, \\text{ps (from AND gates)} + 100 \\, \\text{ps (from OR gate)} = 300 \\, \\text{ps}\n    t\n    p\n    d\n    \u200b\n    =\n    2\n    \u00d7\n    100\n    ps\u00a0(from\u00a0AND\u00a0gates)\n    +\n    100\n    ps\u00a0(from\u00a0OR\u00a0gate)\n    =\n    300\n    ps\n    .\n   </li>\n   <li>\n    <strong>\n     Contamination Delay\n    </strong>\n    :\n    t\n    c\n    d\n    =\n    60\n    ps\u00a0(from\u00a0AND)\n    +\n    60\n    ps\u00a0(from\u00a0OR)\n    =\n    120\n    ps\n    t_{cd} = 60 \\, \\text{ps (from AND)} + 60 \\, \\text{ps (from OR)} = 120 \\, \\text{ps}\n    t\n    c\n    d\n    \u200b\n    =\n    60\n    ps\u00a0(from\u00a0AND)\n    +\n    60\n    ps\u00a0(from\u00a0OR)\n    =\n    120\n    ps\n    .\n   </li>\n  </ul>\n </li>\n</ol>\n<h3>\n Additional Considerations\n</h3>\n<p>\n While this analysis doesn't include wire delays, it's important to note that as digital circuits get faster, the delay from long wires can become as significant as the delay from the gates themselves. More on wire delays is discussed in Appendix A.\n</p>\n"}, "Page 91": {"response": "<h3>\n Delay Calculations in Circuits\n</h3>\n<p>\n For the circuit discussed, the propagation delay (\n t\n p\n d\n t_{pd}\n t\n p\n d\n \u200b\n ) is determined by the longest path, which goes from inputs\n A\n A\n A\n or\n B\n B\n B\n through three gates to the output\n Y\n Y\n Y\n . Since each gate has a propagation delay of 100 picoseconds (ps), the total\n t\n p\n d\n t_{pd}\n t\n p\n d\n \u200b\n is:\n</p>\n<p>\n t\n p\n d\n =\n 3\n \u00d7\n 100\n ps\n =\n 300\n ps\n .\n t_{pd} = 3 \\times 100 \\, \\text{ps} = 300 \\, \\text{ps}.\n t\n p\n d\n \u200b\n =\n 3\n \u00d7\n 100\n ps\n =\n 300\n ps\n .\n</p>\n<p>\n The shortest path, indicated in gray, goes from inputs\n C\n C\n C\n ,\n D\n D\n D\n , or\n E\n E\n E\n through two gates to\n Y\n Y\n Y\n . Therefore, the contamination delay (\n t\n c\n d\n t_{cd}\n t\n c\n d\n \u200b\n ) is:\n</p>\n<p>\n t\n c\n d\n =\n 2\n \u00d7\n 60\n ps\n =\n 120\n ps\n .\n t_{cd} = 2 \\times 60 \\, \\text{ps} = 120 \\, \\text{ps}.\n t\n c\n d\n \u200b\n =\n 2\n \u00d7\n 60\n ps\n =\n 120\n ps\n .\n</p>\n<h3>\n Example: Timing in Multiplexer Designs\n</h3>\n<p>\n <strong>\n  Example 2.16\n </strong>\n compares the worst-case timing of three different four-input multiplexer designs. Each design's critical path and propagation delays are analyzed based on the components used.\n</p>\n<ol>\n <li>\n  <strong>\n   Critical Paths\n  </strong>\n  :\n  <ul>\n   <li>\n    For each design, the critical path is identified, with one path highlighted in blue.\n   </li>\n   <li>\n    t\n    p\n    d\n    s\n    y\n    t_{pd_{sy}}\n    t\n    p\n    d\n    sy\n    \u200b\n    \u200b\n    represents the delay from the select input\n    S\n    S\n    S\n    to the output\n    Y\n    Y\n    Y\n    , while\n    t\n    p\n    d\n    d\n    y\n    t_{pd_{dy}}\n    t\n    p\n    d\n    d\n    y\n    \u200b\n    \u200b\n    represents the delay from the data input\n    D\n    D\n    D\n    to the output\n    Y\n    Y\n    Y\n    . The overall worst-case delay (\n    t\n    p\n    d\n    t_{pd}\n    t\n    p\n    d\n    \u200b\n    ) is the maximum of these two delays:\n   </li>\n  </ul>\n </li>\n</ol>\n<p>\n t\n p\n d\n =\n max\n \u2061\n (\n t\n p\n d\n s\n y\n ,\n t\n p\n d\n d\n y\n )\n .\n t_{pd} = \\max(t_{pd_{sy}}, t_{pd_{dy}}).\n t\n p\n d\n \u200b\n =\n max\n (\n t\n p\n d\n sy\n \u200b\n \u200b\n ,\n t\n p\n d\n d\n y\n \u200b\n \u200b\n )\n .\n</p>\n<ol start=\"2\">\n <li>\n  <strong>\n   Control-Critical vs. Data-Critical\n  </strong>\n  :\n  <ul>\n   <li>\n    In the two-level logic and tristate designs, the critical path is primarily from the control signal\n    S\n    S\n    S\n    to the output\n    Y\n    Y\n    Y\n    . This makes these designs\n    <strong>\n     control-critical\n    </strong>\n    because any extra delay in the control signal will increase the overall delay.\n   </li>\n   <li>\n    For instance, in the tristate implementation, the delay from\n    D\n    D\n    D\n    to\n    Y\n    Y\n    Y\n    is only 50 ps, while the delay from\n    S\n    S\n    S\n    to\n    Y\n    Y\n    Y\n    is 125 ps, emphasizing the importance of the control signal timing in determining performance.\n   </li>\n  </ul>\n </li>\n</ol>\n"}, "Page 92": {"response": "<h3>\n Hierarchical Implementation of a 4:1 Multiplexer\n</h3>\n<p>\n Figure 2.74 shows a hierarchical 4:1 multiplexer made from two stages of 2:1 multiplexers. In this design, the critical path runs from any of the data inputs (\n D\n D\n D\n ) to the output (\n Y\n Y\n Y\n ). This makes the circuit\n <strong>\n  data-critical\n </strong>\n since the delay is determined by the data input reaching the output, represented as:\n</p>\n<p>\n t\n p\n d\n =\n t\n p\n d\n d\n y\n .\n t_{pd} = t_{pd_{dy}}.\n t\n p\n d\n \u200b\n =\n t\n p\n d\n d\n y\n \u200b\n \u200b\n .\n</p>\n<h3>\n Choosing the Right Design\n</h3>\n<p>\n When choosing a design, if the data inputs arrive well before the control inputs, we should prefer the hierarchical design (Figure 2.74) due to its shorter control-to-output delay. Conversely, if the control inputs arrive first, we should opt for the tristate design (Figure 2.73(b)) for its shorter data-to-output delay.\n</p>\n<p>\n The best choice of design not only depends on the critical path and arrival times of inputs but also considers factors like power consumption, cost, and the availability of components.\n</p>\n<h3>\n Glitches in Logic Circuits\n</h3>\n<p>\n Up to this point, we\u2019ve focused on scenarios where a single input change leads to one output change. However, a single input change can sometimes cause multiple output changes, known as\n <strong>\n  glitches\n </strong>\n or\n <strong>\n  hazards\n </strong>\n . While glitches typically don't create significant issues, it's important to recognize them when analyzing timing diagrams.\n</p>\n<p>\n For example, when\n A\n =\n 0\n A = 0\n A\n =\n 0\n ,\n C\n =\n 1\n C = 1\n C\n =\n 1\n , and\n B\n B\n B\n changes from 1 to 0, the timing diagram illustrates how a glitch can occur. The short path (in gray) travels through two gates (an AND gate and an OR gate), while the critical path (in blue) goes through an inverter followed by the AND and OR gates.\n</p>\n<p>\n In the context of digital design, we use the term \"glitches\" for these multiple output transitions to avoid confusion with another definition related to microarchitecture discussed in Chapter 7.\n</p>\n"}, "Page 93": {"response": "<h3>\n Timing Analysis of 4:1 Multiplexers\n</h3>\n<p>\n In the timing analysis of a 4:1 multiplexer, we examine the propagation delays for two designs: two-level logic and a tristate configuration.\n</p>\n<h4>\n Two-Level Logic Design\n</h4>\n<p>\n For the two-level logic multiplexer:\n</p>\n<ul>\n <li>\n  <strong>\n   Critical Path Delay (\n   t\n   p\n   d\n   s\n   y\n   tpd_{sy}\n   tp\n   d\n   sy\n   \u200b\n   )\n  </strong>\n  :\n  <ul>\n   <li>\n    Calculated as:\n    t\n    p\n    d\n    s\n    y\n    =\n    t\n    p\n    d\n    I\n    N\n    V\n    +\n    t\n    p\n    d\n    A\n    N\n    D\n    3\n    +\n    t\n    p\n    d\n    O\n    R\n    4\n    =\n    30\n    ps\n    +\n    80\n    ps\n    +\n    90\n    ps\n    =\n    200\n    ps\n    tpd_{sy} = tpd_{INV} + tpd_{AND3} + tpd_{OR4} = 30 \\text{ ps} + 80 \\text{ ps} + 90 \\text{ ps} = 200 \\text{ ps}\n    tp\n    d\n    sy\n    \u200b\n    =\n    tp\n    d\n    I\n    N\n    V\n    \u200b\n    +\n    tp\n    d\n    A\n    N\n    D\n    3\n    \u200b\n    +\n    tp\n    d\n    OR\n    4\n    \u200b\n    =\n    30\n    ps\n    +\n    80\n    ps\n    +\n    90\n    ps\n    =\n    200\n    ps\n   </li>\n  </ul>\n </li>\n <li>\n  <strong>\n   Data Path Delay (\n   t\n   p\n   d\n   d\n   y\n   tpd_{dy}\n   tp\n   d\n   d\n   y\n   \u200b\n   )\n  </strong>\n  :\n  <ul>\n   <li>\n    Calculated as:\n    t\n    p\n    d\n    d\n    y\n    =\n    t\n    p\n    d\n    A\n    N\n    D\n    3\n    +\n    t\n    p\n    d\n    O\n    R\n    4\n    =\n    170\n    ps\n    tpd_{dy} = tpd_{AND3} + tpd_{OR4} = 170 \\text{ ps}\n    tp\n    d\n    d\n    y\n    \u200b\n    =\n    tp\n    d\n    A\n    N\n    D\n    3\n    \u200b\n    +\n    tp\n    d\n    OR\n    4\n    \u200b\n    =\n    170\n    ps\n   </li>\n  </ul>\n </li>\n</ul>\n<h4>\n Tristate Design\n</h4>\n<p>\n For the tristate multiplexer:\n</p>\n<ul>\n <li>\n  <p>\n   <strong>\n    Critical Path Delay (\n    t\n    p\n    d\n    s\n    y\n    tpd_{sy}\n    tp\n    d\n    sy\n    \u200b\n    )\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Calculated as:\n    t\n    p\n    d\n    s\n    y\n    =\n    t\n    p\n    d\n    I\n    N\n    V\n    +\n    t\n    p\n    d\n    A\n    N\n    D\n    2\n    +\n    t\n    p\n    d\n    T\n    R\n    I\n    S\n    Y\n    =\n    30\n    ps\n    +\n    60\n    ps\n    +\n    35\n    ps\n    =\n    125\n    ps\n    tpd_{sy} = tpd_{INV} + tpd_{AND2} + tpd_{TRI_{SY}} = 30 \\text{ ps} + 60 \\text{ ps} + 35 \\text{ ps} = 125 \\text{ ps}\n    tp\n    d\n    sy\n    \u200b\n    =\n    tp\n    d\n    I\n    N\n    V\n    \u200b\n    +\n    tp\n    d\n    A\n    N\n    D\n    2\n    \u200b\n    +\n    tp\n    d\n    TR\n    I\n    S\n    Y\n    \u200b\n    \u200b\n    =\n    30\n    ps\n    +\n    60\n    ps\n    +\n    35\n    ps\n    =\n    125\n    ps\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Data Path Delay (\n    t\n    p\n    d\n    d\n    y\n    tpd_{dy}\n    tp\n    d\n    d\n    y\n    \u200b\n    )\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Calculated as:\n    t\n    p\n    d\n    d\n    y\n    =\n    t\n    p\n    d\n    T\n    R\n    I\n    A\n    Y\n    =\n    50\n    ps\n    tpd_{dy} = tpd_{TRI_{AY}} = 50 \\text{ ps}\n    tp\n    d\n    d\n    y\n    \u200b\n    =\n    tp\n    d\n    TR\n    I\n    A\n    Y\n    \u200b\n    \u200b\n    =\n    50\n    ps\n   </li>\n  </ul>\n </li>\n</ul>\n<h4>\n Glitches in Output\n</h4>\n<p>\n As\n B\n B\n B\n transitions from 1 to 0, a glitch can occur. The timing diagram shows that while\n n\n 2\n n2\n n\n 2\n (on the short path) falls before\n n\n 1\n n1\n n\n 1\n (on the critical path) can rise, both inputs to the OR gate are temporarily 0. This causes the output\n Y\n Y\n Y\n to drop to 0 momentarily. Eventually, when\n n\n 1\n n1\n n\n 1\n rises,\n Y\n Y\n Y\n returns to 1.\n</p>\n<p>\n The output\n Y\n Y\n Y\n starts and ends at 1 but briefly glitches to 0 during the transition. This behavior illustrates how glitches can occur even when the final state is correct.\n</p>\n<h3>\n Summary of Circuit Behavior\n</h3>\n<p>\n In the example circuit:\n</p>\n<ul>\n <li>\n  The relationship is defined by:\n  Y\n  =\n  A\n  B\n  +\n  B\n  C\n  Y = AB + BC\n  Y\n  =\n  A\n  B\n  +\n  BC\n </li>\n <li>\n  The truth table indicates the output behavior based on the combinations of inputs\n  A\n  A\n  A\n  ,\n  B\n  B\n  B\n  , and\n  C\n  C\n  C\n  .\n </li>\n</ul>\n<p>\n This detailed timing analysis is crucial for understanding how circuits respond during transitions and for designi\n</p>\n"}, "Page 94": {"response": "<h3>\n Understanding Glitches in Digital Circuits\n</h3>\n<p>\n When a circuit experiences an input change, it can lead to glitches, which are brief incorrect outputs before the system stabilizes. As long as we wait for the propagation delay to pass, glitches generally aren't a problem, since the output will eventually correct itself.\n</p>\n<h4>\n Managing Glitches with K-Maps\n</h4>\n<p>\n To understand and avoid glitches, we can use a Karnaugh map (K-map). For example, consider the input transition for\n B\n B\n B\n changing from\n A\n B\n C\n =\n 001\n ABC = 001\n A\n BC\n =\n 001\n to\n A\n B\n C\n =\n 011\n ABC = 011\n A\n BC\n =\n 011\n . This change crosses the boundary between two prime implicant circles in the K-map, signaling a potential glitch.\n</p>\n<p>\n When the circuitry for one prime implicant turns off before the circuitry for the other prime implicant can turn on, it creates a glitch. To resolve this, we can add another term to our circuit design that covers the boundary of the prime implicants, as illustrated in the K-map.\n</p>\n<p>\n This added term is known as the consensus term or redundant term, and it helps prevent glitches by ensuring that the circuit remains stable during transitions between different states.\n</p>\n<h3>\n Summary\n</h3>\n<ul>\n <li>\n  <strong>\n   Glitches\n  </strong>\n  occur during transitions when the output temporarily becomes incorrect but eventually stabilizes.\n </li>\n <li>\n  To avoid glitches, we can use K-maps to visualize input changes and implement additional terms (consensus terms) that cover transition boundaries between prime impli\n </li>\n</ul>\n"}, "Page 95": {"response": "<h3>\n Summary of Glitches in Digital Circuits\n</h3>\n<p>\n In the updated circuit shown in Figure 2.79, a new AND gate (highlighted in blue) prevents glitches. This means that when the input\n B\n B\n B\n changes while\n A\n =\n 0\n A = 0\n A\n =\n 0\n and\n C\n =\n 1\n C = 1\n C\n =\n 1\n , the output remains stable. The added gate keeps the output at 1 during the transition, avoiding any momentary errors.\n</p>\n<h4>\n Understanding Glitches\n</h4>\n<ol>\n <li>\n  <p>\n   <strong>\n    Cause of Glitches\n   </strong>\n   : Glitches can occur when a single input change crosses the boundary between two prime implicants in a K-map. To eliminate these glitches, we can add redundant terms in the K-map, which requires extra hardware.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Simultaneous Transitions\n   </strong>\n   : Glitches can also arise from multiple inputs changing at the same time. Unfortunately, adding hardware won't fix these kinds of glitches.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Reality of Glitches\n   </strong>\n   : Many systems deal with simultaneous transitions, making glitches a common occurrence in circuits. While we can mitigate some glitches with design changes, it's crucial to recognize their presence, especially when analyzing timing diagrams with simulators or oscilloscopes.\n  </p>\n </li>\n</ol>\n<h3>\n Chapter Overview\n</h3>\n<p>\n This chapter focused on\n <strong>\n  digital circuits\n </strong>\n , particularly\n <strong>\n  combinational circuits\n </strong>\n , which have outputs that rely solely on current input values. Each digital circuit has defined inputs, outputs, and a specification outlining its function and timing.\n</p>\n"}, "Page 96": {"response": "<h3>\n Overview of Combinational Circuits\n</h3>\n<p>\n <strong>\n  Function Representation\n </strong>\n : A combinational circuit's function can be described using a truth table or a Boolean equation. You can derive a Boolean equation from a truth table using two main forms: sum-of-products (SOP) and product-of-sums (POS).\n</p>\n<ul>\n <li>\n  <strong>\n   Sum-of-Products (SOP)\n  </strong>\n  : In this form, the function is expressed as the sum (OR) of one or more implicants. An implicant is a product (AND) of literals, where literals are the true or inverted (complementary) forms of the input variables.\n </li>\n</ul>\n<p>\n <strong>\n  Simplification\n </strong>\n : Boolean equations can be simplified using Boolean algebra rules. You can achieve a minimal sum-of-products form by merging implicants that differ only in one literal's true or complementary form.\n</p>\n<ul>\n <li>\n  <strong>\n   Karnaugh Maps\n  </strong>\n  : These are visual tools that help simplify functions of up to four variables. With practice, designers can often simplify functions just by looking at them. For more complex functions, computer-aided design (CAD) tools are recommended, which will be covered in Chapter 4.\n </li>\n</ul>\n<h3>\n Building Combinational Circuits\n</h3>\n<p>\n <strong>\n  Logic Gates\n </strong>\n : Combinational circuits are created by connecting logic gates to perform the desired function. Any function in SOP form can be constructed using two-level logic:\n</p>\n<ul>\n <li>\n  <strong>\n   NOT Gates\n  </strong>\n  create complementary literals.\n </li>\n <li>\n  <strong>\n   AND Gates\n  </strong>\n  form the products.\n </li>\n <li>\n  <strong>\n   OR Gates\n  </strong>\n  combine the products into a sum.\n </li>\n</ul>\n<p>\n Depending on the specific function and available components, multilevel logic using various gate types can be more efficient. For instance, CMOS technology often uses NAND and NOR gates since they can be built directly from CMOS transistors without needing additional NOT gates.\n</p>\n<p>\n <strong>\n  Bubble Pushing\n </strong>\n : This technique helps manage inversions when using NAND and NOR gates.\n</p>\n<h3>\n Examples of Combinational Circuits\n</h3>\n<p>\n Common combinational building blocks include:\n</p>\n<ul>\n <li>\n  <strong>\n   Multiplexers\n  </strong>\n  : Select one data input based on the control signal.\n </li>\n <li>\n  <strong>\n   Decoders\n  </strong>\n  : Activate one output line according to the input.\n </li>\n <li>\n  <strong>\n   Priority Circuits\n  </strong>\n  : Indicate the highest priority input.\n </li>\n</ul>\n<p>\n Chapter 5 will introduce more building blocks, including arithmetic circuits, which are essential for constructing a microprocessor discussed in Chapter 7.\n</p>\n<h3>\n Timing Specifications\n</h3>\n<p>\n A combinational circuit's timing is defined by:\n</p>\n<ul>\n <li>\n  <strong>\n   Propagation Delay\n  </strong>\n  : The maximum time taken for an output to change after an input change.\n </li>\n <li>\n  <strong>\n   Contamination Delay\n  </strong>\n  : The minimum time before any output starts to change after an input change.\n </li>\n</ul>\n<p>\n To calculate the propagation delay, identify the critical path through the circuit and sum the propagation delays of each element along that path. There are various methods to implement complex combinational circuits, each offering trade-offs between speed and cost.\n</p>\n<h3>\n Next Steps\n</h3>\n<p>\n The following chapter will focus on\n <strong>\n  sequential circuits\n </strong>\n , where outputs depend on both current and previous input values, meaning these circuits have memory of past states.\n</p>\n"}, "Page 97": {"response": "<h3>\n Exercises Overview\n</h3>\n<p>\n <strong>\n  Exercise 2.1\n </strong>\n : Create a Boolean equation in sum-of-products (SOP) canonical form for each truth table shown in Figure 2.80.\n</p>\n<p>\n <strong>\n  Exercise 2.2\n </strong>\n : Develop a Boolean equation in product-of-sums (POS) canonical form for the same truth tables in Figure 2.80.\n</p>\n<p>\n <strong>\n  Exercise 2.3\n </strong>\n : Minimize each Boolean equation you wrote in Exercise 2.1.\n</p>\n<p>\n <strong>\n  Exercise 2.4\n </strong>\n : Draw a simple combinational circuit for each function from Exercise 2.3. Aim for efficiency, using a reasonable number of gates without excessive trial and error.\n</p>\n<p>\n <strong>\n  Exercise 2.5\n </strong>\n : Redo Exercise 2.4 but only using NOT, AND, and OR gates.\n</p>\n<p>\n <strong>\n  Exercise 2.6\n </strong>\n : Repeat Exercise 2.4 again, but this time use only NOT, NAND, and NOR gates.\n</p>\n<p>\n <strong>\n  Exercise 2.7\n </strong>\n : Simplify the following Boolean equations using Boolean theorems. Verify your work with a truth table or a Karnaugh map.\n</p>\n<ol>\n <li>\n  Y\n  =\n  A\n  B\n  C\n  D\n  +\n  A\n  B\n  C\n  +\n  A\n  B\n  D\n  +\n  A\n  B\n  C\n  D\n  +\n  A\n  B\n  C\n  +\n  A\n  Y = A B C D + A B C + A B D + A B C D + A B C + A\n  Y\n  =\n  A\n  BC\n  D\n  +\n  A\n  BC\n  +\n  A\n  B\n  D\n  +\n  A\n  BC\n  D\n  +\n  A\n  BC\n  +\n  A\n </li>\n <li>\n  Y\n  =\n  A\n  B\n  +\n  A\n  B\n  C\n  +\n  (\n  A\n  +\n  C\n  )\n  Y = A B + A B C + (A + C)\n  Y\n  =\n  A\n  B\n  +\n  A\n  BC\n  +\n  (\n  A\n  +\n  C\n  )\n </li>\n <li>\n  Y\n  =\n  A\n  C\n  +\n  A\n  B\n  C\n  Y = A C + A B C\n  Y\n  =\n  A\n  C\n  +\n  A\n  BC\n </li>\n</ol>\n<p>\n Each equation should be simplified, and you should check the results for correctness.\n</p>\n<h3>\n Additional Context\n</h3>\n<p>\n Truth tables in Figure 2.80 will provide the necessary data to complete these exercises. Focus on understanding the logic behind each transformation and simplification process as you work\n</p>\n"}, "Page 98": {"response": "<h3>\n Exercises Overview\n</h3>\n<p>\n <strong>\n  Exercise 2.8\n </strong>\n : Draw a simple combinational circuit for each function derived from Exercise 2.7.\n</p>\n<p>\n <strong>\n  Exercise 2.9\n </strong>\n : Simplify each of the following Boolean equations and then sketch a simple combinational circuit for the simplified version:\n</p>\n<ol>\n <li>\n  Y\n  =\n  A\n  B\n  C\n  +\n  A\n  B\n  D\n  +\n  A\n  B\n  E\n  +\n  A\n  C\n  D\n  +\n  A\n  C\n  E\n  Y = ABC + ABD + ABE + ACD + ACE\n  Y\n  =\n  A\n  BC\n  +\n  A\n  B\n  D\n  +\n  A\n  BE\n  +\n  A\n  C\n  D\n  +\n  A\n  CE\n </li>\n</ol>\n<p>\n <strong>\n  Exercise 2.10\n </strong>\n : Create a truth table that has between 3 billion and 5 billion rows, which can be constructed using fewer than 40 two-input gates (but at least 1).\n</p>\n<p>\n <strong>\n  Exercise 2.11\n </strong>\n : Provide an example of a circuit that has a cyclic path but is still a combinational circuit.\n</p>\n<p>\n <strong>\n  Exercise 2.12\n </strong>\n : Discuss Alyssa P. Hacker's claim that any Boolean function can be expressed in minimal sum-of-products form as the sum of all its prime implicants. Ben Bitdiddle disagrees, saying some functions' minimal equations don\u2019t include all prime implicants. Explain who is correct or give a counterexample.\n</p>\n<p>\n <strong>\n  Exercise 2.13\n </strong>\n : Prove the following theorems using perfect induction (you don\u2019t need to prove their duals):\n</p>\n<ol>\n <li>\n  The idempotency theorem (T3)\n </li>\n <li>\n  The distributivity theorem (T8)\n </li>\n <li>\n  The combining theorem (T10)\n </li>\n</ol>\n<p>\n <strong>\n  Exercise 2.14\n </strong>\n : Prove De Morgan\u2019s Theorem (T12) for three variables\n B\n 2\n ,\n B\n 1\n ,\n B\n 0\n B_2, B_1, B_0\n B\n 2\n \u200b\n ,\n B\n 1\n \u200b\n ,\n B\n 0\n \u200b\n using perfect induction.\n</p>\n<p>\n <strong>\n  Exercise 2.15\n </strong>\n : Write Boolean equations for the circuit shown in Figure 2.81. You don\u2019t need to minimize these equations.\n</p>\n<h3>\n Additional Context\n</h3>\n<p>\n These exercises cover a variety of topics, including circuit design, truth table creation, theorems in Boolean algebra, and proof techniques. Focus on applying the concepts learned in previous sections while completing these tasks.\n</p>\n"}, "Page 99": {"response": "<h3>\n Exercises Overview\n</h3>\n<p>\n <strong>\n  Exercise 2.16\n </strong>\n : Simplify the Boolean equations from Exercise 2.15 and draw a more efficient circuit that performs the same function.\n</p>\n<p>\n <strong>\n  Exercise 2.17\n </strong>\n : Use De Morgan's theorem and bubble pushing techniques to redraw the circuit shown in Figure 2.82. This will help you derive the Boolean equation more easily. Write out the resulting Boolean equation.\n</p>\n<p>\n <strong>\n  Exercise 2.18\n </strong>\n : Do the same as Exercise 2.17, but for the circuit in Figure 2.83.\n</p>\n<h3>\n Additional Context\n</h3>\n<p>\n These exercises focus on minimizing Boolean equations, circuit optimization, and using visual methods to simplify circuit analysis. Aim to apply the techniques learned in earlier sections to complete these tasks effectively.\n</p>\n"}, "Page 100": {"response": "<h3>\n Exercises Overview\n</h3>\n<p>\n <strong>\n  Exercise 2.19\n </strong>\n : Create the simplest Boolean equation for the function shown in Figure 2.84, using the don\u2019t care entries to your advantage.\n</p>\n<p>\n <strong>\n  Exercise 2.20\n </strong>\n : Draw a circuit that represents the function from Exercise 2.19.\n</p>\n<p>\n <strong>\n  Exercise 2.21\n </strong>\n : Check if the circuit from Exercise 2.20 could have glitches when one of the inputs changes. If it does not, explain why. If it does, show how to modify the circuit to remove the glitches.\n</p>\n<p>\n <strong>\n  Exercise 2.22\n </strong>\n : Write a Boolean equation for Ben Bitdiddle's enjoyment (E) at his picnic based on the conditions: he enjoys it on sunny days (S) without ants (A), on any day he sees a hummingbird (H), or on days when there are both ants (A) and ladybugs (L).\n</p>\n<h3>\n Key Concepts\n</h3>\n<ul>\n <li>\n  <strong>\n   Don\u2019t Care Entries\n  </strong>\n  : Use these to simplify the Boolean expression effectively.\n </li>\n <li>\n  <strong>\n   Circuit Design\n  </strong>\n  : Visual representation of the Boolean function to facilitate understanding.\n </li>\n <li>\n  <strong>\n   Glitches\n  </strong>\n  : Analyze the circuit for potential issues that may arise with input changes and propose solutions.\n </li>\n <li>\n  <strong>\n   Boolean Equations\n  </strong>\n  : Formulate logical conditions based on specific scenarios.\n </li>\n</ul>\n"}, "Page 101": {"response": "<h3>\n Exercises Overview\n</h3>\n<p>\n <strong>\n  Exercise 2.23\n </strong>\n : Design a seven-segment decoder for segments Sc to Sg.\n</p>\n<ul>\n <li>\n  <strong>\n   (a)\n  </strong>\n  : Create Boolean equations for Sc to Sg, assuming inputs greater than 9 result in blank (0) outputs.\n </li>\n <li>\n  <strong>\n   (b)\n  </strong>\n  : Create Boolean equations for Sc to Sg, assuming inputs greater than 9 are treated as don\u2019t cares.\n </li>\n <li>\n  <strong>\n   (c)\n  </strong>\n  : Draw a simple gate-level circuit for part (b), sharing gates for multiple outputs when possible.\n </li>\n</ul>\n<p>\n <strong>\n  Exercise 2.24\n </strong>\n : Design a circuit with four inputs (A3:0) representing numbers from 0 to 15.\n</p>\n<ul>\n <li>\n  Output P should be TRUE for prime numbers (excluding 0 and 1).\n </li>\n <li>\n  Output D should be TRUE if the number is divisible by 3. Provide simplified Boolean equations and a circuit diagram for both outputs.\n </li>\n</ul>\n<p>\n <strong>\n  Exercise 2.25\n </strong>\n : Create an eight-input priority encoder with inputs A7:0 and outputs Y2:0 and NONE.\n</p>\n<ul>\n <li>\n  The encoder outputs Y2:0 to indicate the most significant TRUE input, or 0 if none are TRUE.\n </li>\n <li>\n  The NONE output should be TRUE if no inputs are TRUE. Provide simplified Boolean equations and a schematic diagram.\n </li>\n</ul>\n<p>\n <strong>\n  Exercise 2.26\n </strong>\n : Design a modified priority encoder with inputs A7:0 that produces two 3-bit outputs: Y and Z.\n</p>\n<ul>\n <li>\n  Y indicates the most significant TRUE input; Z indicates the second most significant.\n </li>\n <li>\n  If no inputs are TRUE, Y should be 0; if only one input is TRUE, Z should be 0. Provide simplified Boolean equations and a schematic.\n </li>\n</ul>\n<p>\n <strong>\n  Exercise 2.27\n </strong>\n : Design a 3:7 binary-to-thermometer code converter.\n</p>\n<ul>\n <li>\n  The output should have k 1\u2019s followed by M-k 0\u2019s. For example, for input 110, the output should be 0111111. Provide simplified Boolean equations and a schematic.\n </li>\n</ul>\n<p>\n <strong>\n  Exercise 2.28\n </strong>\n : Write a minimized Boolean equation for the function performed by the circuit shown in Figure 2.85.\n</p>\n"}, "Page 102": {"response": "<h3>\n Exercises Overview\n</h3>\n<p>\n <strong>\n  Exercise 2.30\n </strong>\n : Implement the function from Figure 2.80(b) using different multiplexers.\n</p>\n<ul>\n <li>\n  <strong>\n   (a)\n  </strong>\n  : Use an 8:1 multiplexer.\n </li>\n <li>\n  <strong>\n   (b)\n  </strong>\n  : Use a 4:1 multiplexer along with one inverter.\n </li>\n <li>\n  <strong>\n   (c)\n  </strong>\n  : Use a 2:1 multiplexer and two additional logic gates.\n </li>\n</ul>\n<p>\n <strong>\n  Exercise 2.31\n </strong>\n : Implement the function from Exercise 2.9(a) using various configurations.\n</p>\n<ul>\n <li>\n  <strong>\n   (a)\n  </strong>\n  : Use an 8:1 multiplexer.\n </li>\n <li>\n  <strong>\n   (b)\n  </strong>\n  : Use a 4:1 multiplexer with no additional gates.\n </li>\n <li>\n  <strong>\n   (c)\n  </strong>\n  : Use a 2:1 multiplexer, one OR gate, and one inverter.\n </li>\n</ul>\n<p>\n <strong>\n  Exercise 2.32\n </strong>\n : Calculate the propagation delay and contamination delay for the circuit in Figure 2.83, using the gate delay values provided in Table 2.8.\n</p>\n<p>\n <strong>\n  Exercise 2.29\n </strong>\n : Write a minimized Boolean equation for the function performed by the circuit in Figure 2.86.\n</p>\n"}, "Page 103": {"response": "<h3>\n Exercises Overview\n</h3>\n<p>\n <strong>\n  Exercise 2.33\n </strong>\n : Create a schematic for a fast 3:8 decoder using gates listed in Table 2.8. Design it for the shortest possible critical path and specify what that path is. Also, calculate the propagation delay and contamination delay.\n</p>\n<p>\n <strong>\n  Exercise 2.34\n </strong>\n : Redesign the circuit from Exercise 2.24 to maximize speed, using only the gates from Table 2.8. Provide a sketch of the new circuit and indicate the critical path. Determine its propagation delay and contamination delay.\n</p>\n<p>\n <strong>\n  Exercise 2.35\n </strong>\n : Redesign the priority encoder from Exercise 2.25 to optimize for speed, utilizing any gates from Table 2.8. Sketch the new circuit and identify the critical path. Calculate the propagation delay and contamination delay.\n</p>\n<p>\n <strong>\n  Exercise 2.36\n </strong>\n : Design an 8:1 multiplexer that minimizes delay from data inputs to output. Use any gates from Table 2.7 on page 88. Provide a schematic and calculate the resulting delay using the gate delays from the table.\n</p>\n<h3>\n Gate Delays (for reference)\n</h3>\n<ul>\n <li>\n  <strong>\n   NOT\n  </strong>\n  : tpd 15 ps, tcd 10 ps\n </li>\n <li>\n  <strong>\n   2-input NAND\n  </strong>\n  : tpd 20 ps, tcd 15 ps\n </li>\n <li>\n  <strong>\n   3-input NAND\n  </strong>\n  : tpd 30 ps, tcd 25 ps\n </li>\n <li>\n  <strong>\n   2-input NOR\n  </strong>\n  : tpd 30 ps, tcd 25 ps\n </li>\n <li>\n  <strong>\n   3-input NOR\n  </strong>\n  : tpd 45 ps, tcd 35 ps\n </li>\n <li>\n  <strong>\n   2-input AND\n  </strong>\n  : tpd 30 ps, tcd 25 ps\n </li>\n <li>\n  <strong>\n   3-input AND\n  </strong>\n  : tpd 40 ps, tcd 30 ps\n </li>\n <li>\n  <strong>\n   2-input OR\n  </strong>\n  : tpd 40 ps, tcd 30 ps\n </li>\n <li>\n  <strong>\n   3-input OR\n  </strong>\n  : tpd 55 ps, tcd 45 ps\n </li>\n <li>\n  <strong>\n   2-input XOR\n  </strong>\n  : tpd 60 ps, tcd 40 ps\n </li>\n</ul>\n"}, "Page 104": {"response": "<h3>\n Interview Questions Overview\n</h3>\n<p>\n <strong>\n  Question 2.1\n </strong>\n : Draw a schematic for a two-input XOR gate using only NAND gates. Determine the minimum number of NAND gates needed for this design.\n</p>\n<p>\n <strong>\n  Question 2.2\n </strong>\n : Create a circuit that checks if a month (represented by a 4-bit input, A3:0) has 31 days. For instance, input\n <code>\n  0001\n </code>\n represents January, and\n <code>\n  1100\n </code>\n represents December. The output, Y, should be HIGH only for months that have 31 days. Write a simplified Boolean equation for this circuit and sketch the circuit diagram using the fewest gates possible. (Tip: Use don't care conditions to simplify.)\n</p>\n<p>\n <strong>\n  Question 2.3\n </strong>\n : What is a tristate buffer? Explain how it works and why it is used in circuits.\n</p>\n<p>\n <strong>\n  Question 2.4\n </strong>\n : A gate or group of gates is considered universal if it can construct any Boolean function. For instance, the combination of AND, OR, and NOT gates is universal.\n</p>\n<ul>\n <li>\n  (a) Is a single AND gate universal? Explain your answer.\n </li>\n <li>\n  (b) Is the combination of OR and NOT gates universal? Justify your response.\n </li>\n <li>\n  (c) Is a single NAND gate universal? Provide reasoning.\n </li>\n</ul>\n<p>\n <strong>\n  Question 2.5\n </strong>\n : Why might a circuit\u2019s contamination delay be shorter than its propagation delay?\n</p>\n"}, "Page 105": {"response": "<h3>\n Sequential Logic Design Overview\n</h3>\n<p>\n <strong>\n  3.1 Introduction\n </strong>\n <br/>\n In the previous chapter, we focused on combinational logic, where the output relies solely on current input values. We learned to create optimized circuits based on specifications like truth tables or Boolean equations. In this chapter, we will explore sequential logic, where outputs depend on both current and past input values, giving these circuits a memory function.\n</p>\n<p>\n Sequential logic can remember previous inputs directly or summarize them into a smaller set of information known as the system's state. The state of a digital sequential circuit consists of bits called state variables, which store all past information needed to predict future behavior.\n</p>\n<p>\n We'll begin with latches and flip-flops, the basic components that store a single bit of state. Since sequential circuits can be complex, we will focus on synchronous sequential circuits, which combine combinational logic with flip-flops that hold the circuit's state. We will also cover finite state machines (FSMs) as a structured approach to designing sequential circuits. Finally, we\u2019ll discuss the speed of these circuits and the role of parallelism in enhancing clock speeds.\n</p>\n<p>\n <strong>\n  3.2 Latches and Flip-Flops\n </strong>\n <br/>\n The core component of memory is the bistable element, which has two stable states. For example, a simple bistable element consists of a pair of inverters arranged in a loop. This setup, when drawn with emphasis on its symmetry, shows that the output of one inverter feeds into the input of the other. While this circuit does not have external inputs, it generates\n</p>\n"}, "Page 106": {"response": "<h3>\n Bistable Circuit Analysis\n</h3>\n<p>\n In this section, we analyze a bistable circuit, which differs from combinational circuits because it is cyclic. Here, the output\n Q\n Q\n Q\n depends on another output\n Q\n \u203e\n \\overline{Q}\n Q\n \u200b\n , and vice versa.\n</p>\n<p>\n <strong>\n  Case Analysis of the Bistable Circuit:\n </strong>\n</p>\n<ol>\n <li>\n  <p>\n   <strong>\n    Case I:\n    Q\n    =\n    0\n    Q = 0\n    Q\n    =\n    0\n   </strong>\n  </p>\n  <ul>\n   <li>\n    In this scenario (see Figure 3.2(a)), the input\n    I\n    2\n    I_2\n    I\n    2\n    \u200b\n    receives a FALSE signal (from\n    Q\n    Q\n    Q\n    ), producing a TRUE output at\n    Q\n    \u203e\n    \\overline{Q}\n    Q\n    \u200b\n    .\n   </li>\n   <li>\n    The input\n    I\n    1\n    I_1\n    I\n    1\n    \u200b\n    , on the other hand, gets a TRUE signal from\n    Q\n    \u203e\n    \\overline{Q}\n    Q\n    \u200b\n    , resulting in a FALSE output at\n    Q\n    Q\n    Q\n    .\n   </li>\n   <li>\n    This is consistent with our assumption that\n    Q\n    =\n    0\n    Q = 0\n    Q\n    =\n    0\n    , confirming that this state is stable.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Case II:\n    Q\n    =\n    1\n    Q = 1\n    Q\n    =\n    1\n   </strong>\n  </p>\n  <ul>\n   <li>\n    Here (see Figure 3.2(b)),\n    I\n    2\n    I_2\n    I\n    2\n    \u200b\n    receives a TRUE input, leading to a FALSE output at\n    Q\n    \u203e\n    \\overline{Q}\n    Q\n    \u200b\n    .\n   </li>\n   <li>\n    Consequently,\n    I\n    1\n    I_1\n    I\n    1\n    \u200b\n    receives a FALSE input, which results in a TRUE output at\n    Q\n    Q\n    Q\n    .\n   </li>\n   <li>\n    This is also stable, affirming that both states\u2014\n    Q\n    =\n    0\n    Q = 0\n    Q\n    =\n    0\n    and\n    Q\n    =\n    1\n    Q = 1\n    Q\n    =\n    1\n    \u2014are stable conditions for the circuit.\n   </li>\n  </ul>\n </li>\n</ol>\n<h3>\n Characteristics of Bistable Circuits\n</h3>\n<ul>\n <li>\n  The cross-coupled inverters in this circuit create two stable states:\n  Q\n  =\n  0\n  Q = 0\n  Q\n  =\n  0\n  and\n  Q\n  =\n  1\n  Q = 1\n  Q\n  =\n  1\n  . This means the circuit is\n  <strong>\n   bistable\n  </strong>\n  , capable of storing one bit of information.\n </li>\n <li>\n  There is a third state known as the\n  <strong>\n   metastable state\n  </strong>\n  , where both outputs are approximately halfway between 0 and 1. This state can lead to uncertainty and will be discussed in more detail later.\n </li>\n</ul>\n<p>\n An element with\n N\n N\n N\n stable states can convey\n log\n \u2061\n 2\n N\n \\log_2 N\n lo\n g\n 2\n \u200b\n N\n bits of information. Since our bistable circuit has two stable states, it stores one bit of information. The state variable\n Q\n Q\n Q\n encapsulates all the necessary historical information about the circuit\u2019s past to predict its future behavior.\n</p>\n<ul>\n <li>\n  If\n  Q\n  =\n  0\n  Q = 0\n  Q\n  =\n  0\n  , it will remain 0 indefinitely; if\n  Q\n  =\n  1\n  Q = 1\n  Q\n  =\n  1\n  , it will stay 1 forever.\n </li>\n <li>\n  While\n  Q\n  \u203e\n  \\overline{Q}\n  Q\n  \u200b\n  is another node in the circuit, it does not provide any additional information because knowing\n  Q\n  Q\n  Q\n  also gives you\n  Q\n  \u203e\n  \\overline{Q}\n  Q\n  \u200b\n  . However,\n  Q\n  \u203e\n  \\overline{Q}\n  Q\n  \u200b\n  can also serve as a valid state variable.\n </li>\n</ul>\n<p>\n Commonly,\n Q\n Q\n Q\n represents the output of sequential logic circuits, si\n</p>\n"}, "Page 107": {"response": "<h3>\n Initial State of Sequential Circuits\n</h3>\n<p>\n When you first power up a sequential circuit, its starting state is often unpredictable and can vary each time the circuit is turned on. Although the cross-coupled inverters can hold a bit of information, they aren't practical for real use because there's no way for the user to control their state. Instead, other bistable elements like latches and flip-flops offer inputs that allow users to control the state variable. This section will focus on these circuits.\n</p>\n<h3>\n 3.2.1 SR Latch\n</h3>\n<p>\n One of the simplest sequential circuits is the\n <strong>\n  SR latch\n </strong>\n , made up of two cross-coupled NOR gates, as shown in Figure 3.3. The SR latch has two inputs,\n <strong>\n  S\n </strong>\n (set) and\n <strong>\n  R\n </strong>\n (reset), and two outputs,\n <strong>\n  Q\n </strong>\n and\n Q\n \u203e\n \\overline{Q}\n Q\n \u200b\n . Unlike the cross-coupled inverters, the SR latch allows control over its state through the S and R inputs.\n</p>\n<p>\n To understand how the SR latch works, we can create its truth table by examining the four possible input combinations of R and S.\n</p>\n<h4>\n Case Analysis for the SR Latch:\n</h4>\n<ol>\n <li>\n  <p>\n   <strong>\n    Case I:\n    R\n    =\n    1\n    ,\n    S\n    =\n    0\n    R = 1, S = 0\n    R\n    =\n    1\n    ,\n    S\n    =\n    0\n   </strong>\n  </p>\n  <ul>\n   <li>\n    The first NOR gate (N1) sees a TRUE input from R, so it produces a FALSE output on Q.\n   </li>\n   <li>\n    The second NOR gate (N2) sees both\n    Q\n    \u203e\n    \\overline{Q}\n    Q\n    \u200b\n    and S as FALSE, resulting in a TRUE output on\n    Q\n    \u203e\n    \\overline{Q}\n    Q\n    \u200b\n    .\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Case II:\n    R\n    =\n    0\n    ,\n    S\n    =\n    1\n    R = 0, S = 1\n    R\n    =\n    0\n    ,\n    S\n    =\n    1\n   </strong>\n  </p>\n  <ul>\n   <li>\n    N1 receives a FALSE input and\n    Q\n    \u203e\n    \\overline{Q}\n    Q\n    \u200b\n    . Since we don\u2019t know\n    Q\n    \u203e\n    \\overline{Q}\n    Q\n    \u200b\n    yet, we can\u2019t determine Q.\n   </li>\n   <li>\n    N2 has a TRUE input from S, leading to a FALSE output on\n    Q\n    \u203e\n    \\overline{Q}\n    Q\n    \u200b\n    .\n   </li>\n   <li>\n    Knowing that both inputs to N1 are now FALSE, we can conclude that Q must be TRUE.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Case III:\n    R\n    =\n    1\n    ,\n    S\n    =\n    1\n    R = 1, S = 1\n    R\n    =\n    1\n    ,\n    S\n    =\n    1\n   </strong>\n  </p>\n  <ul>\n   <li>\n    Both N1 and N2 see at least one TRUE input (either R or S), resulting in FALSE outputs for both Q and\n    Q\n    \u203e\n    \\overline{Q}\n    Q\n    \u200b\n    .\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Case IV:\n    R\n    =\n    0\n    ,\n    S\n    =\n    0\n    R = 0, S = 0\n    R\n    =\n    0\n    ,\n    S\n    =\n    0\n   </strong>\n  </p>\n  <ul>\n   <li>\n    N1 has inputs of 0 and\n    Q\n    \u203e\n    \\overline{Q}\n    Q\n    \u200b\n    , making it impossible to determine Q at this point.\n   </li>\n   <li>\n    N2 also has inputs of 0 and Q, so we can't conclude anything about\n    Q\n    \u203e\n    \\overline{Q}\n    Q\n    \u200b\n    either. This scenario leaves us in a state of uncertainty, similar to the cross-coupled inverters.\n   </li>\n   <li>\n    However, we know Q must be either 0 or 1, so we can explore what happens in each subcase.\n   </li>\n  </ul>\n </li>\n</ol>\n<h3>\n Conclusion\n</h3>\n<p>\n The SR latch serves as a fundamental building block in sequential logic design, allowing for controlled memory storage.\n</p>\n"}, "Page 108": {"response": "<h3>\n Case IV Analysis for the SR Latch\n</h3>\n<p>\n <strong>\n  Case IVa:\n  Q\n  =\n  0\n  Q = 0\n  Q\n  =\n  0\n </strong>\n <br/>\n When\n S\n S\n S\n and\n Q\n Q\n Q\n are both FALSE, the second NOR gate (N2) produces a TRUE output on\n Q\n \u203e\n \\overline{Q}\n Q\n \u200b\n . Now, N1 receives this TRUE input, causing its output\n Q\n Q\n Q\n to remain FALSE, which matches our assumption.\n</p>\n<p>\n <strong>\n  Case IVb:\n  Q\n  =\n  1\n  Q = 1\n  Q\n  =\n  1\n </strong>\n <br/>\n If\n Q\n Q\n Q\n is TRUE, N2 outputs FALSE on\n Q\n \u203e\n \\overline{Q}\n Q\n \u200b\n . N1 then receives two FALSE inputs (from\n R\n R\n R\n and\n Q\n \u203e\n \\overline{Q}\n Q\n \u200b\n ), leading it to output TRUE on\n Q\n Q\n Q\n , confirming our assumption.\n</p>\n<h3>\n Memory Function of the SR Latch\n</h3>\n<p>\n When entering Case IV, if\n Q\n Q\n Q\n has a known previous value (let's call it\n Q\n prev\n Q_{\\text{prev}}\n Q\n prev\n \u200b\n ), it can either be 0 or 1, reflecting the circuit's state. If both\n R\n R\n R\n and\n S\n S\n S\n are 0,\n Q\n Q\n Q\n retains its old value\n Q\n prev\n Q_{\\text{prev}}\n Q\n prev\n \u200b\n , and\n Q\n \u203e\n \\overline{Q}\n Q\n \u200b\n becomes its opposite. This indicates that the circuit has memory.\n</p>\n<h3>\n Summary of the Truth Table\n</h3>\n<p>\n The truth table (Figure 3.5) captures the behavior of the SR latch based on its inputs\n S\n S\n S\n (Set) and\n R\n R\n R\n (Reset):\n</p>\n<ul>\n <li>\n  <strong>\n   Setting a bit\n  </strong>\n  : Making it TRUE.\n </li>\n <li>\n  <strong>\n   Resetting a bit\n  </strong>\n  : Making it FALSE.\n </li>\n <li>\n  <strong>\n   Outputs\n   Q\n   Q\n   Q\n   and\n   Q\n   \u203e\n   \\overline{Q}\n   Q\n   \u200b\n  </strong>\n  : Usually complementary.\n </li>\n <li>\n  When\n  R\n  R\n  R\n  is active,\n  Q\n  Q\n  Q\n  resets to 0, and\n  Q\n  \u203e\n  \\overline{Q}\n  Q\n  \u200b\n  becomes 1. When\n  S\n  S\n  S\n  is active,\n  Q\n  Q\n  Q\n  sets to 1, and\n  Q\n  \u203e\n  \\overline{Q}\n  Q\n  \u200b\n  becomes 0.\n </li>\n <li>\n  If both\n  S\n  S\n  S\n  and\n  R\n  R\n  R\n  are active, it creates a contradiction (set and reset simultaneously), causing both outputs to become 0.\n </li>\n</ul>\n<h3>\n SR Latch Representation\n</h3>\n<p>\n The SR latch is symbolized in Figure 3.6. This representation is an example of abstraction and modularity in circuit design. Different configurations can implement an SR latch using various logic gates or transistors, but as long as th\n</p>\n"}, "Page 109": {"response": "<h3>\n Memory in the SR Latch\n</h3>\n<p>\n The state of the SR latch is fully described by the variable\n Q\n Q\n Q\n . Regardless of the previous sequence of setting and resetting, you only need to know if the latch was most recently set (1) or reset (0) to predict its future behavior.\n</p>\n<h3>\n D Latch\n</h3>\n<p>\n The SR latch can behave unpredictably when both\n S\n S\n S\n and\n R\n R\n R\n are activated at the same time. Additionally, the\n S\n S\n S\n and\n R\n R\n R\n inputs mix up the concepts of what the state should be and when it should change. To address these issues, the D latch, shown in Figure 3.7(a), was developed.\n</p>\n<h4>\n Inputs and Functionality\n</h4>\n<p>\n The D latch has two inputs:\n</p>\n<ul>\n <li>\n  <strong>\n   Data input (D)\n  </strong>\n  : This determines what the next state should be.\n </li>\n <li>\n  <strong>\n   Clock input (CLK)\n  </strong>\n  : This controls when the state changes.\n </li>\n</ul>\n<h4>\n Truth Table Analysis\n</h4>\n<p>\n To understand the D latch, we can refer to the truth table in Figure 3.7(b):\n</p>\n<ul>\n <li>\n  When\n  C\n  L\n  K\n  =\n  0\n  CLK = 0\n  C\n  L\n  K\n  =\n  0\n  : Both\n  S\n  S\n  S\n  and\n  R\n  R\n  R\n  are FALSE, regardless of the value of\n  D\n  D\n  D\n  . The latch retains its previous output\n  Q\n  prev\n  Q_{\\text{prev}}\n  Q\n  prev\n  \u200b\n  .\n </li>\n <li>\n  When\n  C\n  L\n  K\n  =\n  1\n  CLK = 1\n  C\n  L\n  K\n  =\n  1\n  : The outputs\n  S\n  S\n  S\n  and\n  R\n  R\n  R\n  depend on\n  D\n  D\n  D\n  :\n  <ul>\n   <li>\n    If\n    D\n    =\n    1\n    D = 1\n    D\n    =\n    1\n    :\n    S\n    S\n    S\n    becomes TRUE, allowing\n    Q\n    Q\n    Q\n    to be set to 1.\n   </li>\n   <li>\n    If\n    D\n    =\n    0\n    D = 0\n    D\n    =\n    0\n    :\n    R\n    R\n    R\n    becomes TRUE, allowing\n    Q\n    Q\n    Q\n    to be reset to 0.\n   </li>\n  </ul>\n </li>\n</ul>\n<p>\n In both cases,\n Q\n \u203e\n \\overline{Q}\n Q\n \u200b\n remains the opposite of\n Q\n Q\n Q\n .\n</p>\n<h3>\n Behavior of the D Latch\n</h3>\n<p>\n The D latch is \"transparent\" when\n C\n L\n K\n =\n 1\n CLK = 1\n C\n L\n K\n =\n 1\n . This means data flows from\n D\n D\n D\n directly to\n Q\n Q\n Q\n , almost like a buffer. Conversely, when\n C\n L\n K\n =\n 0\n CLK = 0\n C\n L\n K\n =\n 0\n , it becomes \"opaque,\" blocking new data from passing through and keeping\n Q\n Q\n Q\n at its previous value.\n</p>\n<p>\n The D latch is often called a\n <strong>\n  transparent latch\n </strong>\n or a\n <strong>\n  level-sensitive latch\n </strong>\n , as depicted in Figure 3.7(c). It continuously updates its state while\n C\n L\n K\n =\n 1\n CLK = 1\n C\n L\n K\n =\n 1\n . Later in this chapter, we will explore the D flip-flop, which updates its state at specific moments in time rather than continuously.\n</p>\n<h3>\n Terminology\n</h3>\n<p>\n Some may refer to a latch as being \"open\" or \"closed,\" but this terminology can be confusing. It's clearer to describe them as transparent (allowing data flow) or opaque (blocking data flow) to avoid ambiguity.\n</p>\n"}, "Page 110": {"response": "<h3>\n D Flip-Flop\n</h3>\n<p>\n A D flip-flop consists of two D latches connected in series, with opposite clock signals, as shown in Figure 3.8(a). The first latch is called the\n <strong>\n  master\n </strong>\n (L1), and the second is the\n <strong>\n  slave\n </strong>\n (L2). The connection between them is called\n <strong>\n  N1\n </strong>\n . The symbol for the D flip-flop is shown in Figure 3.8(b), and a simplified version is in Figure 3.8(c).\n</p>\n<h4>\n Functionality\n</h4>\n<ul>\n <li>\n  When\n  <strong>\n   CLK = 0\n  </strong>\n  : The master latch is transparent, allowing the value of\n  D\n  D\n  D\n  to pass through to\n  N\n  1\n  N1\n  N\n  1\n  . The slave latch is opaque, so its output\n  Q\n  Q\n  Q\n  remains unchanged.\n </li>\n <li>\n  When\n  <strong>\n   CLK = 1\n  </strong>\n  : The master latch becomes opaque, and the slave latch becomes transparent. The value at\n  N\n  1\n  N1\n  N\n  1\n  (which was just set by the master) now flows to\n  Q\n  Q\n  Q\n  . At this point,\n  D\n  D\n  D\n  is no longer connected to\n  N\n  1\n  N1\n  N\n  1\n  , so\n  Q\n  Q\n  Q\n  only changes based on what\n  D\n  D\n  D\n  was just before the clock transitioned from 0 to 1.\n </li>\n</ul>\n<p>\n This means the D flip-flop captures the value of\n D\n D\n D\n at the rising edge of the clock and maintains that value until the next clock edge. It's essential to remember that the D flip-flop only changes its output\n Q\n Q\n Q\n at this clock edge.\n</p>\n<h3>\n Terminology\n</h3>\n<p>\n A D flip-flop is also called:\n</p>\n<ul>\n <li>\n  <strong>\n   Master-slave flip-flop\n  </strong>\n </li>\n <li>\n  <strong>\n   Edge-triggered flip-flop\n  </strong>\n </li>\n <li>\n  <strong>\n   Positive edge-triggered flip-flop\n  </strong>\n </li>\n</ul>\n<p>\n The triangle in its symbol indicates that it responds to the edge of the clock signal. The output\n Q\n Q\n Q\n can be omitted in simplified diagrams when not needed.\n</p>\n<h3>\n Example: Transistor Count for a D Flip-Flop\n</h3>\n<p>\n To determine how many transistors are needed for a D flip-flop:\n</p>\n<ul>\n <li>\n  A\n  <strong>\n   NAND\n  </strong>\n  or\n  <strong>\n   NOR\n  </strong>\n  gate uses 4 transistors.\n </li>\n <li>\n  A\n  <strong>\n   NOT\n  </strong>\n  gate uses 2 transistors.\n </li>\n <li>\n  An\n  <strong>\n   AND\n  </strong>\n  gate, made from a NAND and NOT, uses 6 transistors.\n </li>\n <li>\n  An\n  <strong>\n   SR latch\n  </strong>\n  consists of 2 NOR gates, totaling 8 transistors.\n </li>\n <li>\n  A\n  <strong>\n   D latch\n  </strong>\n  uses an SR latch plus 2 AND gates and a NOT, totaling 22 transistors.\n </li>\n <li>\n  Thus, a\n  <strong>\n   D flip-flop\n  </strong>\n  uses 2 D latches and a NOT gate, which adds up to 46 transistors.\n </li>\n</ul>\n<p>\n A more efficient design using CMOS technology is discussed in Section 3.2.7.\n</p>\n<h3>\n Register\n</h3>\n<p>\n An\n <strong>\n  N-bit register\n </strong>\n is simply a group of N flip-flops that share a common clock input. This means all bits in the register can be updated simultaneously based on the clock signal.\n</p>\n<h3>\n Clarification of Terms\n</h3>\n<p>\n The distinction between flip-flops and latches can be confusing:\n</p>\n<ul>\n <li>\n  A\n  <strong>\n   flip-flop\n  </strong>\n  is typically edge-triggered and only changes state at a clock edge (e.g., when the clock rises from 0 to 1).\n </li>\n <li>\n  A\n  <strong>\n   latch\n  </strong>\n  does not respond to clock edges and can change its state based on input levels.\n </li>\n</ul>\n<p>\n In common usage, the term \"flip-flop\" usually refers to a D flip-flop, while \"latch\" refers to a D latch, as these are the most frequently used types in practice.\n</p>\n"}, "Page 111": {"response": "<h3>\n Registers\n</h3>\n<p>\n Registers are essential components in most sequential circuits. They store multiple bits of data. Figure 3.9 illustrates a four-bit register, which has four inputs (\n D\n 3\n :\n 0\n D3:0\n D\n 3\n :\n 0\n ) and four outputs (\n Q\n 3\n :\n 0\n Q3:0\n Q\n 3\n :\n 0\n ). Both the inputs and outputs function as 4-bit buses, allowing the transfer of data in parallel.\n</p>\n<h3>\n Enabled Flip-Flop\n</h3>\n<p>\n An\n <strong>\n  enabled flip-flop\n </strong>\n includes an additional input, known as\n <strong>\n  EN\n </strong>\n (or ENABLE), which controls whether data is loaded on the clock edge. Here's how it works:\n</p>\n<ul>\n <li>\n  <strong>\n   When EN is TRUE\n  </strong>\n  : The enabled flip-flop operates just like a regular D flip-flop, allowing it to update its output based on the input\n  D\n  D\n  D\n  when the clock signal activates.\n </li>\n <li>\n  <strong>\n   When EN is FALSE\n  </strong>\n  : The flip-flop ignores the clock signal and keeps i\n </li>\n</ul>\n"}, "Page 112": {"response": "<h3>\n Enabled Flip-Flop\n</h3>\n<p>\n When the\n <strong>\n  EN\n </strong>\n (ENABLE) input is TRUE, the CLK (clock) input for the flip-flop operates normally. If EN is FALSE, the CLK input also becomes FALSE, and the flip-flop retains its previous value. It's crucial that EN doesn't change while CLK is HIGH (1) to prevent clock glitches, which can cause the flip-flop to switch at the wrong time. Generally, manipulating the clock signal this way can lead to timing issues, so it should only be done if you fully understand the implications.\n</p>\n<h3>\n Resettable Flip-Flop\n</h3>\n<p>\n A\n <strong>\n  resettable flip-flop\n </strong>\n includes an additional input called\n <strong>\n  RESET\n </strong>\n . Here's how it works:\n</p>\n<ul>\n <li>\n  <strong>\n   When RESET is FALSE\n  </strong>\n  : The flip-flop functions like a standard D flip-flop.\n </li>\n <li>\n  <strong>\n   When RESET is TRUE\n  </strong>\n  : The flip-flop ignores the D input and resets its output to 0. This is particularly useful for setting all flip-flops to a known state (0) when the system is powered on.\n </li>\n</ul>\n<p>\n Resettable flip-flops can be either synchronous or asynchronous:\n</p>\n<ul>\n <li>\n  <strong>\n   Synchronous Resettable Flip-Flops\n  </strong>\n  : They only reset on the rising edge of the CLK signal.\n </li>\n <li>\n  <strong>\n   Asynchronous Resettable Flip-Flops\n  </strong>\n  : They reset immediately when RESET goes HIGH, regardless of the CLK state.\n </li>\n</ul>\n<p>\n Figure 3.11(a) shows a synchronous resettable flip-flop constructed from a standard D flip-flop and an AND gate. When RESET is FALSE, the AND gate sends a 0 to the flip-flop, resetting it. When RESET is TRUE, the AND gate allows the D input to pass through. In this design, RESET is active low, meaning it activates the reset function when it's 0. An inverter could be added to make it active high instead.\n</p>\n<p>\n Figures 3.11(b) and 3.11(c) show the symbols for resettable flip-flops with an active high RESET input.\n</p>\n<p>\n <strong>\n  Asynchronous resettable flip-flops\n </strong>\n require changes to the flip-flop's internal structure, which you can design in Exercise 3.10. These flip-flops are often available as standard components.\n</p>\n<p>\n Additionally,\n <strong>\n  settable flip-flops\n </strong>\n can also be used. They load a 1 into the flip-flop when the SET input is asserted and can be synchronous or asynchronous. Both resettable and settable flip-flops may include an enable input and can be grouped into N-bit registers.\n</p>\n<h3>\n Transistor-Level Latch and Flip-Flop Designs\n</h3>\n<p>\n While Example 3.1 highlighted that latches and flip-flops made from logic gates require many transistors, there are more efficient designs at th\n</p>\n"}, "Page 113": {"response": "<h3>\n Latch Design Using Transmission Gates\n</h3>\n<p>\n A latch can operate in two modes:\n <strong>\n  transparent\n </strong>\n (allowing data to flow) or\n <strong>\n  opaque\n </strong>\n (blocking data). To efficiently create a latch, we can use\n <strong>\n  transmission gates\n </strong>\n , which are effective CMOS switches.\n</p>\n<h4>\n Compact D Latch\n</h4>\n<p>\n A simple D latch can be made using one transmission gate, as shown in Figure 3.12(a). Here\u2019s how it works:\n</p>\n<ul>\n <li>\n  <strong>\n   When CLK = 1\n  </strong>\n  : The transmission gate is ON, allowing the value of D to pass through to Q, making the latch transparent.\n </li>\n <li>\n  <strong>\n   When CLK = 0\n  </strong>\n  : The transmission gate is OFF, isolating Q from D, making the latch opaque.\n </li>\n</ul>\n<p>\n However, this design has two significant drawbacks:\n</p>\n<ol>\n <li>\n  <p>\n   <strong>\n    Floating Output Node\n   </strong>\n   : When the latch is opaque, Q doesn't have any gates holding its value. This makes Q a floating or dynamic node, meaning it can change unexpectedly due to noise or charge leakage over time.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Lack of Buffers\n   </strong>\n   : Without buffers, external noise can interfere with the latch\u2019s operation. For example, if D experiences a voltage spike, it can inadvertently turn on the nMOS transistor, making the latch transparent even when CLK is 0. Similarly, noise on D can affect the pMOS transistor. Transmission gates are symmetric, so noise on Q can also affect D. To avoid these issues, neither the input of a transmission gate nor the state of a sequential circuit should be exposed to external noise.\n  </p>\n </li>\n</ol>\n<h4>\n Improved 12-Transistor D Latch\n</h4>\n<p>\n Figure 3.12(b) presents a more reliable D latch design using 12 transistors. This version retains the clocked transmission gate but adds:\n</p>\n<ul>\n <li>\n  <strong>\n   Inverters (I1 and I2)\n  </strong>\n  : These serve as buffers for the input and output, making the latch more robust.\n </li>\n <li>\n  <strong>\n   Static Node (N1)\n  </strong>\n  : The state of the latch is held on this node.\n </li>\n <li>\n  <strong>\n   Inverter I3 and Tristate Buffer T1\n  </strong>\n  : These components provide feedback to maintain N1 as a static node, ensuring that even if a small amount of noise affects N1 while CLK is 0, T1 will return N1 to a valid logic level.\n </li>\n</ul>\n<h4>\n D Flip-Flop Design\n</h4>\n<p>\n Figure 3.13 shows a D flip-flop made from two static latches, controlled by the CLK signal. This design is more efficient because it eliminates some redundant internal inverters, resulting in a total of only\n <strong>\n  20 transistors\n </strong>\n required.\n</p>\n<p>\n Overall, using transmission gates and adding buffering components enhances the stability and reliabi\n</p>\n"}, "Page 114": {"response": "<h3>\n Overview of Latches and Flip-Flops\n</h3>\n<p>\n Latches and flip-flops are essential components in sequential circuits. Here are the key differences and functions:\n</p>\n<ul>\n <li>\n  <strong>\n   D Latch\n  </strong>\n  :\n  <ul>\n   <li>\n    <strong>\n     Level-sensitive\n    </strong>\n    : It is transparent when CLK = 1, meaning it allows the input D to flow directly to the output Q.\n   </li>\n  </ul>\n </li>\n <li>\n  <strong>\n   D Flip-Flop\n  </strong>\n  :\n  <ul>\n   <li>\n    <strong>\n     Edge-triggered\n    </strong>\n    : It captures the value of D and transfers it to Q only on the rising edge of CLK. At all other times, both the latch and flip-flop maintain their previous state.\n   </li>\n  </ul>\n </li>\n</ul>\n<p>\n A\n <strong>\n  register\n </strong>\n consists of multiple D flip-flops that all receive the same CLK signal, allowing them to update simultaneously.\n</p>\n<h3>\n Example Comparison: D Latch vs. D Flip-Flop\n</h3>\n<p>\n In Example 3.2, we analyze how a D latch and a D flip-flop respond to given D and CLK inputs shown in Figure 3.14.\n</p>\n<p>\n <strong>\n  Output Analysis\n </strong>\n :\n</p>\n<ol>\n <li>\n  <p>\n   <strong>\n    D Latch\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    The initial value of Q is unknown (could be 0 or 1).\n   </li>\n   <li>\n    On the first rising edge of CLK, if D = 0, then Q will become 0.\n   </li>\n   <li>\n    While CLK = 1, any changes in D will directly update Q.\n   </li>\n   <li>\n    When CLK = 0, changes in D do not affect Q.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    D Flip-Flop\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Q copies the value of D on each rising edge of CLK.\n   </li>\n   <li>\n    At all other times (when CLK is not rising), Q holds its last value and does not change.\n   </li>\n  </ul>\n </li>\n</ol>\n<p>\n Figures 3.14 and 3.15 illustrate these waveforms, show\n</p>\n"}, "Page 115": {"response": "<h3>\n Synchronous Logic Design Overview\n</h3>\n<p>\n Sequential circuits are those where the output depends not just on current inputs but also on past states. This section explores unusual sequential circuits and introduces synchronous sequential circuits, which help simplify the analysis and design process.\n</p>\n<h3>\n 3.3.1 Problematic Circuits\n</h3>\n<h4>\n Example 3.3: Astable Circuits\n</h4>\n<p>\n Alyssa P. Hacker finds a loop of three inverters connected together (shown in Figure 3.16). Each inverter has a propagation delay of 1 nanosecond (ns).\n</p>\n<p>\n <strong>\n  Analysis\n </strong>\n :\n</p>\n<ul>\n <li>\n  If we start with node X at 0, then:\n  <ul>\n   <li>\n    Y becomes 1,\n   </li>\n   <li>\n    Z goes back to 0,\n   </li>\n   <li>\n    This causes X to switch to 1, which contradicts our initial assumption.\n   </li>\n  </ul>\n </li>\n <li>\n  The circuit has no stable states and is called\n  <strong>\n   unstable\n  </strong>\n  or\n  <strong>\n   astable\n  </strong>\n  .\n </li>\n</ul>\n<p>\n <strong>\n  Behavior\n </strong>\n :\n</p>\n<ul>\n <li>\n  If X changes to 1 at time 0, the outputs will change in the following sequence:\n  <ul>\n   <li>\n    At 1 ns: Y falls to 0.\n   </li>\n   <li>\n    At 2 ns: Z rises to 1.\n   </li>\n   <li>\n    At 3 ns: X falls back to 0.\n   </li>\n   <li>\n    This cycle continues, creating a repetitive pattern every 6 ns.\n   </li>\n  </ul>\n </li>\n</ul>\n<p>\n This setup is known as a\n <strong>\n  ring oscillator\n </strong>\n . Its period (the time it takes to complete one cycle) depends on the inverter's propagation delay, which varies based on manufacturing, voltage, and temperature. Thus, the period is hard to predict accurately. Overall, a ring oscillator is a sequential circuit with no inputs and an output that changes periodically.\n</p>\n<h4>\n Example 3.4: Race Conditions\n</h4>\n<p>\n Ben Bitdiddle claims he has designed a new D latch that is superior because it uses fewer gates. He has create\n</p>\n"}, "Page 116": {"response": "<h3>\n Race Conditions in Latch Design\n</h3>\n<p>\n Ben Bitdiddle has created a D latch design, shown in Figure 3.18, based on the inputs D and CLK and the previous state of the latch, Qprev. He has derived Boolean equations from a truth table and is feeding back the output Q to obtain Qprev.\n</p>\n<p>\n <strong>\n  Does the Latch Work?\n </strong>\n</p>\n<ul>\n <li>\n  The latch may not work correctly due to\n  <strong>\n   race conditions\n  </strong>\n  . These occur when different gates in the circuit have varying delays.\n </li>\n</ul>\n<p>\n <strong>\n  Example of Failure\n </strong>\n :\n</p>\n<ol>\n <li>\n  When both CLK and D are 1, the latch becomes transparent, passing D to Q (thus Q = 1).\n </li>\n <li>\n  When CLK falls, the latch is supposed to hold Q at 1.\n </li>\n <li>\n  If the inverter delay from CLK to N1 is longer than the delays of the AND and OR gates, both N1 and Q might fall before N2 rises.\n </li>\n <li>\n  This could prevent N2 from rising, resulting in Q getting stuck at 0.\n </li>\n</ol>\n<p>\n <strong>\n  Asynchronous Circuit Design\n </strong>\n :\n</p>\n<ul>\n <li>\n  <p>\n   This design is an example of an\n   <strong>\n    asynchronous circuit\n   </strong>\n   , where outputs are directly fed back to inputs. Such circuits often suffer from race conditions, where the behavior depends on the speed of signal paths through the logic gates.\n  </p>\n </li>\n <li>\n  <p>\n   Problems arise because:\n  </p>\n  <ul>\n   <li>\n    One circuit may function correctly while another, seemingly identical circuit with slightly different gate delays, may fail.\n   </li>\n   <li>\n    Performance can also vary with temperature or voltage changes, making it challenging to troubleshoot these issues.\n   </li>\n  </ul>\n </li>\n</ul>\n<h3>\n 3.3.2 Synchronous Sequential Circuits\n</h3>\n<p>\n The previous examples involved\n <strong>\n  cyclic paths\n </strong>\n , where outputs loop back to inputs, making them sequential rather than combinational circuits.\n</p>\n<ul>\n <li>\n  <p>\n   <strong>\n    Combinational Logic\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Has no cyclic paths or races. Outputs settle to the correct values within a specific propagation delay when inputs are applied.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Sequential Circuits\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    With cyclic paths, they can exhibit undesirable races or unstable behavior.\n   </li>\n   <li>\n    Analyzing these circuits for potential issues is time-consuming and error-prone, leading to mistakes even among experienced designers.\n   </li>\n  </ul>\n </li>\n</ul>\n"}, "Page 117": {"response": "<p>\n To prevent issues like race conditions, designers insert registers into cyclic paths in circuits. This change transforms the setup into a combination of combinational logic and registers, where registers store the system's state. The state updates only at clock edges, meaning it's synchronized with the clock. If the clock speed is slow enough for inputs to settle before the next edge, all race conditions can be eliminated.\n</p>\n<h3>\n Definition of Synchronous Sequential Circuits\n</h3>\n<p>\n A synchronous sequential circuit is defined by its input and output terminals, functional specifications, and timing specifications. Key characteristics include:\n</p>\n<ul>\n <li>\n  <strong>\n   Finite States\n  </strong>\n  : It has a limited number of states, such as {S0, S1, ..., Sk-1}.\n </li>\n <li>\n  <strong>\n   Clock Input\n  </strong>\n  : The rising edge of the clock indicates when state transitions happen.\n </li>\n <li>\n  <strong>\n   Current and Next State\n  </strong>\n  : We refer to the state of the system at the present as the current state and the future state after the next clock edge as the next state.\n </li>\n</ul>\n<p>\n The\n <strong>\n  functional specification\n </strong>\n outlines how the next state and outputs are determined based on the current state and inputs. The\n <strong>\n  timing specification\n </strong>\n includes:\n</p>\n<ul>\n <li>\n  <strong>\n   tpcq\n  </strong>\n  : The maximum time for the output to change after the clock edge.\n </li>\n <li>\n  <strong>\n   tccq\n  </strong>\n  : The minimum time before the output starts to change.\n </li>\n <li>\n  <strong>\n   Setup and Hold Times\n  </strong>\n  : These specify when inputs need to be stable in relation to the clock edge (tsetup and thold).\n </li>\n</ul>\n<h3>\n Rules for Synchronous Sequential Circuits\n</h3>\n<p>\n A circuit is considered synchronous sequential if:\n</p>\n<ul>\n <li>\n  Every element is either a register or a combinational circuit.\n </li>\n <li>\n  At least one element is a register.\n </li>\n <li>\n  All registers share the same clock signal.\n </li>\n <li>\n  Every cyclic path includes a\n </li>\n</ul>\n"}, "Page 118": {"response": "<h3>\n Example 3.5: Identifying Synchronous Sequential Circuits\n</h3>\n<p>\n In Figure 3.21, we need to determine which circuits are synchronous sequential circuits.\n</p>\n<ul>\n <li>\n  <p>\n   <strong>\n    Circuit (a)\n   </strong>\n   : This is combinational logic since it has no registers, so it's not a sequential circuit.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Circuit (b)\n   </strong>\n   : This is a simple sequential circuit because it has no feedback.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Circuit (c)\n   </strong>\n   : This circuit contains a latch, making it neither combinational nor synchronous sequential.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Circuits (d) and (e)\n   </strong>\n   : Both are synchronous sequential circuits and represent two forms of finite state machines, which will be covered in Section 3.4.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Circuit (f)\n   </strong>\n   : This circuit is not combinational or synchronous sequential because it has a feedback loop without a register.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Circuit (g)\n   </strong>\n   : This is a synchronous sequential circuit in the form of a pipeline, discussed in Section 3.6.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Circuit (h)\n   </strong>\n   : Technically, this is not a synchronous sequential circuit because the second register is clocked with a different signal than the first, which is delayed by two inverter stages.\n  </p>\n </li>\n</ul>\n<h3>\n Synchronous vs. Asynchronous Circuits\n</h3>\n<p>\n Asynchronous designs are theoretically broader than synchronous designs because they don't rely on clocked registers for timing. Similar to how analog circuits can utilize any voltage, asynchronous circuits can implement various types of feedback.\n</p>\n<p>\n However, synchronous circuits are generally easier to design and implement, much like digital circuits compared to analog ones. Despite extensive research on asynchronous circuits, nearly all digi\n</p>\n"}, "Page 119": {"response": "<h3>\n Asynchronous Circuits and Their Importance\n</h3>\n<p>\n Asynchronous circuits are sometimes essential for communicating between systems with different clock speeds or for handling inputs received at unpredictable times. This is similar to how analog circuits are needed to interact with the continuous voltage of the real world. Ongoing research in asynchronous circuits can also lead to valuable insights that may enhance synchronous designs.\n</p>\n<h3>\n Finite State Machines (FSMs)\n</h3>\n<p>\n Synchronous sequential circuits can be represented as finite state machines (FSMs), as shown in Figure 3.22. FSMs are called this because a circuit with\n k\n k\n k\n registers can exist in one of\n 2\n k\n 2^k\n 2\n k\n unique states. An FSM has:\n</p>\n<ul>\n <li>\n  <strong>\n   M Inputs\n  </strong>\n  : The signals it receives.\n </li>\n <li>\n  <strong>\n   N Outputs\n  </strong>\n  : The signals it produces.\n </li>\n <li>\n  <strong>\n   k Bits of State\n  </strong>\n  : The information it stores.\n </li>\n</ul>\n<p>\n FSMs operate with a clock signal and may also have a reset signal. They consist of two main components:\n</p>\n<ol>\n <li>\n  <strong>\n   Next State Logic\n  </strong>\n  : Determines the next state based on the current state and inputs.\n </li>\n <li>\n  <strong>\n   Output Logic\n  </strong>\n  : Computes the outputs based on the current state (and possibly the inputs).\n </li>\n</ol>\n<p>\n Each time there is a clock pulse, the FSM transitions to the next state based on its current state and the inputs. There are two main types of FSMs:\n</p>\n<ul>\n <li>\n  <strong>\n   Moore Machines\n  </strong>\n  : Outputs depend only on the current state.\n </li>\n <li>\n  <strong>\n   Mealy Machines\n  </strong>\n  : Outputs depend on both the current state and current inputs.\n </li>\n</ul>\n<p>\n FSMs provide a structured method for designing synchronous sequential circuits based on functional specifications. This section will elaborate on this design process, starting with an example.\n</p>\n<h3>\n FSM Design Example\n</h3>\n<p>\n To demonstrate FSM design, consider creating a controller for a traffic light at a busy campus intersection. This example involves designing an FSM that will manage traffic lights for students moving between dorms and labs on Academic Ave.\n</p>\n<h3>\n Historical Context\n</h3>\n<p>\n Moore and Mealy machines are named after researchers who contributed to automata theory at Bell Labs. Edward F. Moore published influential work on sequential machines in 1956, while George H. Mealy published methods for synthesiz\n</p>\n"}, "Page 120": {"response": "<h3>\n Traffic Light Control with FSM\n</h3>\n<p>\n On a busy campus, students and football players are crossing streets without paying attention, leading to several injuries at the intersection of Academic Ave and Bravado Blvd. The Dean of Students has asked Ben Bitdiddle to install a traffic light to prevent serious accidents.\n</p>\n<p>\n To address this, Ben decides to use a finite state machine (FSM). He installs two traffic sensors:\n</p>\n<ul>\n <li>\n  <strong>\n   TA\n  </strong>\n  on Academic Ave\n </li>\n <li>\n  <strong>\n   TB\n  </strong>\n  on Bravado Blvd\n </li>\n</ul>\n<p>\n Each sensor signals TRUE when students are present and FALSE when the street is empty. Ben also sets up two traffic lights:\n</p>\n<ul>\n <li>\n  <strong>\n   LA\n  </strong>\n  for Academic Ave\n </li>\n <li>\n  <strong>\n   LB\n  </strong>\n  for Bravado Blvd\n </li>\n</ul>\n<p>\n These lights can be controlled to show green, yellow, or red, based on the sensor inputs. The FSM thus has two inputs (TA and TB) and two outputs (LA and LB). The system, including the lights and sensors, is illustrated in Figure 3.23.\n</p>\n<p>\n Ben provides a clock with a 5-second cycle. On each clock tick (the rising edge), the lights can change depending on the traffic detected by the sensors. He also adds a reset button so that maintenance staff can set the system to a known starting state.\n</p>\n<p>\n Next, Ben sketches a state transition diagram (Figure 3.25) that shows all possible states of the system and how the transitions occur. When the system resets, the lights are set to green for Academic Ave and red for Bravado Blvd. Every 5 seconds, the control\n</p>\n"}, "Page 121": {"response": "<h3>\n Traffic Light Control Logic\n</h3>\n<p>\n In the traffic light control system, the light on Academic Ave stays green as long as there are vehicles present. Once traffic clears, the Academic Ave light turns yellow for 5 seconds before switching to red, while the Bravado Blvd. light turns green. Similarly, the Bravado Blvd. light remains green while traffic is present and then turns yellow and eventually red when traffic stops.\n</p>\n<p>\n <strong>\n  State Transition Diagram:\n </strong>\n</p>\n<ul>\n <li>\n  <strong>\n   States:\n  </strong>\n  Represented by circles in the diagram.\n </li>\n <li>\n  <strong>\n   Transitions:\n  </strong>\n  Shown as arrows between states, indicating how the system changes state at the rising edge of the clock. The clock's presence is assumed and not explicitly shown.\n </li>\n <li>\n  <strong>\n   Reset Transition:\n  </strong>\n  An arrow from \"outer space\" leading to state S0 indicates that the system resets to this state regardless of its previous state.\n </li>\n <li>\n  <strong>\n   Multiple Arcs:\n  </strong>\n  If a state has several outgoing arrows, each is labeled to show what input triggers the transition. For example, from state S0, if TA (traffic on Academic Ave) is TRUE, the system stays in S0; if TA is FALSE, it moves to S1.\n </li>\n <li>\n  <strong>\n   Single Arc Transition:\n  </strong>\n  If a state has only one outgoing arc, that transition always occurs, regardless of input. For instance, from state S1, the system always transitions to S2.\n </li>\n</ul>\n<p>\n <strong>\n  Output Values:\n </strong>\n The outputs are indicated within each state. For instance, in state S2, LA (light for Academic Ave) is red, and LB (light for Bravado Blvd) is green.\n</p>\n<p>\n <strong>\n  State Transition Table:\n </strong>\n Ben creates a state transition table (Table 3.1) that outlines the next state (S') based on the current state and inputs. The table uses \"don't care\" symbols (X) when the next state does not depend on a specific input. The reset condition is not included in the table, as resettable flip-flops ensure the system goes to state S0 on reset, regardless of inputs.\n</p>\n<p>\n <strong>\n  Binary Encoding:\n </strong>\n The abstract state transition diagram labels the states as\n</p>\n"}, "Page 122": {"response": "<p>\n It looks like your message got cut off. How can I assist you?\n</p>\n"}, "Page 123": {"response": "<h3>\n Moore Finite State Machine (FSM) Overview\n</h3>\n<p>\n In this section, Ben is developing a Moore finite state machine (FSM) for a traffic light controller. Here\u2019s a clearer breakdown of the process:\n</p>\n<h4>\n Output Table Creation\n</h4>\n<p>\n Ben creates an output table (Table 3.5) that defines the outputs for each possible state of the FSM. It\u2019s easy to derive and simplify the Boolean equations for these outputs. For instance, the output LA1 is TRUE only when the state S1 is TRUE.\n</p>\n<h4>\n Sketching the FSM\n</h4>\n<p>\n Next, Ben sketches the FSM as depicted in Figure 3.22(a). He begins by illustrating a 2-bit state register (shown in Figure 3.26(a)). This register updates its current state, denoted as S1:0, on each clock edge. It can be initialized through either synchronous or asynchronous reset at startup.\n</p>\n<h4>\n Next State Logic\n</h4>\n<p>\n He then outlines the next state logic based on Equation 3.2, which determines the next state using the current state and inputs. This is represented in Figure 3.26(b).\n</p>\n<h4>\n Output Logic\n</h4>\n<p>\n Following that, Ben draws the output logic according to Equation 3.3, which computes the outputs based on the current state, as shown in Figure 3.26(c).\n</p>\n<h4>\n Timing Diagram\n</h4>\n<p>\n Figure 3.27 presents a timing diagram for the traffic light controller, illustrating its transition through various states. This diagram includes:\n</p>\n<ul>\n<li>\n<strong>\n   CLK\n  </strong>\n  : The clock signal.\n </li>\n<li>\n<strong>\n   Reset\n  </strong>\n  : The reset signal.\n </li>\n<li>\n<strong>\n   Inputs\n  </strong>\n  : TA and TB, which influence state changes.\n </li>\n<li>\n<strong>\n   Next State (S')\n  </strong>\n  : The anticipated state after the clock edge.\n </li>\n<li>\n<strong>\n   Current State (S)\n  </strong>\n  : The state of the FSM at any given moment.\n </li>\n<li>\n<strong>\n   Outputs (LA and LB)\n  </strong>\n  : The outputs of the FSM based on the current state.\n </li>\n</ul>\n<p>\n Arrows in the diagram indicate cause-and-effect relationships; for example, a state change affects the outputs, while input changes influence the next state. Dashed lines mark the rising edge of the clock signal, where state changes occur.\n</p>\n<p>\n The clock period is set at 5 seconds, indicating that the traffic lights can change states at most once every 5 seconds. Initially, when the FSM is powered on, its state is uncertain, represented by question marks, necessitating a reset to establish a known starting state.\n</p>\n<h3>\n Output Table Summary (Table 3.5)\n</h3>\n<p>\n The table summarizes the outputs based on the current states (S1 and S0):\n</p>\n<table>\n<thead>\n<tr>\n<th>\n    Current State\n   </th>\n<th>\n    Outputs\n   </th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>\n    S1\n   </td>\n<td>\n    S0\n   </td>\n</tr>\n<tr>\n<td>\n    0\n   </td>\n<td>\n    0\n   </td>\n</tr>\n<tr>\n<td>\n    0\n   </td>\n<td>\n    1\n   </td>\n</tr>\n<tr>\n<td>\n    1\n   </td>\n<td>\n    0\n   </td>\n</tr>\n<tr>\n<td>\n    1\n   </td>\n<td>\n    1\n   </td>\n</tr>\n</tbody>\n</table>\n<p>\n This table provides a clear reference for understanding how the FSM outputs vary with the current state.\n</p>\n"}, "Page 124": {"response": "<h3>\n Traffic Light Controller Design\n</h3>\n<p>\n This section discusses the circuit design for a traffic light controller, illustrating how sequential logic is utilized in its operation.\n</p>\n<h4>\n State Machine Circuit\n</h4>\n<p>\n Figure 3.26 shows the circuit for the traffic light controller, consisting of:\n</p>\n<ol>\n<li>\n<p>\n<strong>\n    State Register\n   </strong>\n   :\n  </p>\n<ul>\n<li>\n    Holds the current state, represented by two bits (S1 and S0).\n   </li>\n<li>\n    Updates its state on each clock pulse (CLK).\n   </li>\n<li>\n    Can be reset using a reset signal (Reset).\n   </li>\n</ul>\n</li>\n<li>\n<p>\n<strong>\n    Next State Logic\n   </strong>\n   :\n  </p>\n<ul>\n<li>\n    Determines the next state (S'1 and S'0) based on current state and inputs (TA and TB).\n   </li>\n</ul>\n</li>\n<li>\n<p>\n<strong>\n    Output Logic\n   </strong>\n   :\n  </p>\n<ul>\n<li>\n    Produces outputs (LA1, LB1, LB0, LA0) based on the current state.\n   </li>\n</ul>\n</li>\n</ol>\n<p>\n This modular design enables clear separation between state management, next state calculation, and output generation.\n</p>\n<h4>\n Timing Diagram\n</h4>\n<p>\n Figure 3.27 illustrates the timing sequence for the traffic light controller. Key elements include:\n</p>\n<ul>\n<li>\n<strong>\n   Clock Cycles\n  </strong>\n  : Each cycle shows the state transitions of the traffic lights over time, marking specific states such as Green (00), Yellow (01), and Red (10).\n </li>\n<li>\n<strong>\n   State Changes\n  </strong>\n  : The diagram indicates state changes at specific intervals, where the system starts in an unknown state, requiring a reset to establish a known configuration.\n </li>\n</ul>\n<p>\n The diagram also depicts how the traffic lights change according to the clock cycles, ensuring they operate in a predictable sequence.\n</p>\n<h4>\n Implementation Notes\n</h4>\n<p>\n The schematic employs AND gates with inverted inputs (bubbles). These can be implemented in various ways:\n</p>\n<ul>\n<li>\n  Using AND gates paired with inverters.\n </li>\n<li>\n  Using NOR gates with inverters for non-inverted inputs.\n </li>\n<li>\n  The optimal choice for gate configuration depends on the specific technology used for implementation.\n </li>\n</ul>\n<p>\n This flexibility allows designers to adapt the logic to fit different hardware setups while maintain\n</p>\n"}, "Page 125": {"response": "<h3>\n Traffic Light Controller Operation and State Encoding\n</h3>\n<p>\n This section explains the operation of a traffic light controller and discusses the principles of state encoding in finite state machines (FSMs).\n</p>\n<h4>\n Traffic Light Operation\n</h4>\n<p>\n The traffic light controller starts by resetting to state S0, where light LA is green and light LB is red. When traffic arrives on Academic Ave., the controller keeps LA green even if vehicles on Bravado Blvd. start to wait.\n</p>\n<ul>\n<li>\n<strong>\n   Timing Sequence\n  </strong>\n  :\n  <ul>\n<li>\n    After 15 seconds, traffic on Academic Ave. clears, and the input TA (indicating traffic on Academic Ave.) falls.\n   </li>\n<li>\n    At the next clock edge, the controller transitions to state S1, changing LA to yellow.\n   </li>\n<li>\n    After another 5 seconds, the controller moves to state S2, where LA turns red and LB turns green, allowing traffic on Bravado Blvd. to proceed.\n   </li>\n<li>\n    Once traffic on Bravado Blvd. clears, the controller enters state S3, changing LB to yellow.\n   </li>\n<li>\n    After 5 more seconds, it returns to state S0, making LB red and LA green again. This cycle then repeats.\n   </li>\n</ul>\n</li>\n</ul>\n<h4>\n State Encodings\n</h4>\n<p>\n The example illustrates that state and output encodings can be chosen arbitrarily, impacting the design of the circuit. The challenge lies in finding an encoding that minimizes logic gates or reduces propagation delay. However, there isn\u2019t a straightforward method to determine the optimal encoding without exploring all possibilities, which can be impractical for numerous states.\n</p>\n<ul>\n<li>\n<strong>\n   Encoding Choices\n  </strong>\n  :\n  <ul>\n<li>\n<strong>\n     Binary Encoding\n    </strong>\n    :\n    <ul>\n<li>\n      Each state is represented by a binary number. For K states, log2K bits are required. This was used in the traffic light example.\n     </li>\n</ul>\n</li>\n<li>\n<strong>\n     One-Hot Encoding\n    </strong>\n    :\n    <ul>\n<li>\n      Each state has its own dedicated bit, resulting in one bit being \"hot\" (TRUE) at any time. For example, three states might be encoded as 001, 010, and 100. This method requires more flip-flops but can simplify next-state and output logic, potentially using fewer gates overall.\n     </li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>\n The best encoding strategy often depends on the specific FSM design.\n</p>\n<h4>\n Example: Divide-by-N Counter\n</h4>\n<p>\n As an example of state encoding, consider a divide-by-3 counter, which outputs a HIGH signal for one clock cycle every three cycles. The design can be implemented using both binary and one-hot state encodings, each with its own advantages in terms of circuit complexity.\n</p>\n<h4>\n Conclusion\n</h4>\n<p>\n While designing FSMs, it's crucial to consider state encodings carefully to balance complexity, efficiency, and performance. Ultimately, the goal is to create circuits that operate correctly and efficiently within the specified application context.\n</p>\n"}, "Page 126": {"response": "<h3>\n Overview of State Encoding for a Divide-by-3 Counter\n</h3>\n<p>\n This section discusses the state transition and output tables for a divide-by-3 counter, along with comparisons of binary and one-hot encodings.\n</p>\n<h4>\n State Transition and Output Tables\n</h4>\n<p>\n Tables 3.6 and 3.7 present the abstract state transition and output tables before encoding the divide-by-3 counter.\n</p>\n<ul>\n<li>\n<p>\n<strong>\n    State Transition Table (Table 3.6)\n   </strong>\n   :\n  </p>\n<ul>\n<li>\n    This table shows how the current state transitions to the next state.\n   </li>\n<li>\n    The transitions occur as follows:\n    <ul>\n<li>\n      From S0 to S1\n     </li>\n<li>\n      From S1 to S2\n     </li>\n<li>\n      From S2 back to S0\n     </li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>\n<strong>\n    Output Table (Table 3.7)\n   </strong>\n   :\n  </p>\n<ul>\n<li>\n    This table lists the output corresponding to each state:\n    <ul>\n<li>\n      In state S0, the output is 1.\n     </li>\n<li>\n      In states S1 and S2, the output is 0.\n     </li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h4>\n Encoding Comparisons\n</h4>\n<ul>\n<li>\n<p>\n<strong>\n    Binary Encoding\n   </strong>\n   :\n  </p>\n<ul>\n<li>\n    This method uses two bits to represent the three states.\n   </li>\n<li>\n    The state transition table using binary encoding is shown in Table 3.9.\n   </li>\n<li>\n    Notably, the next state depends solely on the current state, with no additional inputs required. The output table is left for the reader to complete.\n   </li>\n<li>\n    The next-state and output equations for binary encoding are defined in Equations (3.4) and (3.5).\n   </li>\n</ul>\n</li>\n<li>\n<p>\n<strong>\n    One-Hot Encoding\n   </strong>\n   :\n  </p>\n<ul>\n<li>\n    This method employs three bits, where each state is represented by one \"hot\" (TRUE) bit.\n   </li>\n<li>\n    The state transition table for one-hot encoding appears in Table 3.10, while the output table is again for the reader to fill in.\n   </li>\n<li>\n    The next-state and output equations for one-hot encoding are given in Equations (3.6) and (3.7).\n   </li>\n</ul>\n</li>\n</ul>\n<h4>\n Schematic Designs\n</h4>\n<p>\n Figure 3.29 illustrates the schematics for both encoding designs:\n</p>\n<ul>\n<li>\n  The binary encoded design can be optimized to share the same gate for outputs Y and S0.\n </li>\n<li>\n  The one-hot encoding requires both settable (s) and resettable (r) flip-flops to ensure that the FSM resets to state S0.\n </li>\n</ul>\n<p>\n The choice between these implementations often depends on the relative costs of gates and flip-flops. In many cases, one-hot encoding is preferred for this type of counter due to its simplicity in logic design.\n</p>\n<h4>\n Related Encoding: One-Cold Encoding\n</h4>\n<p>\n Another encoding method is the one-cold encoding, where K states are represented using K bits, with exactly one bit being FALSE at any time. This is a less common encoding but may be useful in certain applications.\n</p>\n<p>\n By understanding these different encoding methods and their implications on circuit design, you can optimize the performance and e\n</p>\n"}, "Page 127": {"response": "<h3>\n Overview of Encodings for the Divide-by-3 Counter\n</h3>\n<p>\n This section examines the binary and one-hot encodings used for the divide-by-3 counter, detailing their respective state representations and transition tables.\n</p>\n<h4>\n Encoding Comparisons\n</h4>\n<p>\n<strong>\n  Table 3.8\n </strong>\n shows the state encodings for the divide-by-3 counter, comparing binary and one-hot encodings:\n</p>\n<ul>\n<li>\n<p>\n<strong>\n    Binary Encoding\n   </strong>\n   :\n  </p>\n<ul>\n<li>\n    Uses two bits to represent the three states:\n    <ul>\n<li>\n      S0: 00\n     </li>\n<li>\n      S1: 01\n     </li>\n<li>\n      S2: 10\n     </li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>\n<strong>\n    One-Hot Encoding\n   </strong>\n   :\n  </p>\n<ul>\n<li>\n    Uses three bits, where each state is represented by one bit being \"hot\":\n    <ul>\n<li>\n      S0: 001\n     </li>\n<li>\n      S1: 010\n     </li>\n<li>\n      S2: 100\n     </li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h4>\n State Transition Tables\n</h4>\n<p>\n<strong>\n  Table 3.9\n </strong>\n presents the state transition table for binary encoding. It outlines how the current state transitions to the next state:\n</p>\n<ul>\n<li>\n<strong>\n   Current State to Next State\n  </strong>\n  :\n  <ul>\n<li>\n    From 00 (S0) to 01 (S1)\n   </li>\n<li>\n    From 01 (S1) to 10 (S2)\n   </li>\n<li>\n    From 10 (S2) back to 00 (S0)\n   </li>\n</ul>\n</li>\n</ul>\n<p>\n<strong>\n  Table 3.10\n </strong>\n shows the state transition table for one-hot encoding. It specifies the same transitions but in a one-hot format:\n</p>\n<ul>\n<li>\n<strong>\n   Current State to Next State\n  </strong>\n  :\n  <ul>\n<li>\n    From 001 (S0) to 010 (S1)\n   </li>\n<li>\n    From 010 (S1) to 100 (S2)\n   </li>\n<li>\n    From 100 (S2) back to 001 (S0)\n   </li>\n</ul>\n</li>\n</ul>\n<h4>\n Circuit Designs\n</h4>\n<p>\n<strong>\n  Figure 3.29\n </strong>\n illustrates the circuit designs for both encoding types:\n</p>\n<ul>\n<li>\n<strong>\n   (a) Binary Encoding Circuit\n  </strong>\n  : Displays the output logic, state register, and next state logic interconnected.\n </li>\n<li>\n<strong>\n   (b) One-Hot Encoding Circuit\n  </strong>\n  : Shows a similar structure but tailored for one-hot encoding, requiring both settable and resettable flip-flops to manage state transitions.\n </li>\n</ul>\n<p>\n By understanding these encodings and their corresponding transition tables, designers can choose the most efficient implementation for the divide-by-3 counter, balancing complexity and performance.\n</p>\n"}, "Page 128": {"response": "<h3>\n Moore and Mealy Machines: An Overview\n</h3>\n<p>\n This section explains the key differences between Moore and Mealy machines, which are types of finite state machines (FSMs).\n</p>\n<h4>\n Moore Machines\n</h4>\n<p>\n In a\n <strong>\n  Moore machine\n </strong>\n , the output depends solely on the current state. In state transition diagrams for Moore machines, outputs are indicated inside the circles representing each state. This means the output is consistent as long as the machine remains in the same state, regardless of any changes in input.\n</p>\n<h4>\n Mealy Machines\n</h4>\n<p>\n In contrast, a\n <strong>\n  Mealy machine\n </strong>\n allows the output to be influenced by both the current state and the inputs. In state transition diagrams for Mealy machines, outputs are labeled on the arcs connecting the states. This means the output can change immediately with input changes, potentially leading to fewer states than a Moore machine.\n</p>\n<h4>\n Example: Robotic Snail FSM\n</h4>\n<p>\n Consider an example involving a robotic snail that crawls along a tape of 1's and 0's. The snail smiles when the last four bits it has encountered are 1101. The input (A) is the bit directly underneath the snail's antennae, and the output (Y) indicates whether the snail smiles.\n</p>\n<ul>\n<li>\n<p>\n<strong>\n    Moore Machine Design\n   </strong>\n   :\n  </p>\n<ul>\n<li>\n    This design requires five states, as illustrated in the corresponding state transition diagram. An arc from state S4 to S2 when the input is 1 signifies a transition based on the input while maintaining the output based on the current state.\n   </li>\n</ul>\n</li>\n<li>\n<p>\n<strong>\n    Mealy Machine Design\n   </strong>\n   :\n  </p>\n<ul>\n<li>\n    This version only needs four states, which streamlines the design. The transitions are labeled with A/Y, where A is the input value that triggers the transition and Y is the output.\n   </li>\n</ul>\n</li>\n</ul>\n<h4>\n State Transition and Output Tables\n</h4>\n<p>\n The tables for the Moore machine (Tables 3.11 and 3.12) indicate the state transitions and outputs based on the input sequence. A binary encoding can represent the states as follows:\n</p>\n<ul>\n<li>\n  S0: 000\n </li>\n<li>\n  S1: 001\n </li>\n<li>\n  S2: 010\n </li>\n<li>\n  S3: 011\n </li>\n<li>\n  S4: 100\n </li>\n</ul>\n<p>\n Similarly, Tables 3.13 and 3.14 provide the state transition and output tables with these encodings.\n</p>\n<h4>\n Minimizing Equations\n</h4>\n<p>\n The next state and output equations can be derived from the tables. Notably, the presence of \"don't care\" conditions (for states that do not exist) allows for simplification of these equations, making them easier to work with.\n</p>\n<h3>\n Key Takeaway\n</h3>\n<p>\n A simple way to remember the difference between these two types of machines is that Moore machines generally require more states than Mealy machines to so\n</p>\n"}, "Page 129": {"response": "<h3>\n Mealy Machine State Transition and Output Table\n</h3>\n<p>\n Table 3.15 presents the combined state transition and output table for a Mealy machine. This design requires at least two bits to represent the states, which can be encoded as follows:\n</p>\n<ul>\n<li>\n  S0: 00\n </li>\n<li>\n  S1: 01\n </li>\n<li>\n  S2: 10\n </li>\n<li>\n  S3: 11\n </li>\n</ul>\n<p>\n Table 3.16 then reformulates the state transition and output table using these binary encodings. From these tables, we can derive the next state and output equations through inspection.\n</p>\n<h3>\n Schematic Diagrams\n</h3>\n<p>\n The schematics for both the Moore and Mealy machines are illustrated in Figure 3.31(a) and 3.31(b), respectively.\n</p>\n<h3>\n Timing Diagrams\n</h3>\n<p>\n The timing diagrams for both machines, shown in Figure 3.32, reveal that they follow different sequences of states. Notably, the Mealy machine\u2019s output changes a clock cycle sooner than the Moore machine\u2019s output. This is because the Mealy machine reacts directly to input changes, whereas the Moore machine waits for a state transition. If the Mealy output were delayed using a flip-flop, it would align with the Moore output.\n</p>\n<h3>\n Design Considerations\n</h3>\n<p>\n When selecting your FSM design approach, it's important to consider when you want the outputs to respond to inputs. This decision can significantly influence the behav\n</p>\n"}, "Page 130": {"response": "<h3>\n Moore State Transition and Output Tables\n</h3>\n<p>\n<strong>\n  Moore State Transition Table (with State Encodings)\n </strong>\n<br/>\n Table 3.13 outlines the state transitions for a Moore machine, which shows how the system moves from one state to another based on the current state and input. Here\u2019s a breakdown:\n</p>\n<ul>\n<li>\n<strong>\n   Current State\n  </strong>\n  : Identifies the current state using binary encodings (S2, S1, S0).\n </li>\n<li>\n<strong>\n   Input\n  </strong>\n  : The input A that triggers state transitions.\n </li>\n<li>\n<strong>\n   Next State\n  </strong>\n  : Indicates the next state (S'2, S'1, S'0) based on the current state and input.\n </li>\n</ul>\n<p>\n<strong>\n  Moore Output Table (with State Encodings)\n </strong>\n<br/>\n Table 3.14 provides the output corresponding to each state:\n</p>\n<ul>\n<li>\n<strong>\n   Current State\n  </strong>\n  : Displays the state (S2, S1, S0).\n </li>\n<li>\n<strong>\n   Output (Y)\n  </strong>\n  : Shows the output for each state. For instance, the output is 1 when in state S4 and 0 in all other states.\n </li>\n</ul>\n<h3>\n Summary of Tables\n</h3>\n<ul>\n<li>\n  The\n  <strong>\n   Moore state transition table\n  </strong>\n  highlights how the machine transitions from one state to another based on inputs, while the\n  <strong>\n   output table\n  </strong>\n  details what output is produced in each state.\n </li>\n<li>\n  The machine design typically reflects a deterministic approach where outputs depend solely on the current state, as illustrated by the consistent outputs for states S0 through S4.\n </li>\n</ul>\n<p>\n These tables are essential for understanding the operational logic of the Moore machine and how it proc\n</p>\n"}, "Page 131": {"response": "<h3>\n Factoring State Machines\n</h3>\n<p>\n<strong>\n  Overview of Factoring State Machines\n </strong>\n<br/>\n Designing complex finite state machines (FSMs) can be simplified by breaking them down into smaller, more manageable state machines. This approach allows for greater modularity and organization within the design process.\n</p>\n<p>\n<strong>\n  Key Concepts:\n </strong>\n</p>\n<ul>\n<li>\n<strong>\n   Hierarchy and Modularity\n  </strong>\n  : By creating simpler state machines that interact with one another, you can design a more complex FSM without losing clarity. Each smaller machine can handle a specific part of the overall function.\n </li>\n<li>\n<strong>\n   Input and Output Interactions\n  </strong>\n  : The output of one state machine can serve as the input for another. This interconnectivity enables the combination of simpler functions to achieve more complex behaviors efficiently.\n </li>\n</ul>\n<p>\n This method of factoring state machines is beneficial in reducing complexity, making it easier to design, test, and main\n</p>\n"}, "Page 132": {"response": "<h3>\n Example 3.8: Unfactored and Factored State Machines\n</h3>\n<h4>\n Introduction\n</h4>\n<p>\n This example modifies the traffic light controller to include a \"parade mode\" that keeps the Bravado Boulevard light green while a parade passes by. The controller now has two additional inputs:\n <strong>\n  P\n </strong>\n for entering parade mode and\n <strong>\n  R\n </strong>\n for exiting it.\n</p>\n<h4>\n Single FSM Approach\n</h4>\n<ol>\n <li>\n  <p>\n   <strong>\n    Inputs\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     P\n    </strong>\n    : Activates parade mode for at least one clock cycle.\n   </li>\n   <li>\n    <strong>\n     R\n    </strong>\n    : Deactivates parade mode for at least one clock cycle.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Functionality\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    When\n    <strong>\n     P\n    </strong>\n    is asserted, the controller transitions into parade mode.\n   </li>\n   <li>\n    In parade mode, the controller follows its regular sequence until the LB light turns green. It then stays in that state with LB green until\n    <strong>\n     R\n    </strong>\n    is asserted to exit parade mode.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    State Transition Diagram\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    The state transition diagram for this single FSM is illustrated in Figure 3.33(a). It shows how the system moves between states based on the inputs.\n   </li>\n  </ul>\n </li>\n</ol>\n<h4>\n Factored FSM Approach\n</h4>\n<ol>\n <li>\n  <p>\n   <strong>\n    Modular Design\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Instead of using one large FSM, the design can be broken down into two smaller interacting FSMs.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Interaction\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    The first FSM manages the regular traffic light sequence.\n   </li>\n   <li>\n    The second FSM handles the parade mode.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    State Transition Diagrams\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    Each of the two FSMs has its own state transition diagram. This separation allows for clearer management and easier modifications, as each FSM focuses on its specific functionality.\n   </li>\n  </ul>\n </li>\n</ol>\n<h3>\n Conclusion\n</h3>\n<p>\n By modifying the traffic light controller to include a parade mode, the design can be approached through both a single FSM and a factored FSM method. The factored approach can simplify complexity and improve\n</p>\n"}, "Page 133": {"response": "<h3>\n 3.4 Finite State Machines\n</h3>\n<h4>\n Timing Diagrams\n</h4>\n<p>\n The timing diagrams for Mealy and Moore machines illustrate how the state transitions and outputs change over cycles. Each machine behaves differently in response to inputs over multiple cycles, with the Mealy machine often producing outputs sooner because its output depends on both the state and inputs.\n</p>\n<h4>\n Modified Traffic Light Controller\n</h4>\n<ol>\n <li>\n  <p>\n   <strong>\n    Design Overview\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    The modified traffic light controller includes a \"parade mode,\" activated by the input\n    <strong>\n     P\n    </strong>\n    and deactivated by\n    <strong>\n     R\n    </strong>\n    .\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Single FSM Design\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     States\n    </strong>\n    : The single FSM design includes states S0 to S3 for normal operation and states S4 to S7 for parade mode.\n   </li>\n   <li>\n    In parade mode (states S4 to S7), the FSM keeps the Bravado Boulevard light green, staying in state S6.\n   </li>\n   <li>\n    The\n    <strong>\n     P\n    </strong>\n    and\n    <strong>\n     R\n    </strong>\n    inputs manage transitions between normal and parade modes.\n   </li>\n   <li>\n    This design is complex and can be cumbersome.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Factored FSM Design\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    The factored design separates the FSM into two parts: a Mode FSM and a Lights FSM.\n   </li>\n   <li>\n    The Mode FSM tracks whether the system is in normal or parade mode and asserts an output\n    <strong>\n     M\n    </strong>\n    when in parade mode.\n   </li>\n   <li>\n    The Lights FSM operates based on the state of\n    <strong>\n     M\n    </strong>\n    and the traffic sensors (TA and TB).\n   </li>\n   <li>\n    This design simplifies the overall structure, allowing the Lights FSM to stay in state S2 while\n    <strong>\n     M\n    </strong>\n    is active, making it more organized and manageable.\n   </li>\n  </ul>\n </li>\n</ol>\n<h3>\n Summary\n</h3>\n<p>\n By comparing the single FSM\n</p>\n"}, "Page 134": {"response": "<h3>\n 3.4.5 FSM Review\n</h3>\n<p>\n Finite State Machines (FSMs) are effective tools for designing sequential circuits based on a set of specifications. Here\u2019s a straightforward procedure to create an FSM:\n</p>\n<ol>\n <li>\n  <p>\n   <strong>\n    Identify Inputs and Outputs\n   </strong>\n   : Determine what signals will serve as inputs to the FSM and what outputs it will generate.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Sketch a State Transition Diagram\n   </strong>\n   : Create a visual representation of how the FSM transitions between different states based on inputs.\n  </p>\n </li>\n</ol>\n<h3>\n Example Transition Diagram\n</h3>\n<p>\n In the provided diagrams:\n</p>\n<ul>\n <li>\n  <p>\n   <strong>\n    States\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     S0\n    </strong>\n    : LA is green, LB is red.\n   </li>\n   <li>\n    <strong>\n     S1\n    </strong>\n    : LA is yellow, LB is red.\n   </li>\n   <li>\n    <strong>\n     S2\n    </strong>\n    : LA is red, LB is green.\n   </li>\n   <li>\n    <strong>\n     S3\n    </strong>\n    : LA is red, LB is yellow.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Inputs\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    <strong>\n     TA\n    </strong>\n    and\n    <strong>\n     TB\n    </strong>\n    represent traffic inputs.\n   </li>\n   <li>\n    <strong>\n     P\n    </strong>\n    activates parade mode.\n   </li>\n   <li>\n    <strong>\n     R\n    </strong>\n    deactivates parade mode.\n   </li>\n  </ul>\n </li>\n <li>\n  <p>\n   <strong>\n    Transition Dynamics\n   </strong>\n   :\n  </p>\n  <ul>\n   <li>\n    In the unfactored design, the system transitions through states based on traffic inputs and the parade mode signals.\n   </li>\n   <li>\n    In the factored design, the system is divided into two parts: a Mode FSM that tracks whether the system is in normal or parade mode, and a Lights FSM that manages the light signals based on the current mode.\n   </li>\n  </ul>\n </li>\n</ul>\n<h3>\n S\n</h3>\n"}, "Page 135": {"response": "<h3>\n FSM Design Steps\n</h3>\n<h4>\n For a Moore Machine:\n</h4>\n<ol>\n <li>\n  <strong>\n   Write a State Transition Table\n  </strong>\n  : List the current states and the next states based on inputs.\n </li>\n <li>\n  <strong>\n   Write an Output Table\n  </strong>\n  : Specify the outputs for each state.\n </li>\n</ol>\n<h4>\n For a Mealy Machine:\n</h4>\n<ol>\n <li>\n  <p>\n   <strong>\n    Write a Combined State Transition and Output Table\n   </strong>\n   : This includes both the next state and the output for each current state and input.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Select State Encodings\n   </strong>\n   : The choice of state encoding will impact the hardware design of the machine.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Write Boolean Equations\n   </strong>\n   : Formulate the equations for the next state and output logic based on the tables.\n  </p>\n </li>\n <li>\n  <p>\n   <strong>\n    Sketch the Circuit Schematic\n   </strong>\n   : Create a visual representation of the circuit that implements the FSM.\n  </p>\n </li>\n</ol>\n<h3>\n Overview\n</h3>\n<p>\n These steps will be used throughout the book to design complex digital systems using FSMs.\n</p>\n<hr/>\n<h3>\n 3.5 Timing of Sequential Logic\n</h3>\n<p>\n A flip-flop transfers the input\n D\n D\n D\n to the output\n Q\n Q\n Q\n on the rising edge of the clock. This is known as sampling\n D\n D\n D\n . If\n D\n D\n D\n is stable at either 0 or 1 when the clock rises, the behavior is clear. However, if\n D\n D\n D\n changes right when the clock rises, issues can arise.\n</p>\n<h4>\n The Camera Analogy\n</h4>\n<p>\n Think of a camera capturing a moment: if it snaps a picture of a frog jumping at the wrong time, the image may be blurry. Just like a camera has an aperture time to capture a clear image, a sequential element has an aperture time around the clock edge. During this time, the input must be stable for the flip-flop to output a defined value.\n</p>\n<h4>\n Aperture Time\n</h4>\n<p>\n The aperture time consists of:\n</p>\n<ul>\n <li>\n  <strong>\n   Setup Time\n  </strong>\n  : Time before the clock edge when the input must be stable.\n </li>\n <li>\n  <strong>\n   Hold Time\n  </strong>\n  : Time after the clock edge during which the input should remain stable.\n </li>\n</ul>\n<p>\n To avoid issues, signals should change outside of this aperture time. This aligns with the dynamic discipline, which helps manage timing in digital systems.\n</p>\n<h4>\n Discrete Timing\n</h4>\n<p>\n We can think of time in discrete units called clock cycles instead of specific instants. A signal may fluctuate during its cycle, but we only care about its stable value at the end of the cycle. For example, we can write\n A\n [\n n\n ]\n A[n]\n A\n [\n n\n ]\n for the value of signal\n A\n A\n A\n at the end of the\n n\n n\n n\n -th clock c\n</p>\n"}, "Page 136": {"response": "<h3>\n Clock Skew and Metastability\n</h3>\n<p>\n In digital circuits, it's crucial for all flip-flops to receive the clock signal simultaneously. However, variations in the timing of the clock signal, known as clock skew, can lengthen the necessary clock period.\n</p>\n<p>\n Sometimes, it's impossible to ensure stable signals when interacting with real-world inputs. For example, if a button is pressed just as the clock signal rises, this can lead to\n <strong>\n  metastability\n </strong>\n . In this state, a flip-flop may capture a signal that's neither fully 0 nor fully 1. The time it takes to resolve this into a stable logic level can be unpredictable. To address this issue with asynchronous inputs, a\n <strong>\n  synchronizer\n </strong>\n is used, which has a small chance of producing an invalid logic value.\n</p>\n<hr/>\n<h3>\n 3.5.1 The Dynamic Discipline\n</h3>\n<p>\n We have focused on the functionality of sequential circuits, but timing is als\n</p>\n"}, "Page 137": {"response": "<h3>\n 3.5.2 System Timing\n</h3>\n<p>\n<strong>\n  Clock Period and Frequency\n </strong>\n<br/>\n The clock period (Tc) is the time between rising edges of a repetitive clock signal. Its reciprocal,\n f\n c\n =\n 1\n T\n c\n f_c = \\frac{1}{T_c}\n f\n c\n \u200b\n =\n T\n c\n \u200b\n 1\n \u200b\n , gives the clock frequency. Higher clock frequencies enable digital systems to perform more work per unit time. Frequency is measured in Hertz (Hz):\n</p>\n<ul>\n<li>\n  1 MHz =\n  1\n  0\n  6\n  10^6\n  1\n  0\n  6\n  Hz\n </li>\n<li>\n  1 GHz =\n  1\n  0\n  9\n  10^9\n  1\n  0\n  9\n  Hz\n </li>\n</ul>\n<p>\n<strong>\n  Synchronous Circuit Timing\n </strong>\n<br/>\n In a synchronous sequential circuit, the timing of the clock period can be illustrated as follows:\n</p>\n<ul>\n<li>\n  On the clock's rising edge, register R1 outputs\n  Q\n  1\n  Q1\n  Q\n  1\n  .\n </li>\n<li>\n  These outputs go to combinational logic, producing\n  D\n  2\n  D2\n  D\n  2\n  , the input for register R2.\n </li>\n</ul>\n<p>\n Timing diagrams show two important delays:\n</p>\n<ul>\n<li>\n<strong>\n   Contamination Delay\n  </strong>\n  : The time it takes for output to start changing after input changes (represented by gray arrows).\n </li>\n<li>\n<strong>\n   Propagation Delay\n  </strong>\n  : The time until the output settles to its final value (represented by blue arrows).\n </li>\n</ul>\n<p>\n<strong>\n  Setup Time Constraint\n </strong>\n<br/>\n To meet the setup time requirement for R2,\n D\n 2\n D2\n D\n 2\n must stabilize no later than the setup time before the next clock edge. This is illustrated in a timing diagram that focuses on the maximum delay through the path (blue arrows).\n</p>\n<p>\n<strong>\n  Historical Context\n </strong>\n<br/>\n In the past thirty years, microprocessor clock frequencies have dramatically increased from 1 MHz to several GHz\u2014over a 1000-fold increase. This acceleration in processing speed has significantly transformed computing and its impact on society.\n</p>\n"}, "Page 237": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 138": {"response": "<p>\n To determine the minimum clock period, we refer to Equation 3.12. In commercial designs, the clock period is typically set by the Director of Engineering or the marketing team to ensure the product remains competitive. The manufacturer specifies the flip-flop's clock-to-Q propagation delay (\n t\n p\n c\n q\n t_{pcq}\n t\n p\n c\n q\n \u200b\n ) and setup time (\n t\n s\n e\n t\n u\n p\n t_{setup}\n t\n se\n t\n u\n p\n \u200b\n ).\n</p>\n<p>\n We can rearrange Equation 3.12 to find the maximum allowable propagation delay through the combinational logic, which is the main variable that designers can control. This rearranged equation is represented as Equation 3.13.\n</p>\n<p>\n In this context, the term\n (\n t\n p\n c\n q\n +\n t\n s\n e\n t\n u\n p\n )\n (t_{pcq} + t_{setup})\n (\n t\n p\n c\n q\n \u200b\n +\n t\n se\n t\n u\n p\n \u200b\n )\n is known as the sequencing overhead. Ideally, the entire clock cycle time (\n T\n c\n T_c\n T\n c\n \u200b\n ) would be available for the useful computation in the combinational logic, represented by the propagation delay (\n t\n p\n d\n t_{pd}\n t\n p\n d\n \u200b\n ). However, the sequencing overhead reduces this available time. Equation 3.13 is referred to as the setup time constraint or max-delay constraint because it relies on the setup time and restricts the maximum propagation delay through the combinational logic.\n</p>\n<p>\n If the propagation delay is too long, the input\n D\n 2\n D_2\n D\n 2\n \u200b\n may not stabilize in time for register\n R\n 2\n R_2\n R\n 2\n \u200b\n to sample it correctly, potentially leading to incorrect results or illegal logic levels. This could cause the circuit to malfunction. To remedy this, one could either extend the clock period or redesign the combinational logic to reduce the propagation delay.\n</p>\n<p>\n Additionally, register\n R\n 2\n R_2\n R\n 2\n \u200b\n</p>\n"}, "Page 143": {"response": "<p>\n In Figure 3.44,\n C\n L\n K\n 2\n CLK2\n C\n L\n K\n 2\n arrives earlier than\n C\n L\n K\n 1\n CLK1\n C\n L\n K\n 1\n due to the longer routing path of the clock wire between the two registers. If the routing had been different, it\u2019s possible that\n C\n L\n K\n 1\n CLK1\n C\n L\n K\n 1\n could have arrived earlier instead. When performing timing analysis, we must consider the worst-case scenario to ensure that the circuit operates reliably under all conditions.\n</p>\n<p>\n Figure 3.45 incorporates clock skew into the timing diagram from Figure 3.36. The solid clock line represents the latest time the clock signal could reach any register, while the dashed lines indicate that the clock could arrive up to\n t\n s\n k\n e\n w\n t_{skew}\n t\n s\n k\n e\n w\n \u200b\n earlier.\n</p>\n<h3>\n Setup Time Constraint\n</h3>\n<p>\n Referring to Figure 3.46, in the worst case,\n R\n 1\n R1\n R\n 1\n receives the latest skewed clock, while\n R\n 2\n R2\n R\n 2\n gets the earliest skewed clock. This configuration minimizes the available time for data to propagate between the registers. The data must travel through the register and the combinational logic before it can be sampled by\n R\n 2\n R2\n R\n 2\n . This leads us to the following conclusion:\n</p>\nt\np\nd\n\u2264\nT\nc\n\u2212\n(\nt\np\nc\nq\n+\nt\ns\ne\nt\nu\np\n+\nt\ns\nk\ne\nw\n)\n(3.18)\nt_{pd} \\leq T_c - (t_{pcq} + t_{setup} + t_{skew}) \\quad \\text{(3.18)}\nt\np\nd\n\u200b\n\u2264\nT\nc\n\u200b\n\u2212\n(\nt\np\nc\nq\n\u200b\n+\nt\nse\nt\nu\np\n\u200b\n+\nt\ns\nk\ne\nw\n\u200b\n)\n(3.18)\nT\nc\n\u2265\nt\np\nc\nq\n+\nt\np\nd\n+\nt\ns\ne\nt\nu\np\n+\nt\ns\nk\ne\nw\n(3.19)\nT_c \\geq t_{pcq} + t_{pd} + t_{setup} + t_{skew} \\quad \\text{(3.19)}\nT\nc\n\u200b\n\u2265\nt\np\nc\nq\n\u200b\n+\nt\np\nd\n\u200b\n+\nt\nse\nt\nu\np\n\u200b\n+\nt\ns\nk\ne\nw\n\u200b\n(3.19)\n<h3>\n Hold Time Constraint\n</h3>\n<p>\n In Figure 3.47, we examine the hold time constraint. Here,\n R\n 1\n R1\n R\n 1\n receives an early skewed clock (\n C\n L\n K\n 1\n CLK1\n C\n L\n K\n 1\n ), and\n R\n 2\n R2\n R\n 2\n receives a late skewed clock (\n C\n L\n K\n 2\n CLK2\n C\n L\n K\n 2\n ). The data propagates through the register and must remain stable for the hold time after\n R\n 2\n R2\n R\n 2\n samples it.\n</p>\n<p>\n Understanding these timing constraints with clock skew is essential for designing reli\n</p>\n"}, "Page 139": {"response": "<p>\n From Equation 3.14, we note that\n t\n c\n c\n q\n t_{ccq}\n t\n cc\n q\n \u200b\n (the clock-to-Q contamination delay) and\n t\n h\n o\n l\n d\n t_{hold}\n t\n h\n o\n l\n d\n \u200b\n (the hold time) are typically fixed characteristics of the flip-flop, and designers usually cannot modify them. By rearranging the equation, we can derive the minimum contamination delay through the combinational logic, expressed in Equation 3.15. This equation is referred to as the min-delay constraint since it sets a limit on the minimum delay in the logic.\n</p>\n<p>\n We assume that any logic elements can be interconnected without introducing timing issues. Specifically, two flip-flops can be directly cascaded without encountering hold time problems, as shown in Figure 3.39. In this case, the contamination delay (\n t\n c\n d\n t_{cd}\n t\n c\n d\n \u200b\n ) is considered zero because there is no combinational logic between the two flip-flops. Plugging this into Equation 3.15 leads us to Equation 3.16, which states that a reliable flip-flop must have a hold time shorter than its contamination delay.\n</p>\n<p>\n Often, flip-flops are designed with\n t\n h\n o\n l\n d\n =\n 0\n t_{hold} = 0\n t\n h\n o\n l\n d\n \u200b\n =\n 0\n , ensuring Equation 3.16 is always met. For simplicity, we will generally assume this in our discussions and overlook the hold time constraint.\n</p>\n<p>\n However, hold time constraints are crucial. If these constraints are violated, the only solution is to increase the contamination delay in the logic, which necessitates a redesign of the circuit. Unlike setup time violations, hold time issues cannot be resolved by merely adjusting the clock period. Redesigning an integrated circuit can be a lengthy and costly process, taking months and potentially millions of dollars, so it's vital to take hold time violations seriously.\n</p>\n<h3>\n Summary\n</h3>\n<p>\n Sequential circuits have both setup and hold time constraints that define the maximum and minimum delays of the combinational logic between flip-flops. Modern flip-flops are often designed so the minimum delay through the combinational logic is zero, allowing them to be placed directly in sequence. The maximum delay constraint limits the number of gates in the critical path of high-speed circuits, where a shorter clock period corresponds to a higher clock frequency.\n</p>\n<h3>\n Example\n</h3>\n<p>\n In Example 3.9, Ben Bitdiddle's circuit design (referenced in Figure 3.40) utilizes flip-flops with specified clock-to-Q contamination delays.\n</p>\n"}, "Page 140": {"response": "<p>\n In this scenario, Ben is working with flip-flops that have a clock-to-Q contamination delay of 30 ps, a propagation delay of 80 ps, a setup time of 50 ps, and a hold time of 60 ps. Each logic gate has a propagation delay of 40 ps and a contamination delay of 25 ps. Ben needs to determine the maximum clock frequency and assess potential hold time violations. This process is known as timing analysis.\n</p>\n<h3>\n Solution:\n</h3>\n<p>\n Figure 3.41(a) illustrates the waveforms showing when the signals may change. Inputs A through D are registered and change shortly after the rising edge of the clock (CLK).\n</p>\n<p>\n<strong>\n  Critical Path Analysis:\n </strong>\n The critical path is defined when\n B\n =\n 1\n B = 1\n B\n =\n 1\n ,\n C\n =\n 0\n C = 0\n C\n =\n 0\n ,\n D\n =\n 0\n D = 0\n D\n =\n 0\n , and\n A\n A\n A\n rises from 0 to 1, triggering\n n\n 1\n n1\n n\n 1\n to rise,\n X\n \u2032\n X'\n X\n \u2032\n to rise, and\n Y\n \u2032\n Y'\n Y\n \u2032\n to fall, as depicted in Figure 3.41(b). This path involves three gate delays, assuming each gate operates at its full propagation delay. To ensure\n Y\n \u2032\n Y'\n Y\n \u2032\n is stable before the next rising edge of CLK, we calculate the minimum cycle time (\n T\n c\n T_c\n T\n c\n \u200b\n ):\n</p>\nT\nc\n=\nt\np\nc\nq\n+\n3\n\u00d7\nt\np\nd\n+\nt\ns\ne\nt\nu\np\n=\n80\nps\n+\n3\n\u00d7\n40\nps\n+\n50\nps\n=\n250\nps\nT_c = t_{pcq} + 3 \\times t_{pd} + t_{setup} = 80 \\, \\text{ps} + 3 \\times 40 \\, \\text{ps} + 50 \\, \\text{ps} = 250 \\, \\text{ps}\nT\nc\n\u200b\n=\nt\np\nc\nq\n\u200b\n+\n3\n\u00d7\nt\np\nd\n\u200b\n+\nt\nse\nt\nu\np\n\u200b\n=\n80\nps\n+\n3\n\u00d7\n40\nps\n+\n50\nps\n=\n250\nps\n<p>\n The maximum clock frequency (\n f\n c\n f_c\n f\n c\n \u200b\n ) can then be calculated as:\n</p>\nf\nc\n=\n1\nT\nc\n=\n1\n250\nps\n=\n4\nGHz\nf_c = \\frac{1}{T_c} = \\frac{1}{250 \\, \\text{ps}} = 4 \\, \\text{GHz}\nf\nc\n\u200b\n=\nT\nc\n\u200b\n1\n\u200b\n=\n250\nps\n1\n\u200b\n=\n4\nGHz\n<p>\n<strong>\n  Short Path Analysis:\n </strong>\n A short path occurs when\n A\n =\n 0\n A = 0\n A\n =\n 0\n and\n C\n C\n C\n rises, causing\n X\n \u2032\n X'\n X\n \u2032\n to rise, as shown in Figure 3.41(c). In this case, we assume each gate switches after its contamination delay, leading to a delay of:\n</p>\nt\ns\nh\no\nr\nt\np\na\nt\nh\n=\nt\nc\nc\nq\n+\nt\nc\nd\n=\n30\nps\n+\n25\nps\n=\n55\nps\nt_{short\\ path} = t_{ccq} + t_{cd} = 30 \\, \\text{ps} + 25 \\, \\text{ps} = 55 \\, \\text{ps}\nt\ns\nh\nor\nt\np\na\nt\nh\n\u200b\n=\nt\ncc\nq\n\u200b\n+\nt\nc\nd\n\u200b\n=\n30\nps\n+\n25\nps\n=\n55\nps\n<p>\n However, the flip-flop has a hold time of 60 ps, meaning that\n X\n \u2032\n X'\n X\n \u2032\n must remain stable for at least 60 ps after the CLK's rising edge for it to reliably sample its value. Since\n X\n \u2032\n =\n 0\n X' = 0\n X\n \u2032\n =\n 0\n at the first rising edge of CLK, we need\n X\n X\n X\n to capture this stable value of 0.\n</p>\n<p>\n Because\n X\n \u2032\n X'\n X\n \u2032\n does not remain stable long enough (only 55 ps), there is a hold time violation. As a result, the actual value of\n X\n X\n X\n is unpredictable, leading to potential erratic behavior at any clock frequency.\n</p>\n<h3>\n Summary:\n</h3>\n<ul>\n<li>\n<strong>\n   Maximum Clock Frequency:\n  </strong>\n  4 GHz\n </li>\n<li>\n<strong>\n   Hold Time Violation:\n  </strong>\n  Yes, due to insufficient stability of\n  X\n  \u2032\n  X'\n  X\n  \u2032\n  after the clock edge, which may cause\n </li>\n</ul>\n"}, "Page 145": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 141": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to resolve hold time violations. These buffers will slow down the short paths, as shown in Figure 3.42. We need to determine the maximum clock frequency and check for any remaining hold time issues.\n</p>\n<h3>\n Solution:\n</h3>\n<p>\n Figure 3.43 presents the waveforms illustrating when signals may change. The critical path from\n A\n A\n A\n to\n Y\n Y\n Y\n remains unaffected by the buffers, meaning the maximum clock frequency is still 4 GHz.\n</p>\n<p>\n For the short paths, the addition of the buffers introduces a delay. Now,\n X\n \u2032\n X'\n X\n \u2032\n will not change until:\n</p>\nt\nc\nc\nq\n+\n2\n\u00d7\nt\nc\nd\n=\n30\nps\n+\n2\n\u00d7\n25\nps\n=\n80\nps\nt_{ccq} + 2 \\times t_{cd} = 30 \\, \\text{ps} + 2 \\times 25 \\, \\text{ps} = 80 \\, \\text{ps}\nt\ncc\nq\n\u200b\n+\n2\n\u00d7\nt\nc\nd\n\u200b\n=\n30\nps\n+\n2\n\u00d7\n25\nps\n=\n80\nps\n<p>\n This change occurs after the 60 ps hold time has elapsed, ensuring that the circuit operates correctly without hold time violations.\n</p>\n<p>\n This example features an unusually long hold time to emphasize the importance of hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n &lt;\n t\n c\n c\n q\n t_{hold} &lt; t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n &lt;\n t\n cc\n q\n \u200b\n to prevent such problems.\n</p>\n<p>\n Additionally, some high-performance microprocessors, like the Pentium 4, utilize a component called a pulsed latch instead of a flip-flop. The pulsed latch functions similarly to a flip-flop but has a shorter clock-to-Q delay and a longer hold time.\n</p>\n<p>\n In general, adding buffers can often, but not always, resolve hold time problems without negatively impacting the critical path.\n</p>\n"}, "Page 146": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 149": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 151": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 150": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 144": {"response": "<h3>\n Impact of Clock Skew on Timing Constraints\n</h3>\n<p>\n Clock skew effectively increases both the setup time and the hold time for sequential circuits. This additional skew contributes to the sequencing overhead, which reduces the time available for the combinational logic to perform useful work. It also raises the minimum required delay through the combinational logic. Even if the hold time (\n t\n h\n o\n l\n d\n t_{hold}\n t\n h\n o\n l\n d\n \u200b\n ) is zero, back-to-back flip-flops will violate the hold time constraint (Equation 3.21) if the clock skew (\n t\n s\n k\n e\n w\n t_{skew}\n t\n s\n k\n e\n w\n \u200b\n ) exceeds the clock-to-Q contamination delay (\n t\n c\n c\n q\n t_{ccq}\n t\n cc\n q\n \u200b\n ). To avoid significant hold time issues, designers must manage clock skew carefully. In some cases, flip-flops are deliberately designed to have a longer\n t\n c\n c\n q\n t_{ccq}\n t\n cc\n q\n \u200b\n to mitigate hold time problems, even when clock skew is substantial.\n</p>\n<h3>\n Example 3.11: Timing Analysis with Clock Skew\n</h3>\n<p>\n Let's revisit Example 3.9, now assuming a clock skew of 50 ps.\n</p>\n<p>\n<strong>\n  Solution:\n </strong>\n</p>\n<ul>\n<li>\n  The critical path remains unchanged, but the effective setup time increases due to skew. Therefore, the minimum cycle time becomes:\n </li>\n</ul>\nT\nc\n=\nt\np\nc\nq\n+\n3\n\u00d7\nt\np\nd\n+\nt\ns\ne\nt\nu\np\n+\nt\ns\nk\ne\nw\n=\n80\nps\n+\n3\n\u00d7\n40\nps\n+\n50\nps\n+\n50\nps\n=\n300\nps\n(3.22)\nT_c = t_{pcq} + 3 \\times t_{pd} + t_{setup} + t_{skew} = 80 \\, \\text{ps} + 3 \\times 40 \\, \\text{ps} + 50 \\, \\text{ps} + 50 \\, \\text{ps} = 300 \\, \\text{ps} \\quad \\text{(3.22)}\nT\nc\n\u200b\n=\nt\np\nc\nq\n\u200b\n+\n3\n\u00d7\nt\np\nd\n\u200b\n+\nt\nse\nt\nu\np\n\u200b\n+\nt\ns\nk\ne\nw\n\u200b\n=\n80\nps\n+\n3\n\u00d7\n40\nps\n+\n50\nps\n+\n50\nps\n=\n300\nps\n(3.22)\n<ul>\n<li>\n  The maximum clock frequency (\n  f\n  c\n  f_c\n  f\n  c\n  \u200b\n  ) can then be calculated as:\n </li>\n</ul>\nf\nc\n=\n1\nT\nc\n=\n1\n300\nps\n\u2248\n3.33\nGHz\nf_c = \\frac{1}{T_c} = \\frac{1}{300 \\, \\text{ps}} \\approx 3.33 \\, \\text{GHz}\nf\nc\n\u200b\n=\nT\nc\n\u200b\n1\n\u200b\n=\n300\nps\n1\n\u200b\n\u2248\n3.33\nGHz\n<ul>\n<li>\n  The short path remains at 55 ps, but the effective hold time is increased by the skew:\n </li>\n</ul>\nt\nh\no\nl\nd\n=\n60\nps\n+\n50\nps\n=\n110\nps\nt_{hold} = 60 \\, \\text{ps} + 50 \\, \\text{ps} = 110 \\, \\text{ps}\nt\nh\no\nl\nd\n\u200b\n=\n60\nps\n+\n50\nps\n=\n110\nps\n<p>\n This value significantly exceeds the 55 ps delay through the combinational logic, resulting in a hold time violation. Therefore, the circuit is likely to malfunction at any frequency. The addition of clock skew exacerbates an already existing hold time issue in the circuit.\n</p>\n"}, "Page 158": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 147": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 142": {"response": "<h3>\n 3.5.3 Clock Skew\n</h3>\n<p>\n In our earlier analysis, we assumed that the clock signal reaches all registers simultaneously. However, in reality, there are variations in this timing, known as clock skew.\n</p>\n<p>\n Clock skew can occur for several reasons:\n</p>\n<ul>\n<li>\n<p>\n<strong>\n    Wire Length Differences\n   </strong>\n   : The wires connecting the clock source to different registers can vary in length, leading to different signal delays, as illustrated in Figure 3.44.\n  </p>\n</li>\n<li>\n<p>\n<strong>\n    Noise\n   </strong>\n   : Variability caused by electrical noise can also affect the timing of the clock signals.\n  </p>\n</li>\n<li>\n<p>\n<strong>\n    Clock Gating\n   </strong>\n   : As described in Section 3.2.5, clock gating can introduce additional delays. When some clocks are gated (turned off) while others remain active, it results in significant skew between the gated and ungated clock signals.\n  </p>\n</li>\n</ul>\n<p>\n Understanding clock skew is essential for ensuring proper circuit operation, as it can impact timing and the reliability of sequential logic designs.\n</p>\n"}, "Page 152": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 148": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 153": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 160": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 162": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 159": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 157": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 161": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 167": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 165": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 155": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 156": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 163": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 168": {"response": "<p>\n Got it! I\u2019ll keep responses high-quality and direct. What do you need?\n</p>\n"}, "Page 174": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 173": {"response": "<h3>\n Endianness and HDL Code Examples\n</h3>\n<p>\n The endianness of a bus is arbitrary and not significant in this context, particularly for a bank of inverters, which is indifferent to bit order. Endianness is important for operations like addition, where carry-over affects subsequent columns. For consistency, we will use little-endian order: [N-1:0] in Verilog and (N-1 downto 0) in VHDL for an N-bit bus.\n</p>\n<p>\n Each code example in this chapter is accompanied by a schematic generated from the Verilog code using the Synplify Pro synthesis tool. For instance, Figure 4.3 shows that the\n <code>\n  inv\n </code>\n module synthesizes to a bank of four inverters, denoted by the inverter symbol labeled y[3:0]. This bank connects to 4-bit input and output buses, and similar hardware is generated from the synthesized VHDL code.\n</p>\n<h4>\n Example: Gates Module\n</h4>\n<p>\n HDL Example 4.3 illustrates bitwise operations on 4-bit buses for other basic logic functions.\n</p>\n<p>\n<strong>\n  Verilog Code for Inverters:\n </strong>\n</p>\nverilog\nCopy code\n<code class=\"!whitespace-pre hljs language-verilog\">\n module inv (input [3:0] a, output [3:0] y);\nassign y = ~a;\nendmodule\n</code>\n<p>\n In this Verilog example,\n <code>\n  a[3:0]\n </code>\n represents a 4-bit bus with bits ordered from most significant to least significant as a[3], a[2], a[1], and a[0]. This is considered little-endian since the least significant bit has the smallest bit number. We could also define the bus as\n <code>\n  a[4:1]\n </code>\n (where a[4] is most significant) or\n <code>\n  a[0:3]\n </code>\n (resulting in big-endian order).\n</p>\n<p>\n<strong>\n  VHDL Code for Inverters:\n </strong>\n</p>\nvhdl\nCopy code\n<code class=\"!whitespace-pre hljs language-vhdl\">\n library IEEE; \nuse IEEE.STD_LOGIC_1164.all;\n\nentity inv is\nport (\n    a: in STD_LOGIC_VECTOR (3 downto 0);\n    y: out STD_LOGIC_VECTOR (3 downto 0)\n);\nend;\n\narchitecture synth of inv is\nbegin\n    y &lt;= not a;\nend;\n</code>\n<p>\n In this VHDL example,\n <code>\n  STD_LOGIC_VECTOR (3 downto 0)\n </code>\n also represents a 4-bit bus. The bits are ordered as 3, 2, 1, and 0, which follows little-endian order. Similar to the Verilog example, we could have defined it as\n <code>\n  STD_LOGIC_VECTOR (4 downto 1)\n </code>\n or\n <code>\n  STD_LOGIC_VECTOR (0 to 3)\n </code>\n for different endianness configurations.\n</p>\n<hr/>\n<p>\n Let me know if you need further information or additional sections summarized!\n</p>\n"}, "Page 184": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 166": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 172": {"response": "<h3>\n Building Hardware with HDL\n</h3>\n<p>\n To effectively build hardware, we focus on a synthesizable subset of hardware description languages (HDLs). This involves separating HDL code into two main components: synthesizable modules and a testbench.\n</p>\n<ul>\n<li>\n<strong>\n   Synthesizable Modules\n  </strong>\n  : These describe the hardware itself.\n </li>\n<li>\n<strong>\n   Testbench\n  </strong>\n  : This contains code for applying inputs to the module, verifying the outputs, and printing any discrepancies between expected and actual results. Note that testbench code is only for simulation and cannot be synthesized into hardware.\n </li>\n</ul>\n<p>\n A common mistake among beginners is viewing HDL as a typical computer program rather than as a concise way to describe digital hardware. If you don't have a clear idea of the hardware your HDL should create, the results may be unsatisfactory\u2014either leading to excess hardware or functioning code that cannot be implemented. It\u2019s crucial to visualize your system as blocks of combinational logic, registers, and finite state machines, sketching their connections before writing any code.\n</p>\n<p>\n The best way to learn HDL is through examples. Each type of logic has specific descriptive methods known as idioms. This chapter will guide you in writing the correct HDL idioms for different types of blocks and combining them to form a functioning system. When you need to describe specific hardware, find a similar example and modify it for your needs. We won\u2019t cover all HDL syntax in detail, as that can be tedious and may reinforce the misconception of HDLs as programming languages rather than hardware descriptions. For more in-depth information, refer to the IEEE specifications for Verilog and VHDL or comprehensive textbooks listed in the Further Readings section.\n</p>\n<h3>\n 4.2 Combinational Logic\n</h3>\n<p>\n As we focus on designing synchronous sequential circuits\u2014comprised of both combinational logic and registers\u2014remember that the outputs of combinational logic depend solely on current inputs. This section will explain how to write behavioral models of combinational logic using HDLs.\n</p>\n<h4>\n 4.2.1 Bitwise Operators\n</h4>\n<p>\n Bitwise operators can operate on single-bit signals or multi-bit buses. For example, the\n <code>\n  inv\n </code>\n module in HDL Example 4.2 illustrates four inverters connected to 4-bit buses.\n</p>\n<hr/>\n<p>\n Let me know if you need any further sections summarized or specific details!\n</p>\n"}, "Page 176": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 154": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 178": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 190": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 177": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 179": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 169": {"response": "<h3>\n 4. Overview of Digital Circuit Design\n</h3>\n<h4>\n 4.1 Introduction\n</h4>\n<p>\n Previously, we focused on designing digital circuits through schematics, which involved manually simplifying truth tables and converting finite state machines (FSMs) into logic gates. This method is time-consuming and prone to errors. In the 1990s, designers found that working at a higher abstraction level improved productivity. They began specifying logical functions using hardware description languages (HDLs), allowing computer-aided design (CAD) tools to optimize gate configurations. The two main HDLs are Verilog and VHDL, which share principles but differ in syntax.\n</p>\n<p>\n This chapter compares Verilog and VHDL side-by-side. When learning, concentrate on one language first; mastering one will help you learn the other quickly if needed. Later chapters will present hardware in both schematic and HDL formats. While it's possible to grasp computer organization through schematics alone, most commercial systems now utilize HDLs. For anyone pursuing digital design, learning an HDL is highly recommended.\n</p>\n<h4>\n 4.1.1 Modules\n</h4>\n<p>\n A module is a hardware block defined by its inputs and outputs. Examples include AND gates, multiplexers, and priority circuits. Module functionality can be described in two main styles:\n</p>\n<hr/>\n<p>\n Let me know if you need more sections rephrased or any specific details!\n</p>\n"}, "Page 170": {"response": "<h3>\n VHDL and Verilog Overview\n</h3>\n<p>\n VHDL, developed by a committee involving U.S. military contractors, the European Space Agency, and telecommunications companies, is widely used in hardware design. Both VHDL and Verilog can describe any hardware system, though each has unique characteristics. The best choice depends on your current environment or customer needs, as most CAD tools allow for mixing both languages across different modules.\n</p>\n<h4>\n 4.1.3 Simulation and Synthesis\n</h4>\n<p>\n The primary functions of HDLs are logic simulation and synthesis.\n</p>\n<ul>\n<li>\n<p>\n<strong>\n    Simulation\n   </strong>\n   : This involves applying inputs to a module and verifying the outputs to ensure correct operation. Identifying and fixing errors, or \"bugs,\" in hardware designs is crucial, especially in systems where safety and costs are at stake. Testing in the lab can be challenging, as only external signals can be observed, making error diagnosis difficult. Fixing mistakes after production can be extremely costly; for instance, Intel's Pentium processor bug led to a $475 million recall.\n  </p>\n</li>\n<li>\n<p>\n<strong>\n    Synthesis\n   </strong>\n   : This process converts the textual description of a module into logic gates.\n  </p>\n</li>\n</ul>\n<h4>\n VHDL\n</h4>\n<p>\n VHDL stands for VHSIC Hardware Description Language, originating from the Very High Speed Integrated Circuits program of the U.S. Department of Defense. Developed in 1981 and standardized by the IEEE in 1987, VHDL was initially intended for documentation but quickly became essential for simulation and synthesis.\n</p>\n<h4>\n Verilog\n</h4>\n<p>\n Verilog was created in 1984 by Gateway Design Automation as a proprietary language for logic simulation. Acquired by Cadence in 1989, it became an open standard in 1990 and was standardized by the IEEE in 1995.\n</p>\n<hr/>\n<p>\n Let me know if you need further details or additional sections!\n</p>\n"}, "Page 175": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 195": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 180": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 209": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 198": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 191": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 171": {"response": "<h3>\n Simulation and Synthesis of HDL Modules\n</h3>\n<p>\n<strong>\n  Simulation\n </strong>\n : Figure 4.1 displays waveforms from a simulation of the\n <code>\n  sillyfunction\n </code>\n module, confirming that the module operates correctly. The output\n <code>\n  y\n </code>\n is TRUE for the input combinations a, b, and c corresponding to 000, 100, or 101, as defined by the Boolean equation.\n</p>\n<p>\n<strong>\n  Synthesis\n </strong>\n : Logic synthesis converts HDL code into a netlist, which outlines the hardware components (like logic gates and their connections). The synthesizer may optimize the design to minimize hardware usage. The netlist can be represented as a text file or a schematic for visualization. In Figure 4.2, the synthesis of the\n <code>\n  sillyfunction\n </code>\n module is shown. Here, three three-input AND gates are simplified into two two-input AND gates, as determined by Boolean algebra.\n</p>\n<p>\n HDL circuit descriptions resemble programming code but are specifically designed to represent hardware. Both Verilog and VHDL offer a wide range of commands, though not all can be synthesized into actual hardware. For example, commands for displaying results during simulation do not translate into physical hardware.\n</p>\n<p>\n The simulations were conducted using the Xilinx ISE Simulator, part of the Xilinx ISE 8.2 software, which is commercially available and free for universities. Synthesis was performed with Synplify Pro from Synplicity, a leading tool for synthesizing HDL into field-programmable gate arrays (FPGAs), also available affordably for academic use.\n</p>\n<hr/>\n<p>\n Let me know if you need more information or further sections summarized!\n</p>\n"}, "Page 204": {"response": "<h3>\n Example 3.10: Fixing Hold Time Violations\n</h3>\n<p>\n<strong>\n  Problem Overview\n </strong>\n<br/>\n Alyssa P. Hacker suggests adding buffers to Ben\u2019s circuit to address hold time violations, as depicted in Figure 3.42. These buffers introduce delays similar to other gates. We need to determine the maximum clock frequency and check for any hold time issues.\n</p>\n<p>\n<strong>\n  Solution\n </strong>\n<br/>\n Figure 3.43 shows signal waveforms that indicate when changes occur. The critical path from A to Y remains unaffected by the buffers, maintaining a maximum clock frequency of 4 GHz.\n</p>\n<p>\n However, the buffers slow down shorter paths. The output\n X\n \u2032\n X'\n X\n \u2032\n will now change after a contamination delay of the buffer:\n <br/>\n t\n c\n c\n q\n =\n 2\n t\n c\n d\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n t_{ccq} = 2t_{cd} = 30 + 2 \\times 25 = 80 \\text{ ps}\n t\n cc\n q\n \u200b\n =\n 2\n t\n c\n d\n \u200b\n =\n 30\n +\n 2\n \u00d7\n 25\n =\n 80\n ps\n <br/>\n This change occurs after the 60 ps hold time, ensuring that the circuit operates correctly.\n</p>\n<p>\n<strong>\n  Additional Notes\n </strong>\n<br/>\n This example highlights an unusually long hold time to emphasize hold time issues. Most flip-flops are designed with\n t\n h\n o\n l\n d\n \u2264\n t\n c\n c\n q\n t_{hold} \\leq t_{ccq}\n t\n h\n o\n l\n d\n \u200b\n \u2264\n t\n cc\n q\n \u200b\n to prevent such problems. Some high-performance microprocessors, like the Pentium 4, use pulsed latches instead of flip-flops. These latches have a shorter clock-to-Q delay and\n</p>\n"}, "Page 308": {"response": "<h3>\n Assembly Code and Conditionals\n</h3>\n<p>\n<strong>\n  If Statements:\n </strong>\n In assembly, the condition tested is the opposite of that in high-level code. For example, if the high-level code checks if\n <code>\n  i &lt; j\n </code>\n , the assembly code checks if\n <code>\n  i \u2265 j\n </code>\n . The\n <code>\n  bne\n </code>\n (branch if not equal) instruction skips the\n <code>\n  if\n </code>\n block when the condition is true. If the condition is false, the\n <code>\n  if\n </code>\n block executes.\n</p>\n<p>\n<strong>\n  If/Else Statements:\n </strong>\n If/else statements execute one of two blocks based on a condition. If the\n <code>\n  if\n </code>\n condition is true, the\n <code>\n  if\n </code>\n block runs; otherwise, the\n <code>\n  else\n </code>\n block runs. Similar to the\n <code>\n  if\n </code>\n statement, the assembly code tests the opposite condition. If\n <code>\n  i &lt; j\n </code>\n is true,\n <code>\n  bne\n </code>\n skips to the\n <code>\n  else\n </code>\n block. If false, the\n <code>\n  if\n </code>\n block executes and uses a jump instruction to skip over the\n <code>\n  else\n </code>\n block.\n</p>\n<p>\n<strong>\n  Example:\n </strong>\n</p>\n<ul>\n<li>\n<strong>\n   High-Level Code:\n  </strong>\n  c\n  Copy code\n  <code class=\"!whitespace-pre hljs language-c\">\n   if\n   (i &lt; j)\n    f = g + h;\n   else\n   f = f - i;\n  </code>\n</li>\n<li>\n<strong>\n   MIPS Assembly:\n  </strong>\n  assembly\n  Copy code\n  <code class=\"!whitespace-pre hljs language-assembly\">\n   # $s0 = f, $s1 = g, $s2 = h, $s3 = i, $s4 = j\nbne $s3, $s4, else    # if i \u2265 j, branch to else\nadd $s0, $s1, $s2     # if block: f = g + h\nj L2                   # skip else block\n  </code>\n</li>\n</ul>\n<p>\n else:\nsub $s0, $s0, $s3 # else block: f = f - i\nL2:\n</p>\nvbnet\nCopy code\n<code class=\"!whitespace-pre hljs language-vbnet\">\n ### Switch/\n Case\n Statements\nSwitch/\n case\n statements allow\n for\n the execution\n of\n one\n of\n several code blocks based\n on\n conditions, defaulting\n to\n a specific block\n if\n no conditions are met. They\n function\n like\n nested\n if\n /\n else\n statements.\n\n**Example:**\nTwo high-level code snippets calculate ATM withdrawal fees\n for\n $\n 20\n , $\n 50\n ,\n or\n $\n 100\n ,\n with\n the same MIPS\n assembly\n implementation.\n\n### Loops\nLoops repeatedly execute code based\n on\n a condition, commonly\n using\n `\n for\n `\n and\n `\n while\n ` constructs\n in\n high-level languages. This section covers how\n to\n translate these loops\n into\n MIPS\n assembly\n language.\n</code>\n"}, "Page 309": {"response": "<h3>\n Switch/Case Statements\n</h3>\n<p>\n<strong>\n  High-Level Code:\n </strong>\n</p>\nc\nCopy code\n<code class=\"!whitespace-pre hljs language-c\">\n switch\n (amount) {\n case\n 20\n : fee =\n 2\n ;\n break\n ;\n case\n 50\n : fee =\n 3\n ;\n break\n ;\n case\n 100\n : fee =\n 5\n ;\n break\n ;\n default\n : fee =\n 0\n ;\n}\n // Equivalent if/else statements\n if\n (amount ==\n 20\n ) fee =\n 2\n ;\n else\n if\n (amount ==\n 50\n ) fee =\n 3\n ;\n else\n if\n (amount ==\n 100\n ) fee =\n 5\n ;\n else\n fee =\n 0\n ;\n</code>\n<p>\n<strong>\n  MIPS Assembly Code:\n </strong>\n</p>\nassembly\nCopy code\n<code class=\"!whitespace-pre hljs language-assembly\">\n # $s0 = amount, $s1 = fee\n\ncase20:\n    addi $t0, $0, 20    # $t0 = 20\n    bne $s0, $t0, case50 # If amount != 20, go to case50\n    addi $s1, $0, 2     # fee = 2\n    j done               # Exit case\n\ncase50:\n    addi $t0, $0, 50    # $t0 = 50\n    bne $s0, $t0, case100 # If amount != 50, go to case100\n    addi $s1, $0, 3     # fee = 3\n    j done               # Exit case\n\ncase100:\n    addi $t0, $0, 100   # $t0 = 100\n    bne $s0, $t0, default # If amount != 100, go to default\n    addi $s1, $0, 5     # fee = 5\n    j done               # Exit case\n\ndefault:\n    add $s1, $0, $0     # fee = 0\n\ndone:\n</code>\n<hr/>\n<h3>\n While Loops\n</h3>\n<p>\n<strong>\n  High-Level Code:\n </strong>\n</p>\nc\nCopy code\n<code class=\"!whitespace-pre hljs language-c\">\n int\n pow\n =\n 1\n ;\n int\n x =\n 0\n ;\n while\n (\n pow\n !=\n 128\n ) {\n pow\n =\n pow\n *\n 2\n ;\n    x = x +\n 1\n ;\n}\n</code>\n<p>\n<strong>\n  MIPS Assembly Code:\n </strong>\n</p>\nassembly\nCopy code\n<code class=\"!whitespace-pre hljs language-assembly\">\n # $s0 = pow, $s1 = x\naddi $s0, $0, 1      # pow = 1\naddi $s1, $0, 0      # x = 0\naddi $t0, $0, 128    # $t0 = 128 for comparison\n\nwhile:\n    beq $s0, $t0, done # If pow == 128, exit loop\n    sll $s0, $s0, 1     # pow = pow * 2\n    addi $s1, $s1, 1    # x = x + 1\n    j while             # Repeat loop\n\ndone:\n</code>\n"}, "Page 310": {"response": "<h3>\n While Loops\n</h3>\n<p>\n In Code Example 6.19, the while loop checks if\n <code>\n  pow\n </code>\n equals 128. If they are equal, it exits the loop. If not, it doubles\n <code>\n  pow\n </code>\n (using a left shift), increments\n <code>\n  x\n </code>\n , and returns to the start of the loop.\n</p>\n<hr/>\n<h3>\n For Loops\n</h3>\n<p>\n For loops, like while loops, repeatedly execute a block of code based on a condition, but they also include a loop variable to track the number of iterations. The general format is:\n</p>\nplaintext\nCopy code\n<code class=\"!whitespace-pre hljs language-plaintext\">\n for (initialization; condition; loop operation)\n</code>\n<ul>\n<li>\n<strong>\n   Initialization\n  </strong>\n  : Runs before the loop starts.\n </li>\n<li>\n<strong>\n   Condition\n  </strong>\n  : Checked at the beginning of each iteration. The loop exits if false.\n </li>\n<li>\n<strong>\n   Loop Operation\n  </strong>\n  : Executes at the end of each iteration.\n </li>\n</ul>\n<p>\n<strong>\n  Example:\n </strong>\n Code Example 6.20 sums the numbers from 0 to 9. The loop variable\n <code>\n  i\n </code>\n starts at 0 and increments after each iteration. The loop continues as long as\n <code>\n  i\n </code>\n is less than 10, executing a total of 10 times. For loops can be rewritten as while loops, but they are often more convenient.\n</p>\n<p>\n<strong>\n  High-Level Code:\n </strong>\n</p>\nc\nCopy code\n<code class=\"!whitespace-pre hljs language-c\">\n int\n sum =\n 0\n ;\n for\n (i =\n 0\n ; i !=\n 10\n ; i++) {\n    sum += i;\n}\n // Equivalent while loop\n int\n sum =\n 0\n ;\n int\n i =\n 0\n ;\n while\n (i !=\n 10\n ) {\n    sum += i;\n    i++;\n}\n</code>\n<p>\n<strong>\n  MIPS Assembly Code:\n </strong>\n</p>\nassembly\nCopy code\n<code class=\"!whitespace-pre hljs language-assembly\">\n # $s0 = i, $s1 = sum\nadd $s1, $0, $0      # sum = 0\naddi $s0, $0, 0      # i = 0\naddi $t0, $0, 10     # $t0 = 10\n\nfor:\n    beq $s0, $t0, done # If i == 10, exit loop\n    add $s1, $s1, $s0   # sum += i\n    addi $s0, $s0, 1    # Increment i\n    j for                # Repeat loop\n\ndone:\n</code>\n<hr/>\n<h3>\n Magnitude Comparison\n</h3>\n<p>\n So far, examples have used\n <code>\n  beq\n </code>\n and\n <code>\n  bne\n </code>\n for equality checks. MIPS also provides the\n <code>\n  slt\n </code>\n (set less than) instruction for magnitude comparisons, which sets\n <code>\n  rd\n </code>\n to 1 if\n <code>\n  rs &lt; rt\n </code>\n , otherwise sets\n <code>\n  rd\n </code>\n to 0.\n</p>\n"}, "Page 311": {"response": "<h3>\n Example 6.6: Loops Using\n <code>\n  slt\n </code>\n</h3>\n<p>\n This example demonstrates how to add the powers of 2 from 1 to 100 using a loop.\n</p>\n<p>\n<strong>\n  High-Level Code:\n </strong>\n</p>\nc\nCopy code\n<code class=\"!whitespace-pre hljs language-c\">\n int\n sum =\n 0\n ;\n for\n (i =\n 1\n ; i &lt;\n 101\n ; i = i *\n 2\n ) {\n    sum += i;\n}\n</code>\n<p>\n<strong>\n  MIPS Assembly Code:\n </strong>\n</p>\nassembly\nCopy code\n<code class=\"!whitespace-pre hljs language-assembly\">\n # $s0 = i, $s1 = sum\naddi $s1, $0, 0      # sum = 0\naddi $s0, $0, 1      # i = 1\naddi $t0, $0, 101     # $t0 = 101\n\nloop:\n    slt $t1, $s0, $t0 # if (i &lt; 101), $t1 = 1, else $t1 = 0\n    beq $t1, $0, done  # if $t1 != 1 (i &gt;= 101), exit loop\n    add $s1, $s1, $s0  # sum += i\n    sll $s0, $s0, 1    # i = i * 2\n    j loop              # Repeat loop\n\ndone:\n</code>\n<hr/>\n<h3>\n Arrays\n</h3>\n<p>\n Arrays allow access to large amounts of similar data, organized as sequential memory addresses. Each element is identified by an index, with the total number of elements referred to as the array's size.\n</p>\n<h4>\n Array Indexing\n</h4>\n<p>\n Consider an array of five integers, with indices ranging from 0 to 4. The array starts at a base address (e.g.,\n <code>\n  0x10007000\n </code>\n ). This base address points to the first element,\n <code>\n  array[0]\n </code>\n .\n</p>\n<p>\n<strong>\n  Example 6.21:\n </strong>\n This example multiplies the first two elements of the array by 8 and stores the results back in the array. To access an array element, first load the base address of the array into a register.\n</p>\n"}, "Page 312": {"response": "<h3>\n Loading Array Elements in MIPS\n</h3>\n<p>\n To access array elements in MIPS, you first load the base address of the array into a register (e.g.,\n <code>\n  $s0\n </code>\n ). Use the\n <code>\n  lui\n </code>\n (load upper immediate) and\n <code>\n  ori\n </code>\n (or immediate) instructions to load a 32-bit constant.\n</p>\n<p>\n<strong>\n  Understanding Memory Access:\n </strong>\n The\n <code>\n  lw\n </code>\n (load word) instruction takes a base address and an offset to access specific elements. For example, if the base address is\n <code>\n  0x10007000\n </code>\n , then:\n</p>\n<ul>\n<li>\n<code>\n   array[0]\n  </code>\n  is at\n  <code>\n   0x10007000\n  </code>\n</li>\n<li>\n<code>\n   array[1]\n  </code>\n  is at\n  <code>\n   0x10007004\n  </code>\n  (4 bytes later)\n </li>\n</ul>\n<h3>\n Example: Accessing Individual Array Elements\n</h3>\n<p>\n In Code Example 6.21, the code for manipulating two array elements is similar, except for the index. While this is manageable for two elements, it becomes inefficient for larger arrays.\n</p>\n<p>\n<strong>\n  High-Level Code:\n </strong>\n</p>\nc\nCopy code\n<code class=\"!whitespace-pre hljs language-c\">\n int\n array\n [\n 5\n ];\n array\n [\n 0\n ] =\n array\n [\n 0\n ] *\n 8\n ;\n array\n [\n 1\n ] =\n array\n [\n 1\n ] *\n 8\n ;\n</code>\n<p>\n<strong>\n  MIPS Assembly Code:\n </strong>\n</p>\nassembly\nCopy code\n<code class=\"!whitespace-pre hljs language-assembly\">\n # $s0 = base address of array\nlui $s0, 0x1000        # Load upper half\nori $s0, $s0, 0x7000   # $s0 = 0x10007000\n\nlw $t1, 0($s0)         # Load array[0] into $t1\nsll $t1, $t1, 3        # $t1 = array[0] * 8\nsw $t1, 0($s0)         # Store back into array[0]\n\nlw $t1, 4($s0)         # Load array[1] into $t1\nsll $t1, $t1, 3        # $t1 = array[1] * 8\nsw $t1, 4($s0)         # Store back into array[1]\n</code>\n<h3>\n Looping Through an Array\n</h3>\n<p>\n For larger arrays, such as a 1000-element array, Code Example 6.22 uses a for loop to multiply each element by 8, which is more efficient than duplicating code for each element.\n</p>\n<p>\n<strong>\n  Memory Addressing:\n </strong>\n In the for loop, since the index is a variable (\n <code>\n  i\n </code>\n ), you can't use an immediate offset with\n <code>\n  lw\n </code>\n . Instead, compute the address of the\n <code>\n  i\n </code>\n -th element by multiplying the index by the size of each element (4 bytes for a word) and adding it to the base address.\n</p>\n<p>\n<strong>\n  Figure Reference:\n </strong>\n An illustration (Figure 6.21) shows a 1000-element array in memory, emphasizing the need for a variable index for efficient access.\n</p>\n"}, "Page 313": {"response": "<h3>\n Base Address Calculation\n</h3>\n<p>\n In MIPS assembly, the base address of an array element can be calculated using\n <code>\n  i * 4\n </code>\n , since each integer is 4 bytes. Shifting left by 2 (using\n <code>\n  sll\n </code>\n ) effectively multiplies\n <code>\n  i\n </code>\n by 4, making it a convenient operation in assembly.\n</p>\n<h3>\n Bytes and Characters\n</h3>\n<p>\n Values in the range [-128, 127] can be stored in a single byte instead of a full word. Since there are fewer than 256 characters on an English keyboard, characters are often represented by bytes. In C, the\n <code>\n  char\n </code>\n type represents a byte or character.\n</p>\n<p>\n Historically, there was no standard mapping of bytes to English characters, complicating text exchange between computers. In 1963, the American Standards Association introduced ASCII (American Standard Code for Information Interchange), assigning unique byte values to each character. ASCII values for printable characters are often represented in hexadecimal, and the difference between lower-case and upper-case letters is 0x20 (32).\n</p>\n<h3>\n Example: Accessing Array Elements Using a For Loop\n</h3>\n<p>\n<strong>\n  High-Level Code:\n </strong>\n</p>\nc\nCopy code\n<code class=\"!whitespace-pre hljs language-c\">\n int\n i;\n int\n array\n [\n 1000\n ];\n for\n (i =\n 0\n ; i &lt;\n 1000\n ; i++) {\n array\n [i] =\n array\n [i] *\n 8\n ;\n}\n</code>\n<p>\n<strong>\n  MIPS Assembly Code:\n </strong>\n</p>\nassembly\nCopy code\n<code class=\"!whitespace-pre hljs language-assembly\">\n # $s0 = base address of array, $s1 = i\nlui $s0, 0x23B8        # Load upper half of base address\nori $s0, $s0, 0xF000   # $s0 = 0x23B8F000\naddi $s1, $0, 0        # i = 0\naddi $t2, $0, 1000     # $t2 = 1000\n\nloop:\n    slt $t0, $s1, $t2  # Check if i &lt; 1000\n    beq $t0, $0, done   # If not, exit loop\n    sll $t0, $s1, 2     # $t0 = i * 4 (byte offset)\n    add $t0, $t0, $s0   # Address of array[i]\n    lw $t1, 0($t0)      # Load array[i] into $t1\n    sll $t1, $t1, 3     # $t1 = array[i] * 8\n    sw $t1, 0($t0)      # Store back into array[i]\n    addi $s1, $s1, 1    # Increment i\n    j loop               # Repeat\n\ndone:\n</code>\n<h3>\n Character Encodings\n</h3>\n<p>\n Other programming languages, like Java, use different character encodings, with Unicode being a notable example. Unicode uses 16 bits for each character, allowing for accents, umlauts, and various Asian scripts. For more information, visit\n <a href=\"http://www.unicode.org\" rel=\"noopener\" style=\"--streaming-animation-state: var(--batch-play-state-1); --animation-rate: var(--batch-play-rate-1);\" target=\"_new\">\n  unicode\n  .org\n </a>\n .\n</p>\n<h3>\n Memory Representation\n</h3>\n<p>\n Figure 6.21 illustrates the layout of the 1000-element array in memory, starting from the base address\n <code>\n  0x23B8F000\n </code>\n . Each element occupies 4 bytes, and the addresses are incremented accordingly.\n</p>\n"}, "Page 314": {"response": "<h3>\n MIPS Byte Manipulation Instructions\n</h3>\n<p>\n MIPS architecture includes instructions to handle individual bytes or characters:\n</p>\n<ul>\n<li>\n<strong>\n   Load Byte Unsigned (lbu)\n  </strong>\n</li>\n<li>\n<strong>\n   Load Byte (lb)\n  </strong>\n</li>\n<li>\n<strong>\n   Store Byte (sb)\n  </strong>\n</li>\n</ul>\n<p>\n These instructions are designed for manipulating single-byte data, as illustrated in Figure 6.22.\n</p>\n<h3>\n Evolution of Character Encoding\n</h3>\n<p>\n Character encoding has a rich history, beginning with telegraph machines that used Morse code (introduced in 1838). Morse code represented letters with a series of dots and dashes. For example:\n</p>\n<ul>\n<li>\n  A: .\u2212\n </li>\n<li>\n  B: \u2212...\n </li>\n<li>\n  C: \u2212.\u2212.\n </li>\n<li>\n  D: \u2212..\n </li>\n</ul>\n<p>\n In 1874, Jean-Maurice-Emile Baudot developed a 5-bit code, where letters A, B, C, and D were represented as:\n</p>\n<ul>\n<li>\n  A: 00011\n </li>\n<li>\n  B: 11001\n </li>\n<li>\n  C: 01110\n </li>\n<li>\n  D: 01001\n </li>\n</ul>\n<p>\n However, this 5-bit code could not represent all English characters. The shift to 8-bit encoding allowed for a more comprehensive character set, leading to the adoption of 8-bit ASCII encoding as the standard for electronic communication.\n</p>\n<h3>\n ASCII Character Encoding Table\n</h3>\n<p>\n Table 6.2 outlines ASCII encodings for various characters. Here are some examples:\n</p>\n<table>\n<thead>\n<tr>\n<th>\n    Decimal\n   </th>\n<th>\n    Character\n   </th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>\n    20\n   </td>\n<td>\n    space\n   </td>\n</tr>\n<tr>\n<td>\n    30\n   </td>\n<td>\n    0\n   </td>\n</tr>\n<tr>\n<td>\n    40\n   </td>\n<td>\n    @\n   </td>\n</tr>\n<tr>\n<td>\n    50\n   </td>\n<td>\n    P\n   </td>\n</tr>\n<tr>\n<td>\n    60\n   </td>\n<td>\n    `\n   </td>\n</tr>\n<tr>\n<td>\n    70\n   </td>\n<td>\n    p\n   </td>\n</tr>\n<tr>\n<td>\n    21\n   </td>\n<td>\n    !\n   </td>\n</tr>\n<tr>\n<td>\n    31\n   </td>\n<td>\n    1\n   </td>\n</tr>\n<tr>\n<td>\n    41\n   </td>\n<td>\n    A\n   </td>\n</tr>\n<tr>\n<td>\n    51\n   </td>\n<td>\n    Q\n   </td>\n</tr>\n<tr>\n<td>\n    61\n   </td>\n<td>\n    a\n   </td>\n</tr>\n<tr>\n<td>\n    71\n   </td>\n<td>\n    q\n   </td>\n</tr>\n</tbody>\n</table>\n<h3>\n Memory Representation Example\n</h3>\n<p>\n In memory, bytes are stored in little-endian format, where the least significant byte is stored at the lowest address. The following example shows how to load and store bytes in MIPS:\n</p>\n<ul>\n<li>\n<p>\n<strong>\n    Example of Load Byte Unsigned (lbu)\n   </strong>\n   :\n  </p>\n<ul>\n<li>\n<code>\n     lbu $s1, 2($0)\n    </code>\n    loads the byte at offset 2 into register\n    <code>\n     $s1\n    </code>\n    .\n   </li>\n</ul>\n</li>\n<li>\n<p>\n<strong>\n    Example of Load Byte (lb)\n   </strong>\n   :\n  </p>\n<ul>\n<li>\n<code>\n     lb $s2, 2($0)\n    </code>\n    loads the byte at offset 2, including sign extension, into register\n    <code>\n     $s2\n    </code>\n    .\n   </li>\n</ul>\n</li>\n<li>\n<p>\n<strong>\n    Example of Store Byte (sb)\n   </strong>\n   :\n  </p>\n<ul>\n<li>\n<code>\n     sb $s3, 3($0)\n    </code>\n    stores the byte from\n    <code>\n     $s3\n    </code>\n    at offset 3.\n   </li>\n</ul>\n</li>\n</ul>\n<p>\n This demonstrates how MIPS handles byte-level data manipulation effectively.\n</p>\n"}, "Page 315": {"response": "<h3>\n Understanding MIPS Byte Instructions\n</h3>\n<p>\n MIPS provides specific instructions to handle byte manipulation:\n</p>\n<ul>\n<li>\n<p>\n<strong>\n    Load Byte Unsigned (lbu)\n   </strong>\n   : This instruction loads a byte from memory and zero-extends it to fill a 32-bit register. For example, if the byte is\n   <code>\n    0x9B\n   </code>\n   , the register will contain\n   <code>\n    0x0000009B\n   </code>\n   .\n  </p>\n</li>\n<li>\n<p>\n<strong>\n    Load Byte (lb)\n   </strong>\n   : This instruction loads a byte from memory and sign-extends it. If the byte is\n   <code>\n    0x9B\n   </code>\n   , the register will contain\n   <code>\n    0xFFFFFFFF9B\n   </code>\n   if the byte's most significant bit is set (indicating a negative value).\n  </p>\n</li>\n<li>\n<p>\n<strong>\n    Store Byte (sb)\n   </strong>\n   : This instruction takes the least significant byte from a 32-bit register and stores it in the specified memory address. For instance, if register\n   <code>\n    $s3\n   </code>\n   contains\n   <code>\n    0xF79B\n   </code>\n   , the command\n   <code>\n    sb $s3, 3($0)\n   </code>\n   will replace the byte at memory address 3 with\n   <code>\n    0x9B\n   </code>\n   .\n  </p>\n</li>\n</ul>\n<h3>\n Example: Converting Characters to Upper Case\n</h3>\n<p>\n Here\u2019s an example of using\n <code>\n  lb\n </code>\n and\n <code>\n  sb\n </code>\n to convert a character array from lowercase to uppercase by subtracting 32 from each character:\n</p>\n<h4>\n High-Level Code\n</h4>\nc\nCopy code\n<code class=\"!whitespace-pre hljs language-c\">\n char\n chararray[\n 10\n ];\n int\n i;\n for\n (i =\n 0\n ; i &lt;\n 10\n ; i++)\n    chararray[i] = chararray[i] -\n 32\n ;\n</code>\n<h4>\n MIPS Assembly Code\n</h4>\nassembly\nCopy code\n<code class=\"!whitespace-pre hljs language-assembly\">\n # $s0  = base address of chararray, $s1 = i\naddi $s1, $0, 0    # i = 0\naddi $t0, $0, 10   # $t0 = 10\n\nloop:\n    beq $t0, $s1, done      # if i == 10, exit loop\n    add $t1, $s1, $s0       # $t1 = address of chararray[i]\n    lb  $t2, 0($t1)         # $t2 = chararray[i]\n    addi $t2, $t2, -32      # convert to upper case\n    sb  $t2, 0($t1)         # store new value in chararray[i]\n    addi $s1, $s1, 1        # i = i + 1\n    j loop                   # repeat\ndone:\n</code>\n<h3>\n Understanding Strings in Memory\n</h3>\n<p>\n Strings in programming are sequences of characters with variable lengths. In C, strings end with a null character (\n <code>\n  0x00\n </code>\n ), which indicates the termination of the string.\n</p>\n<h4>\n Example: String in Memory\n</h4>\n<p>\n Consider the string \"Hello!\" stored in memory, as shown in Figure 6.23:\n</p>\n<ul>\n<li>\n<strong>\n   Memory Representation\n  </strong>\n  :\n  <ul>\n<li>\n    Address\n    <code>\n     0x1522FFF0\n    </code>\n    :\n    <code>\n     0x48\n    </code>\n    (H)\n   </li>\n<li>\n    Address\n    <code>\n     0x1522FFF1\n    </code>\n    :\n    <code>\n     0x65\n    </code>\n    (e)\n   </li>\n<li>\n    Address\n    <code>\n     0x1522FFF2\n    </code>\n    :\n    <code>\n     0x6C\n    </code>\n    (l)\n   </li>\n<li>\n    Address\n    <code>\n     0x1522FFF3\n    </code>\n    :\n    <code>\n     0x6C\n    </code>\n    (l)\n   </li>\n<li>\n    Address\n    <code>\n     0x1522FFF4\n    </code>\n    :\n    <code>\n     0x6F\n    </code>\n    (o)\n   </li>\n<li>\n    Address\n    <code>\n     0x1522FFF5\n    </code>\n    :\n    <code>\n     0x21\n    </code>\n    (!)\n   </li>\n<li>\n    Address\n    <code>\n     0x1522FFF6\n    </code>\n    :\n    <code>\n     0x00\n    </code>\n    (null terminator)\n   </li>\n</ul>\n</li>\n</ul>\n<p>\n This string spans seven bytes, with the first character stored at the lowest address, following the little-endian memory format.\n</p>\n"}, "Page 316": {"response": "<h3>\n Understanding Procedure Calls in MIPS\n</h3>\n<p>\n Procedures, or functions, are essential in high-level programming languages for code reuse and improving program readability. They take inputs called arguments and produce an output known as the return value. Procedures should focus on calculating the return value without causing unintended side effects.\n</p>\n<h3>\n Procedure Calling Convention\n</h3>\n<p>\n When one procedure (the caller) invokes another (the callee), both must agree on how to handle arguments and return values:\n</p>\n<ul>\n<li>\n<strong>\n   Arguments\n  </strong>\n  : In MIPS, the caller places up to four arguments in registers\n  <code>\n   $a0\n  </code>\n  to\n  <code>\n   $a3\n  </code>\n  .\n </li>\n<li>\n<strong>\n   Return Value\n  </strong>\n  : The callee uses registers\n  <code>\n   $v0\n  </code>\n  (and\n  <code>\n   $v1\n  </code>\n  if needed) to store the return value before finishing.\n </li>\n</ul>\n<p>\n This agreement ensures that both procedures can find the arguments and return value, regardless of who wrote them.\n</p>\n<h3>\n Caller-Callee Responsibilities\n</h3>\n<ol>\n<li>\n<strong>\n   Return Address\n  </strong>\n  : The caller saves the return address in the\n  <code>\n   $ra\n  </code>\n  register using the\n  <strong>\n   jump and link (jal)\n  </strong>\n  instruction.\n </li>\n<li>\n<strong>\n   State Preservation\n  </strong>\n  : The callee must not alter any registers or memory that the caller depends on. Specifically, it should not modify:\n  <ul>\n<li>\n    Saved registers (\n    <code>\n     $s0\n    </code>\n    to\n    <code>\n     $s7\n    </code>\n    )\n   </li>\n<li>\n    The return address (\n    <code>\n     $ra\n    </code>\n    )\n   </li>\n<li>\n    The stack, which is used for temporary variables.\n   </li>\n</ul>\n</li>\n</ol>\n<h3>\n Calling and Returning from Procedures\n</h3>\n<p>\n MIPS uses the\n <code>\n  jal\n </code>\n instruction to call a procedure and the\n <code>\n  jr\n </code>\n instruction to return from one.\n</p>\n<h4>\n Example: Simple Procedure Call\n</h4>\n<p>\n<strong>\n  High-Level Code:\n </strong>\n</p>\nc\nCopy code\n<code class=\"!whitespace-pre hljs language-c\">\n int\n main\n ()\n {\n    simple();\n}\n // void indicates the function returns no value\n void\n simple\n ()\n {\n return\n ;\n}\n</code>\n<p>\n<strong>\n  MIPS Assembly Code:\n </strong>\n</p>\nassembly\nCopy code\n<code class=\"!whitespace-pre hljs language-assembly\">\n 0x00400200 main:\n    jal simple  # call the simple procedure\n    ...\n0x00401020 simple:\n    jr $ra      # return to the caller\n</code>\n<p>\n In this example:\n</p>\n<ul>\n<li>\n  The\n  <code>\n   main\n  </code>\n  function calls the\n  <code>\n   simple\n  </code>\n  procedure using\n  <code>\n   jal\n  </code>\n  .\n </li>\n<li>\n  The\n  <code>\n   simple\n  </code>\n  procedure returns control to\n  <code>\n   main\n  </code>\n  with the\n  <code>\n   jr $ra\n  </code>\n  instruction, which jumps back to the address stored in\n  <code>\n   $ra\n  </code>\n  .\n </li>\n</ul>\n<p>\n This mechanism allows for organized, reusable code while maintaining clarity and functionality.\n</p>\n"}, "Page 317": {"response": "<h3>\n Procedure Calls with\n <code>\n  jal\n </code>\n and\n <code>\n  jr\n </code>\n in MIPS\n</h3>\n<p>\n In MIPS assembly, two crucial instructions for procedure calls are\n <strong>\n  jump and link (\n  <code>\n   jal\n  </code>\n  )\n </strong>\n and\n <strong>\n  jump register (\n  <code>\n   jr $ra\n  </code>\n  )\n </strong>\n .\n</p>\n<ul>\n<li>\n<p>\n<strong>\n<code>\n     jal\n    </code>\n    Instruction\n   </strong>\n   :\n  </p>\n<ul>\n<li>\n    This instruction does two things: it saves the address of the next instruction (the one immediately after\n    <code>\n     jal\n    </code>\n    ) into the return address register (\n    <code>\n     $ra\n    </code>\n    ), and it jumps to the target procedure.\n   </li>\n<li>\n    For example, when the\n    <code>\n     main\n    </code>\n    procedure calls\n    <code>\n     simple\n    </code>\n    , executing\n    <code>\n     jal simple\n    </code>\n    stores the address\n    <code>\n     0x00400204\n    </code>\n    in\n    <code>\n     $ra\n    </code>\n    and jumps to the\n    <code>\n     simple\n    </code>\n    procedure.\n   </li>\n</ul>\n</li>\n<li>\n<p>\n<strong>\n<code>\n     jr $ra\n    </code>\n    Instruction\n   </strong>\n   :\n  </p>\n<ul>\n<li>\n    This instruction is used by the called procedure to return control back to the caller. It jumps to the address stored in\n    <code>\n     $ra\n    </code>\n    , allowing the caller (like\n    <code>\n     main\n    </code>\n    ) to continue execution right after the call.\n   </li>\n</ul>\n</li>\n</ul>\n<h3>\n Input Arguments and Return Values\n</h3>\n<p>\n In the previous example, the\n <code>\n  simple\n </code>\n procedure doesn't take any input or return any output, which limits its usefulness. MIPS conventions specify that:\n</p>\n<ul>\n<li>\n<strong>\n   Input Arguments\n  </strong>\n  : The calling procedure should place arguments into registers\n  <code>\n   $a0\n  </code>\n  to\n  <code>\n   $a3\n  </code>\n  . For example,\n  <code>\n   main\n  </code>\n  can pass four arguments to a called procedure.\n </li>\n<li>\n<strong>\n   Return Value\n  </strong>\n  : The called procedure stores its return value in\n  <code>\n   $v0\n  </code>\n  .\n </li>\n</ul>\n<p>\n If a procedure needs to return a 64-bit value (like a double-precision float), it uses both\n <code>\n  $v0\n </code>\n and\n <code>\n  $v1\n </code>\n . Additionally, if a procedure has more than four arguments, any extra arguments are stored on the stack.\n</p>\n<h3>\n Example: Calling a Procedure with Arguments\n</h3>\n<h4>\n High-Level Code:\n</h4>\nc\nCopy code\n<code class=\"!whitespace-pre hljs language-c\">\n int\n main\n ()\n {\n int\n y;\n    y = diffofsums(\n 2\n ,\n 3\n ,\n 4\n ,\n 5\n );\n}\n</code>\n<h4>\n MIPS Assembly Code:\n</h4>\nassembly\nCopy code\n<code class=\"!whitespace-pre hljs language-assembly\">\n main:\n    addi $a0, $0, 2  # argument 0 = 2\n    addi $a1, $0, 3  # argument 1 = 3\n    addi $a2, $0, 4  # argument 2 = 4\n    addi $a3, $0, 5  # argument 3 = 5\n    jal diffofsums    # call procedure\n    add $s0, $v0, $0  # store returned value in y\n    ...\n\ndiffofsums:\n    add $t0, $a0, $a1  # $t0 = f + g\n    add $t1, $a2, $a3  # $t1 = h + i\n    sub $s0, $t0, $t1   # result = (f + g) - (h + i)\n    add $v0, $s0, $0    # return value in $v0\n    jr $ra              # return to caller\n</code>\n<p>\n In this example:\n</p>\n<ul>\n<li>\n  The\n  <code>\n   main\n  </code>\n  procedure prepares four arguments and calls the\n  <code>\n   diffofsums\n  </code>\n  procedure.\n </li>\n<li>\n  The\n  <code>\n   diffofsums\n  </code>\n  procedure computes a result based on the inputs and stores it in\n  <code>\n   $v0\n  </code>\n  for the caller to use.\n </li>\n</ul>\n<h3>\n Note on Code Errors\n</h3>\n<p>\n The code in this example may contain minor errors, which can be corrected in later examples.\n</p>\n"}, "Page 318": {"response": "<h3>\n The Stack in MIPS Programming\n</h3>\n<p>\n The\n <strong>\n  stack\n </strong>\n is a region of memory used for storing local variables within a procedure. It dynamically expands to accommodate additional data when needed and contracts when that data is no longer required. Here's how the stack operates:\n</p>\n<h4>\n Stack Structure\n</h4>\n<ul>\n<li>\n  The stack functions as a\n  <strong>\n   last-in-first-out (LIFO)\n  </strong>\n  structure, meaning the last item added (pushed) is the first one that can be removed (popped). This is similar to a stack of plates where you can only access the top plate.\n </li>\n<li>\n  Each procedure can allocate space on the stack for local variables, but it must also deallocate that space before returning to the caller.\n </li>\n<li>\n  Unlike a stack of plates that grows upward, the MIPS stack\n  <strong>\n   grows downward\n  </strong>\n  in memory, meaning it expands into lower memory addresses as more space is needed.\n </li>\n</ul>\n<h4>\n Stack Pointer ($sp)\n</h4>\n<ul>\n<li>\n  The\n  <strong>\n   stack pointer\n  </strong>\n  ($sp) is a special MIPS register that points to the top of the stack, which is the lowest accessible memory address currently in use.\n </li>\n<li>\n  For example, if $sp holds the address\n  <code>\n   0x7FFFFFFC\n  </code>\n  , it points to the data value stored at that address.\n </li>\n</ul>\n<h4>\n Stack Operations\n</h4>\n<ol>\n<li>\n<p>\n<strong>\n    Expanding the Stack\n   </strong>\n   : When more space is needed, $sp decrements. For instance, if $sp starts at\n   <code>\n    0x7FFFFFFC\n   </code>\n   and needs to store two additional words, it decrements by 8 to\n   <code>\n    0x7FFFFFF4\n   </code>\n   , making room for those two data words.\n  </p>\n</li>\n<li>\n<p>\n<strong>\n    Saving and Restoring Registers\n   </strong>\n   : One of the critical functions of the stack is to save and restore registers during procedure calls. A procedure should modify only the register holding the return value ($v0) and not alter any other registers. If it does, it risks corrupting the caller's data.\n  </p>\n</li>\n</ol>\n<h4>\n Steps for Using the Stack in Procedures\n</h4>\n<ol>\n<li>\n<strong>\n   Allocate Stack Space\n  </strong>\n  : Create space on the stack for the registers that will be modified.\n </li>\n<li>\n<strong>\n   Store Register Values\n  </strong>\n  : Save the current values of the registers onto the stack.\n </li>\n<li>\n<strong>\n   Execute Procedure\n  </strong>\n  : Perform the procedure\u2019s operations using the registers.\n </li>\n<li>\n<strong>\n   Restore Register Values\n  </strong>\n  : Retrieve the original values of the registers from the stack.\n </li>\n<li>\n<strong>\n   Deallocate Stack Space\n  </strong>\n  : Release the stack space used during the procedure.\n </li>\n</ol>\n<h3>\n Visual Representation\n</h3>\n<ul>\n<li>\n<strong>\n   Figure 6.24\n  </strong>\n  illustrates the stack. Initially, $sp points to\n  <code>\n   0x7FFFFFFC\n  </code>\n  , which holds the value\n  <code>\n   0x12345678\n  </code>\n  . When space is allocated, the stack pointer moves down to\n  <code>\n   0x7FFFFFF4\n  </code>\n  , where two new values,\n  <code>\n   0xAABBCCDD\n  </code>\n  and\n  <code>\n   0x11223344\n  </code>\n  , are stored.\n </li>\n</ul>\n<p>\n By using the stack effectively, procedures can ensure they do not unintentionally modify the caller's data, maintaining program stability and correctness.\n</p>\n"}, "Page 319": {"response": "<h3>\n Improved Procedure Management in MIPS\n</h3>\n<p>\n<strong>\n  Code Example 6.25\n </strong>\n presents an enhanced version of the\n <code>\n  diffofsums\n </code>\n procedure that properly saves and restores the registers\n <code>\n  $t0\n </code>\n ,\n <code>\n  $t1\n </code>\n , and\n <code>\n  $s0\n </code>\n . The modifications are highlighted in blue for clarity.\n <strong>\n  Figure 6.25\n </strong>\n illustrates the state of the stack before, during, and after calling\n <code>\n  diffofsums\n </code>\n .\n</p>\n<h4>\n Stack Frame Management\n</h4>\n<ul>\n<li>\n<strong>\n   Stack Space Allocation\n  </strong>\n  :\n  <code>\n   diffofsums\n  </code>\n  allocates space for three words on the stack by decrementing the stack pointer (\n  <code>\n   $sp\n  </code>\n  ) by 12 bytes. It then stores the current values of\n  <code>\n   $s0\n  </code>\n  ,\n  <code>\n   $t0\n  </code>\n  , and\n  <code>\n   $t1\n  </code>\n  in this newly allocated space.\n </li>\n<li>\n<strong>\n   Procedure Execution\n  </strong>\n  : After saving the registers, the procedure executes and modifies the values in these registers.\n </li>\n<li>\n<strong>\n   Restoration and Return\n  </strong>\n  : At the end of the procedure,\n  <code>\n   diffofsums\n  </code>\n  restores the original values of\n  <code>\n   $s0\n  </code>\n  ,\n  <code>\n   $t0\n  </code>\n  , and\n  <code>\n   $t1\n  </code>\n  from the stack, deallocates the stack space, and returns. By the time it finishes,\n  <code>\n   $v0\n  </code>\n  holds the result, while\n  <code>\n   $s0\n  </code>\n  ,\n  <code>\n   $t0\n  </code>\n  ,\n  <code>\n   $t1\n  </code>\n  , and\n  <code>\n   $sp\n  </code>\n  retain their original values before the call.\n </li>\n</ul>\n<h4>\n Stack Frame Concept\n</h4>\n<ul>\n<li>\n  The area of the stack that a procedure uses for its own storage is known as its\n  <strong>\n   stack frame\n  </strong>\n  . In this case,\n  <code>\n   diffofsums\n  </code>\n  has a stack frame that is three words deep.\n </li>\n<li>\n  Following the principle of\n  <strong>\n   modularity\n  </strong>\n  , each procedure should only access its own stack frame and not interfere with the frames of other procedures.\n </li>\n</ul>\n<h3>\n Preserved vs. Non-Preserved Registers\n</h3>\n<ul>\n<li>\n<strong>\n   Preserved Registers\n  </strong>\n  : MIPS categorizes registers into preserved and non-preserved types. The preserved registers are\n  <code>\n   $s0\u2013$s7\n  </code>\n  , which must be saved and restored if used.\n </li>\n<li>\n<strong>\n   Non-Preserved Registers\n  </strong>\n  : The temporary registers,\n  <code>\n   $t0\u2013$t9\n  </code>\n  , are non-preserved and can be modified freely without needing to save their original values.\n </li>\n</ul>\n<p>\n<strong>\n  Code Example 6.26\n </strong>\n further refines\n <code>\n  diffofsums\n </code>\n by only saving the preserved register\n <code>\n  $s0\n </code>\n on the stack. Since\n <code>\n  $t0\n </code>\n and\n <code>\n  $t1\n </code>\n are non-preserved, there is no need to save them, avoiding unnecessary operations.\n</p>\n<h4>\n Caller and Callee Responsibilities\n</h4>\n<ul>\n<li>\n  When one procedure (the caller) calls another (the callee), the callee is responsible for saving and restoring any preserved registers it uses. The callee may modify non-preserved registers without concern for the caller's data. This separation ensures that the caller\u2019s active data remains intact throughout the procedure calls.\n </li>\n</ul>\n"}}